{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5543724",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "################################################################################\n",
      "### WARNING, path does not exist: KALDI_ROOT=/mnt/matylda5/iveselyk/Tools/kaldi-trunk\n",
      "###          (please add 'export KALDI_ROOT=<your_path>' in your $HOME/.profile)\n",
      "###          (or run as: KALDI_ROOT=<your_path> python <your_script>.py)\n",
      "################################################################################\n",
      "\n",
      "/root/anaconda3/lib/python3.7/site-packages/torchaudio/backend/utils.py:54: UserWarning: \"sox\" backend is being deprecated. The default backend will be changed to \"sox_io\" backend in 0.8.0 and \"sox\" backend will be removed in 0.9.0. Please migrate to \"sox_io\" backend. Please refer to https://github.com/pytorch/audio/issues/903 for the detail.\n",
      "  '\"sox\" backend is being deprecated. '\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4498014f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jun 30 15:00:08 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.116.00   Driver Version: 418.116.00   CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM3...  On   | 00000000:59:00.0 Off |                    0 |\n",
      "| N/A   40C    P0    79W / 350W |   4350MiB / 32480MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a141525e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np_rng = np.random.default_rng(1)\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import urllib.parse\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "import os\n",
    "\n",
    "from lidbox.meta import (\n",
    "    common_voice,\n",
    "    generate_label2target,\n",
    "    verify_integrity,\n",
    "    read_audio_durations,\n",
    "    random_oversampling_on_split\n",
    ")\n",
    "\n",
    "\n",
    "train = pd.read_csv(\"/tf/datasets/train.tsv\", sep=\"\\t\")\n",
    "test = pd.read_csv(\"/tf/datasets/test.tsv\", sep=\"\\t\")\n",
    "dev = pd.read_csv(\"/tf/datasets/dev.tsv\", sep=\"\\t\")\n",
    "\n",
    "train[\"path\"] = train[\"path\"].apply(lambda x: x[:-3] + \"mp3\")\n",
    "test[\"path\"] = test[\"path\"].apply(lambda x: x[:-3] + \"mp3\")\n",
    "dev[\"path\"] = dev[\"path\"].apply(lambda x: x[:-3] + \"mp3\")\n",
    "\n",
    "train[\"split\"] = \"train\"\n",
    "test[\"split\"] = \"test\"\n",
    "dev[\"split\"] = \"dev\"\n",
    "#test = test.sample(30000, replace=False)\n",
    "meta = pd.concat([train, test, dev])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb75cd8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-30 15:00:09.749 I numexpr.utils: Note: detected 96 virtual cores but NumExpr set to maximum of 64, check \"NUMEXPR_MAX_THREADS\" environment variable.\n",
      "2021-06-30 15:00:09.750 I numexpr.utils: Note: NumExpr detected 96 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2021-06-30 15:00:09.750 I numexpr.utils: NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>path</th>\n",
       "      <th>locale</th>\n",
       "      <th>split</th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1486</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>ru</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>1486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56701</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>kz</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>56701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3364</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>ru</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>3364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>110475</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>rw</td>\n",
       "      <td>train</td>\n",
       "      <td>3</td>\n",
       "      <td>110475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45384</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>en</td>\n",
       "      <td>train</td>\n",
       "      <td>2</td>\n",
       "      <td>45384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30751</th>\n",
       "      <td>2677</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>ru</td>\n",
       "      <td>dev</td>\n",
       "      <td>1</td>\n",
       "      <td>2677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30752</th>\n",
       "      <td>881</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>ru</td>\n",
       "      <td>dev</td>\n",
       "      <td>1</td>\n",
       "      <td>881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30753</th>\n",
       "      <td>68709</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>kz</td>\n",
       "      <td>dev</td>\n",
       "      <td>0</td>\n",
       "      <td>68709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30754</th>\n",
       "      <td>249025</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>en</td>\n",
       "      <td>dev</td>\n",
       "      <td>2</td>\n",
       "      <td>249025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30755</th>\n",
       "      <td>2986</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>uk</td>\n",
       "      <td>dev</td>\n",
       "      <td>3</td>\n",
       "      <td>2986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168971 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                               path locale  \\\n",
       "0            1486  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...     ru   \n",
       "1           56701  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...     kz   \n",
       "2            3364  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...     ru   \n",
       "3          110475  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...     rw   \n",
       "4           45384  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...     en   \n",
       "...           ...                                                ...    ...   \n",
       "30751        2677  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...     ru   \n",
       "30752         881  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...     ru   \n",
       "30753       68709  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...     kz   \n",
       "30754      249025  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...     en   \n",
       "30755        2986  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...     uk   \n",
       "\n",
       "       split  target      id  \n",
       "0      train       1    1486  \n",
       "1      train       0   56701  \n",
       "2      train       1    3364  \n",
       "3      train       3  110475  \n",
       "4      train       2   45384  \n",
       "...      ...     ...     ...  \n",
       "30751    dev       1    2677  \n",
       "30752    dev       1     881  \n",
       "30753    dev       0   68709  \n",
       "30754    dev       2  249025  \n",
       "30755    dev       3    2986  \n",
       "\n",
       "[168971 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta.loc[meta[\"locale\"] != \"kz\", \"path\"] = \"/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/\" +  meta.loc[meta[\"locale\"] != \"kz\"][\"locale\"] + \"/clips/\" + meta.loc[meta[\"locale\"] != \"kz\"][\"path\"]\n",
    "targets = {\"kz\": 0, \"ru\": 1, \"en\":2, \"other\":3}\n",
    "meta[\"target\"] = meta[\"locale\"]\n",
    "meta.loc[(meta[\"locale\"] != \"kz\") & (meta[\"locale\"] != \"ru\") & (meta[\"locale\"]!=\"en\"), \"target\"] = \"other\"\n",
    "meta = meta.loc[meta[\"path\"] != \"/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/kz/clips/5f590a130a73c.mp3\"]\n",
    "meta = meta.loc[meta[\"path\"] != \"/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/kz/clips/5ef9bd9ba7029.mp3\"]\n",
    "\n",
    "meta[\"id\"] = meta[\"Unnamed: 0\"].apply(str)\n",
    "meta[\"target\"] = meta[\"target\"].map(targets)\n",
    "\n",
    "meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe56c2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "import math\n",
    "DEVICE = 'cuda'\n",
    "def _get_sample(path, resample=None):\n",
    "  effects = [\n",
    "    [\"remix\", \"1\"]\n",
    "  ]\n",
    "  if resample:\n",
    "    effects.append([\"rate\", f'{resample}'])\n",
    "  return torchaudio.sox_effects.apply_effects_file(path, effects=effects)\n",
    "\n",
    "SAMPLE_RIR_PATH = os.path.join(os.getcwd(), \"rir.wav\")\n",
    "\n",
    "def get_rir_sample(*, resample=None, processed=False):\n",
    "    rir_raw, sample_rate = _get_sample(SAMPLE_RIR_PATH, resample=resample)\n",
    "    if not processed:\n",
    "        return rir_raw, sample_rate\n",
    "    rir = rir_raw[:, int(sample_rate*1.01):int(sample_rate*1.3)]\n",
    "    rir = rir / torch.norm(rir, p=2)\n",
    "    rir = torch.flip(rir, [1])\n",
    "    return rir, sample_rate\n",
    "\n",
    "class AudiosDataset(Dataset):\n",
    "    def __init__(self, paths=None, targets=None, augment=False) -> None:\n",
    "        self.paths = paths\n",
    "        self.targets = targets\n",
    "        self.augment = augment\n",
    "        self.extractor = torch.hub.load('s3prl/s3prl', 'audio_albert').to(DEVICE)\n",
    "        self.rir = get_rir_sample()[0]\n",
    "        \n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> dict:\n",
    "        y, sr = torchaudio.load(self.paths.iloc[idx], normalization=True)\n",
    "        \"\"\"\n",
    "        if self.augment:\n",
    "            effects = [\n",
    "                    [\"lowpass\", \"-1\", \"300\"], \n",
    "                    [\"speed\", f\"{random.uniform(0.7, 1.3)}\"],  # change speed\n",
    "                  ]\n",
    "            y, sr = torchaudio.sox_effects.apply_effects_tensor(\n",
    "                y, sr, effects)\n",
    "        #\n",
    "            \n",
    "        if self.augment:\n",
    "            # augment sound in order to imitate the room change\n",
    "            rir = self.rir[:, int(16000*1.1):int(16000*1.3)]\n",
    "            rir = rir / torch.norm(rir, p=2)\n",
    "            rir = torch.flip(rir, [1])\n",
    "            y = torch.nn.functional.conv1d(y[None, ...], rir[None, ...])[0]\n",
    "        \n",
    "        \"\"\"\n",
    "        y = torchaudio.transforms.Resample(orig_freq=sr, new_freq=16000)(y)\n",
    "        y = torchaudio.transforms.Vad(sample_rate = 16000)(y)\n",
    "\n",
    "        \"\"\"\n",
    "        if self.augment:\n",
    "            y = (0.5)*torch.randn(y.shape)\n",
    "        \"\"\"\n",
    "        fixed_length = 1024\n",
    "        with torch.no_grad():\n",
    "            representation = self.extractor(y.to(DEVICE))[0]\n",
    "        # returning result\n",
    "        representation = representation.permute(1, 0)\n",
    "        if representation.shape[1] < fixed_length:\n",
    "            representation = torch.nn.functional.pad(\n",
    "              representation, (0, fixed_length - representation.shape[1]))\n",
    "        else:\n",
    "            representation = representation[:, :fixed_length]\n",
    "        representation = representation.permute(1, 0)\n",
    "        result = {\"target\":self.targets.iloc[idx], \"representation\":representation}\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3b3e49e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/s3prl_s3prl_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[hubconf] can not import upstream.byol_a.hubconf: No module named 'easydict'... Pass.\n",
      "[hubconf] can not import upstream.decoar.hubconf: No module named 'mxnet'... Pass.\n",
      "[hubconf] can not import upstream.wav2vec2_hug.hubconf: No module named 'transformers'... Pass.\n",
      "[hubconf] can not import upstream.pase.hubconf: No module named 'pase'... Pass.\n",
      "[hubconf] can not import upstream.byol_a.hubconf: No module named 'easydict'... Pass.\n",
      "[hubconf] can not import upstream.decoar.hubconf: No module named 'mxnet'... Pass.\n",
      "[hubconf] can not import upstream.wav2vec2_hug.hubconf: No module named 'transformers'... Pass.\n",
      "[hubconf] can not import upstream.pase.hubconf: No module named 'pase'... Pass.\n",
      "2021-06-30 15:00:12.861 I filelock: Lock 140125655932240 acquired on /root/.cache/torch/hub/s3prl_cache/55805839eb58b56972be4a9994ca99c862d2572cfd74ae26c916e8ced5d45a7a.lock\n",
      "Using cache found in /root/.cache/torch/hub/s3prl_cache/55805839eb58b56972be4a9994ca99c862d2572cfd74ae26c916e8ced5d45a7a\n",
      "for https://www.dropbox.com/s/3wgynxmod77ha1z/states-1000000.ckpt?dl=0\n",
      "2021-06-30 15:00:12.862 I filelock: Lock 140125655932240 released on /root/.cache/torch/hub/s3prl_cache/55805839eb58b56972be4a9994ca99c862d2572cfd74ae26c916e8ced5d45a7a.lock\n",
      "[UpstreamExpert] - Using the default upstream expert config\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.7/site-packages/torchaudio/functional.py:318: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n",
      "  \"At least one mel filterbank has all zero values. \"\n",
      "/root/anaconda3/lib/python3.7/site-packages/torch/functional.py:516: UserWarning: stft will require the return_complex parameter be explicitly  specified in a future PyTorch release. Use return_complex=False  to preserve the current behavior or return_complex=True to return  a complex output. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:653.)\n",
      "  normalized, onesided, return_complex)\n",
      "/root/anaconda3/lib/python3.7/site-packages/torch/functional.py:516: UserWarning: The function torch.rfft is deprecated and will be removed in a future PyTorch release. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.fft or torch.fft.rfft. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:590.)\n",
      "  normalized, onesided, return_complex)\n"
     ]
    }
   ],
   "source": [
    "ds = AudiosDataset(meta[\"path\"], meta[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4b8fd0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[hubconf] can not import upstream.byol_a.hubconf: No module named 'easydict'... Pass.\n",
      "[hubconf] can not import upstream.decoar.hubconf: No module named 'mxnet'... Pass.\n",
      "[hubconf] can not import upstream.wav2vec2_hug.hubconf: No module named 'transformers'... Pass.\n",
      "[hubconf] can not import upstream.pase.hubconf: No module named 'pase'... Pass.\n",
      "2021-06-30 15:00:17.824 I filelock: Lock 140125636039568 acquired on /root/.cache/torch/hub/s3prl_cache/55805839eb58b56972be4a9994ca99c862d2572cfd74ae26c916e8ced5d45a7a.lock\n",
      "Using cache found in /root/.cache/torch/hub/s3prl_cache/55805839eb58b56972be4a9994ca99c862d2572cfd74ae26c916e8ced5d45a7a\n",
      "for https://www.dropbox.com/s/3wgynxmod77ha1z/states-1000000.ckpt?dl=0\n",
      "2021-06-30 15:00:17.825 I filelock: Lock 140125636039568 released on /root/.cache/torch/hub/s3prl_cache/55805839eb58b56972be4a9994ca99c862d2572cfd74ae26c916e8ced5d45a7a.lock\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/s3prl_s3prl_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[UpstreamExpert] - Using the default upstream expert config\n",
      "[hubconf] can not import upstream.byol_a.hubconf: No module named 'easydict'... Pass.\n",
      "[hubconf] can not import upstream.decoar.hubconf: No module named 'mxnet'... Pass.\n",
      "[hubconf] can not import upstream.wav2vec2_hug.hubconf: No module named 'transformers'... Pass.\n",
      "[hubconf] can not import upstream.pase.hubconf: No module named 'pase'... Pass.\n",
      "2021-06-30 15:00:18.082 I filelock: Lock 140125636040144 acquired on /root/.cache/torch/hub/s3prl_cache/55805839eb58b56972be4a9994ca99c862d2572cfd74ae26c916e8ced5d45a7a.lock\n",
      "Using cache found in /root/.cache/torch/hub/s3prl_cache/55805839eb58b56972be4a9994ca99c862d2572cfd74ae26c916e8ced5d45a7a\n",
      "for https://www.dropbox.com/s/3wgynxmod77ha1z/states-1000000.ckpt?dl=0\n",
      "2021-06-30 15:00:18.083 I filelock: Lock 140125636040144 released on /root/.cache/torch/hub/s3prl_cache/55805839eb58b56972be4a9994ca99c862d2572cfd74ae26c916e8ced5d45a7a.lock\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/s3prl_s3prl_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[UpstreamExpert] - Using the default upstream expert config\n",
      "[hubconf] can not import upstream.byol_a.hubconf: No module named 'easydict'... Pass.\n",
      "[hubconf] can not import upstream.decoar.hubconf: No module named 'mxnet'... Pass.\n",
      "[hubconf] can not import upstream.wav2vec2_hug.hubconf: No module named 'transformers'... Pass.\n",
      "[hubconf] can not import upstream.pase.hubconf: No module named 'pase'... Pass.\n",
      "2021-06-30 15:00:18.336 I filelock: Lock 140125635737616 acquired on /root/.cache/torch/hub/s3prl_cache/55805839eb58b56972be4a9994ca99c862d2572cfd74ae26c916e8ced5d45a7a.lock\n",
      "Using cache found in /root/.cache/torch/hub/s3prl_cache/55805839eb58b56972be4a9994ca99c862d2572cfd74ae26c916e8ced5d45a7a\n",
      "for https://www.dropbox.com/s/3wgynxmod77ha1z/states-1000000.ckpt?dl=0\n",
      "2021-06-30 15:00:18.336 I filelock: Lock 140125635737616 released on /root/.cache/torch/hub/s3prl_cache/55805839eb58b56972be4a9994ca99c862d2572cfd74ae26c916e8ced5d45a7a.lock\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/s3prl_s3prl_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[UpstreamExpert] - Using the default upstream expert config\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "train_ds = AudiosDataset(meta.loc[meta[\"split\"]==\"train\"][\"path\"], meta.loc[meta[\"split\"]==\"train\"][\"target\"], augment=True)\n",
    "val_ds = AudiosDataset(meta.loc[meta[\"split\"]==\"dev\"][\"path\"], meta.loc[meta[\"split\"]==\"dev\"][\"target\"])\n",
    "test_ds = AudiosDataset(meta.loc[meta[\"split\"]==\"test\"][\"path\"], meta.loc[meta[\"split\"]==\"test\"][\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7669ee6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "import math\n",
    "import torch\n",
    "DEVICE = 'cuda'\n",
    "def _get_sample(path, resample=None):\n",
    "  effects = [\n",
    "    [\"remix\", \"1\"]\n",
    "  ]\n",
    "  if resample:\n",
    "    effects.append([\"rate\", f'{resample}'])\n",
    "  return torchaudio.sox_effects.apply_effects_file(path, effects=effects)\n",
    "\n",
    "SAMPLE_RIR_PATH = os.path.join(os.getcwd(), \"rir.wav\")\n",
    "\n",
    "def get_rir_sample(*, resample=None, processed=False):\n",
    "    rir_raw, sample_rate = _get_sample(SAMPLE_RIR_PATH, resample=resample)\n",
    "    if not processed:\n",
    "        return rir_raw, sample_rate\n",
    "    rir = rir_raw[:, int(sample_rate*1.01):int(sample_rate*1.3)]\n",
    "    rir = rir / torch.norm(rir, p=2)\n",
    "    rir = torch.flip(rir, [1])\n",
    "    return rir, sample_rate\n",
    "\n",
    "class AudiosDataset(Dataset):\n",
    "    def __init__(self, paths=None, targets=None, augment=False) -> None:\n",
    "        self.paths = paths\n",
    "        self.targets = targets\n",
    "        self.augment = augment\n",
    "        self.extractor = torch.hub.load('s3prl/s3prl', 'audio_albert').to(DEVICE)\n",
    "        self.rir = get_rir_sample()[0]\n",
    "        \n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> dict:\n",
    "        y, sr = torchaudio.load(self.paths.iloc[idx], normalization=True)\n",
    "        \"\"\"\n",
    "        if self.augment:\n",
    "            effects = [\n",
    "                    [\"lowpass\", \"-1\", \"300\"], \n",
    "                    [\"speed\", f\"{random.uniform(0.7, 1.3)}\"],  # change speed\n",
    "                  ]\n",
    "            y, sr = torchaudio.sox_effects.apply_effects_tensor(\n",
    "                y, sr, effects)\n",
    "        #\n",
    "            \n",
    "        if self.augment:\n",
    "            # augment sound in order to imitate the room change\n",
    "            rir = self.rir[:, int(16000*1.1):int(16000*1.3)]\n",
    "            rir = rir / torch.norm(rir, p=2)\n",
    "            rir = torch.flip(rir, [1])\n",
    "            y = torch.nn.functional.conv1d(y[None, ...], rir[None, ...])[0]\n",
    "        \n",
    "        \"\"\"\n",
    "        y = torchaudio.transforms.Resample(orig_freq=sr, new_freq=16000)(y)\n",
    "        y = torchaudio.transforms.Vad(sample_rate = 16000)(y)\n",
    "\n",
    "        \"\"\"\n",
    "        if self.augment:\n",
    "            y = (0.5)*torch.randn(y.shape)\n",
    "        \"\"\"\n",
    "        fixed_length = 16000 * 12\n",
    "        \n",
    "        # returning result\n",
    "        if y.shape[1] < fixed_length:\n",
    "            y = torch.nn.functional.pad(\n",
    "              y, (0, fixed_length - y.shape[1]))\n",
    "        else:\n",
    "            y = y[:, :fixed_length]\n",
    "        result = {\"target\":self.targets.iloc[idx], \"representation\":y}\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b7b99f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[hubconf] can not import upstream.byol_a.hubconf: No module named 'easydict'... Pass.\n",
      "[hubconf] can not import upstream.decoar.hubconf: No module named 'mxnet'... Pass.\n",
      "[hubconf] can not import upstream.wav2vec2_hug.hubconf: No module named 'transformers'... Pass.\n",
      "[hubconf] can not import upstream.pase.hubconf: No module named 'pase'... Pass.\n",
      "2021-06-30 15:00:18.562 I filelock: Lock 140125635891472 acquired on /root/.cache/torch/hub/s3prl_cache/55805839eb58b56972be4a9994ca99c862d2572cfd74ae26c916e8ced5d45a7a.lock\n",
      "Using cache found in /root/.cache/torch/hub/s3prl_cache/55805839eb58b56972be4a9994ca99c862d2572cfd74ae26c916e8ced5d45a7a\n",
      "for https://www.dropbox.com/s/3wgynxmod77ha1z/states-1000000.ckpt?dl=0\n",
      "2021-06-30 15:00:18.563 I filelock: Lock 140125635891472 released on /root/.cache/torch/hub/s3prl_cache/55805839eb58b56972be4a9994ca99c862d2572cfd74ae26c916e8ced5d45a7a.lock\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/s3prl_s3prl_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[UpstreamExpert] - Using the default upstream expert config\n",
      "torch.Size([1, 192000])\n"
     ]
    }
   ],
   "source": [
    "ds = AudiosDataset(meta[\"path\"], meta[\"target\"])\n",
    "for i in ds:\n",
    "    print(i['representation'].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "991808c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[hubconf] can not import upstream.byol_a.hubconf: No module named 'easydict'... Pass.\n",
      "[hubconf] can not import upstream.decoar.hubconf: No module named 'mxnet'... Pass.\n",
      "[hubconf] can not import upstream.wav2vec2_hug.hubconf: No module named 'transformers'... Pass.\n",
      "[hubconf] can not import upstream.pase.hubconf: No module named 'pase'... Pass.\n",
      "2021-06-30 15:00:19.085 I filelock: Lock 140125635957072 acquired on /root/.cache/torch/hub/s3prl_cache/55805839eb58b56972be4a9994ca99c862d2572cfd74ae26c916e8ced5d45a7a.lock\n",
      "Using cache found in /root/.cache/torch/hub/s3prl_cache/55805839eb58b56972be4a9994ca99c862d2572cfd74ae26c916e8ced5d45a7a\n",
      "for https://www.dropbox.com/s/3wgynxmod77ha1z/states-1000000.ckpt?dl=0\n",
      "2021-06-30 15:00:19.086 I filelock: Lock 140125635957072 released on /root/.cache/torch/hub/s3prl_cache/55805839eb58b56972be4a9994ca99c862d2572cfd74ae26c916e8ced5d45a7a.lock\n",
      "[UpstreamExpert] - Using the default upstream expert config\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/s3prl_s3prl_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[hubconf] can not import upstream.byol_a.hubconf: No module named 'easydict'... Pass.\n",
      "[hubconf] can not import upstream.decoar.hubconf: No module named 'mxnet'... Pass.\n",
      "[hubconf] can not import upstream.wav2vec2_hug.hubconf: No module named 'transformers'... Pass.\n",
      "[hubconf] can not import upstream.pase.hubconf: No module named 'pase'... Pass.\n",
      "2021-06-30 15:00:19.352 I filelock: Lock 140125656593744 acquired on /root/.cache/torch/hub/s3prl_cache/55805839eb58b56972be4a9994ca99c862d2572cfd74ae26c916e8ced5d45a7a.lock\n",
      "Using cache found in /root/.cache/torch/hub/s3prl_cache/55805839eb58b56972be4a9994ca99c862d2572cfd74ae26c916e8ced5d45a7a\n",
      "for https://www.dropbox.com/s/3wgynxmod77ha1z/states-1000000.ckpt?dl=0\n",
      "2021-06-30 15:00:19.353 I filelock: Lock 140125656593744 released on /root/.cache/torch/hub/s3prl_cache/55805839eb58b56972be4a9994ca99c862d2572cfd74ae26c916e8ced5d45a7a.lock\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/s3prl_s3prl_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[UpstreamExpert] - Using the default upstream expert config\n",
      "[hubconf] can not import upstream.byol_a.hubconf: No module named 'easydict'... Pass.\n",
      "[hubconf] can not import upstream.decoar.hubconf: No module named 'mxnet'... Pass.\n",
      "[hubconf] can not import upstream.wav2vec2_hug.hubconf: No module named 'transformers'... Pass.\n",
      "[hubconf] can not import upstream.pase.hubconf: No module named 'pase'... Pass.\n",
      "2021-06-30 15:00:19.597 I filelock: Lock 140125635959120 acquired on /root/.cache/torch/hub/s3prl_cache/55805839eb58b56972be4a9994ca99c862d2572cfd74ae26c916e8ced5d45a7a.lock\n",
      "Using cache found in /root/.cache/torch/hub/s3prl_cache/55805839eb58b56972be4a9994ca99c862d2572cfd74ae26c916e8ced5d45a7a\n",
      "for https://www.dropbox.com/s/3wgynxmod77ha1z/states-1000000.ckpt?dl=0\n",
      "2021-06-30 15:00:19.598 I filelock: Lock 140125635959120 released on /root/.cache/torch/hub/s3prl_cache/55805839eb58b56972be4a9994ca99c862d2572cfd74ae26c916e8ced5d45a7a.lock\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/s3prl_s3prl_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[UpstreamExpert] - Using the default upstream expert config\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "train_ds = AudiosDataset(meta.loc[meta[\"split\"]==\"train\"][\"path\"], meta.loc[meta[\"split\"]==\"train\"][\"target\"], augment=True)\n",
    "val_ds = AudiosDataset(meta.loc[meta[\"split\"]==\"dev\"][\"path\"], meta.loc[meta[\"split\"]==\"dev\"][\"target\"])\n",
    "test_ds = AudiosDataset(meta.loc[meta[\"split\"]==\"test\"][\"path\"], meta.loc[meta[\"split\"]==\"test\"][\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "774930f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "num_workers = 10\n",
    "loaders = {\n",
    "    \"train\": DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        drop_last=True,\n",
    "    ),\n",
    "    \"valid\": DataLoader(\n",
    "        val_ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        drop_last=True,\n",
    "    ),\n",
    "    \"test\":DataLoader(\n",
    "        test_ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        drop_last=True,\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d46de1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[hubconf] can not import upstream.byol_a.hubconf: No module named 'easydict'... Pass.\n",
      "[hubconf] can not import upstream.decoar.hubconf: No module named 'mxnet'... Pass.\n",
      "[hubconf] can not import upstream.wav2vec2_hug.hubconf: No module named 'transformers'... Pass.\n",
      "[hubconf] can not import upstream.pase.hubconf: No module named 'pase'... Pass.\n",
      "2021-06-30 15:00:19.811 I filelock: Lock 140129131183568 acquired on /root/.cache/torch/hub/s3prl_cache/55805839eb58b56972be4a9994ca99c862d2572cfd74ae26c916e8ced5d45a7a.lock\n",
      "Using cache found in /root/.cache/torch/hub/s3prl_cache/55805839eb58b56972be4a9994ca99c862d2572cfd74ae26c916e8ced5d45a7a\n",
      "for https://www.dropbox.com/s/3wgynxmod77ha1z/states-1000000.ckpt?dl=0\n",
      "2021-06-30 15:00:19.812 I filelock: Lock 140129131183568 released on /root/.cache/torch/hub/s3prl_cache/55805839eb58b56972be4a9994ca99c862d2572cfd74ae26c916e8ced5d45a7a.lock\n",
      "[UpstreamExpert] - Using the default upstream expert config\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/s3prl_s3prl_master\n"
     ]
    }
   ],
   "source": [
    "m = torch.hub.load('s3prl/s3prl', 'audio_albert').to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2bf509b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, extractor):\n",
    "        super().__init__()\n",
    "        self.extractor = extractor\n",
    "        self.rnn = nn.LSTM(input_size=768, hidden_size=512, num_layers=5, bidirectional=True, batch_first=True, dropout=0.7)\n",
    "        self.classifier = nn.Sequential(\n",
    "                    nn.Linear(1024, 512),\n",
    "                    nn.ReLU(),\n",
    "                    nn.BatchNorm1d(512),\n",
    "                    nn.Dropout(0.5),\n",
    "                    nn.Linear(512, 4),\n",
    "                    )\n",
    "    def forward(self, x):\n",
    "        features = self.extractor(torch.squeeze(x))\n",
    "        features = torch.stack(features)\n",
    "        res, _ = self.rnn(features)\n",
    "        res = self.classifier(res[:, -1, :])\n",
    "        return F.log_softmax(res, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9907b8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Classifier(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cdffdfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train(model, opt, scheduler, loss_fn, epochs, data_tr, data_val, max_stable=5):\n",
    "    best_val_loss = 1e9\n",
    "    counter = 0\n",
    "    for epoch in range(epochs):\n",
    "        #tic = time()\n",
    "        print('* Epoch %d/%d' % (epoch+1, epochs))\n",
    "\n",
    "        avg_loss = 0\n",
    "        model.train()  # train mode\n",
    "        for batch in tqdm(data_tr):\n",
    "            loss = 0\n",
    "            # data to device\n",
    "            X_batch, Y_batch = batch[\"representation\"], batch[\"target\"]\n",
    "            #print(X_batch.shape)\n",
    "            X_batch = X_batch.to(DEVICE)\n",
    "            Y_batch = Y_batch.to(DEVICE)\n",
    "            # set parameter gradients to zero\n",
    "            opt.zero_grad()\n",
    "            # forward\n",
    "            Y_pred = model(X_batch)\n",
    "            #print(Y_pred)\n",
    "            loss = loss_fn(Y_pred, Y_batch)# forward-pass\n",
    "            loss.backward()  # backward-pass\n",
    "            opt.step()  # update weights\n",
    "            if not scheduler is None:\n",
    "                scheduler.step()\n",
    "            # calculate loss to show the user\n",
    "            avg_loss += loss / len(data_tr)\n",
    "      #  toc = time()\n",
    "        print('loss: %f' % avg_loss)\n",
    "        # show intermediate results\n",
    "        model.eval()  # testing mode\n",
    "        val_loss = 0\n",
    "        print(\"start validation\")\n",
    "        for v_b in tqdm(data_val):\n",
    "            X_val, Y_val = v_b[\"representation\"], v_b[\"target\"]\n",
    "            Y_hat = model(X_val.to(DEVICE)).detach().cpu()# detach and put into cpu\n",
    "            val_loss += loss_fn(Y_hat, Y_val)\n",
    "        val_loss /= len(data_val)\n",
    "        print( f\"validation loss: {val_loss}\")\n",
    "        if val_loss <= best_val_loss and val_loss > 0:\n",
    "            counter = 0\n",
    "            print(\"Save new model!\")\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), f'best_model.h5')\n",
    "        else:\n",
    "            counter += 1\n",
    "        if counter == max_stable:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "017af0f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('best_model.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0caf5c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10306 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10306 [00:52<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-0d21e9cd1f95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0moptimaizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamW\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5e-5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCosineAnnealingWarmRestarts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimaizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT_0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT_mult\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meta_min\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimaizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"valid\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-d461e4fd275e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, opt, scheduler, loss_fn, epochs, data_tr, data_val, max_stable)\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;31m# forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mY_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0;31m#print(Y_pred)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# forward-pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-4b37fd3dc960>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     14\u001b[0m                     )\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/torch/hub/s3prl_s3prl_master/upstream/mockingjay/expert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, wavs)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mwav_lengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwav\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mwav\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwavs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwavs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (batch_size, extracted_seqlen, feature_dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mwav_lengths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/torch/hub/s3prl_s3prl_master/upstream/mockingjay/builder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    282\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/torch/hub/s3prl_s3prl_master/upstream/mockingjay/builder.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;31m# forward the whole sequence at once\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_input_length\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minput_len\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_input_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m             \u001b[0mfeat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_enc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_input_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# x shape: (B, T, D)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_enc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_all_encoded_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweighted_sum\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_layer\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (B, T, D) or # (N, B, T, D)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;31m# forward the sequence in chunks then concat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/torch/hub/s3prl_s3prl_master/upstream/mockingjay/builder.py\u001b[0m in \u001b[0;36mprocess_input_data\u001b[0;34m(self, feat)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mseq_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0mpos_enc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mposition_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (seq_len, hidden_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m         \u001b[0mattn_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (batch_size, seq_len)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/torch/hub/s3prl_s3prl_master/upstream/mockingjay/builder.py\u001b[0m in \u001b[0;36mposition_encoding\u001b[0;34m(seq_len, hidden_size)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mposition_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[0;34m\"\"\" position encoding table \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m     \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_sinusoid_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m     \u001b[0;31m# no extra CPU and GPU memory allocation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;31m# after getting the (seq_len, hidden_size) tensor, one should first put\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/torch/hub/s3prl_s3prl_master/upstream/mockingjay/builder.py\u001b[0m in \u001b[0;36mget_sinusoid_table\u001b[0;34m(hidden_size)\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_posi_angle_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_cal_angle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhid_j\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mhid_j\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m     \u001b[0msinusoid_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_get_posi_angle_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_i\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpos_i\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAX_SEQLEN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m     \u001b[0msinusoid_table\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msinusoid_table\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# dim 2i\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[0msinusoid_table\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msinusoid_table\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# dim 2i+1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/torch/hub/s3prl_s3prl_master/upstream/mockingjay/builder.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_posi_angle_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_cal_angle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhid_j\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mhid_j\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m     \u001b[0msinusoid_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_get_posi_angle_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_i\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpos_i\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAX_SEQLEN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m     \u001b[0msinusoid_table\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msinusoid_table\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# dim 2i\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[0msinusoid_table\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msinusoid_table\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# dim 2i+1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/torch/hub/s3prl_s3prl_master/upstream/mockingjay/builder.py\u001b[0m in \u001b[0;36m_get_posi_angle_vec\u001b[0;34m(position)\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mposition\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhid_idx\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_posi_angle_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_cal_angle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhid_j\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mhid_j\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m     \u001b[0msinusoid_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_get_posi_angle_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_i\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpos_i\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAX_SEQLEN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0msinusoid_table\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msinusoid_table\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# dim 2i\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/torch/hub/s3prl_s3prl_master/upstream/mockingjay/builder.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mposition\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhid_idx\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_posi_angle_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_cal_angle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhid_j\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mhid_j\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m     \u001b[0msinusoid_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_get_posi_angle_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_i\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpos_i\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAX_SEQLEN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0msinusoid_table\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msinusoid_table\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# dim 2i\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/torch/hub/s3prl_s3prl_master/upstream/mockingjay/builder.py\u001b[0m in \u001b[0;36m_cal_angle\u001b[0;34m(position, hid_idx)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_sinusoid_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_cal_angle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhid_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mposition\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhid_idx\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_posi_angle_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_cal_angle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhid_j\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mhid_j\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "DEVICE = 'cuda'\n",
    "max_epochs = 100\n",
    "model = model.to(DEVICE)\n",
    "#torch.cuda.empty_cache()\n",
    "loss_fn =  nn.CrossEntropyLoss()\n",
    "optimaizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimaizer, T_0=5, T_mult=1, eta_min=1e-8, last_epoch=-1)\n",
    "train(model, optimaizer,scheduler, loss_fn, max_epochs, loaders[\"train\"], loaders[\"valid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2964f32c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6971/6971 [54:59<00:00,  2.11it/s]  \n"
     ]
    }
   ],
   "source": [
    "true_labels = []\n",
    "predicted_labels = []\n",
    "for batch in tqdm(loaders[\"test\"]):\n",
    "    model.eval()\n",
    "    prediction = model(batch[\"representation\"].to(DEVICE)).detach().cpu()\n",
    "    predicted_labels.extend(torch.argmax(prediction, dim=1).tolist())\n",
    "    true_labels.extend(batch[\"target\"].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1baec01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          kz       1.00      1.00      1.00     17341\n",
      "          ru       0.95      0.84      0.89     10379\n",
      "          en       0.93      0.93      0.93     12964\n",
      "       other       0.85      0.92      0.88     15084\n",
      "\n",
      "    accuracy                           0.93     55768\n",
      "   macro avg       0.93      0.92      0.93     55768\n",
      "weighted avg       0.93      0.93      0.93     55768\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(true_labels, predicted_labels, target_names=list(targets.keys()), labels=range(4))\n",
    "print(report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6972f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9f6bec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "791d9df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          kz       1.00      1.00      1.00     17337\n",
      "          ru       0.67      0.33      0.44     10374\n",
      "          en       0.65      0.18      0.29     12956\n",
      "       other       0.45      0.89      0.60     15077\n",
      "\n",
      "    accuracy                           0.66     55744\n",
      "   macro avg       0.69      0.60      0.58     55744\n",
      "weighted avg       0.71      0.66      0.62     55744\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(true_labels, predicted_labels, target_names=list(targets.keys()), labels=range(4))\n",
    "print(report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be520f7",
   "metadata": {},
   "source": [
    "##  Vox test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4920f726",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np_rng = np.random.default_rng(1)\n",
    "\n",
    "\n",
    "import urllib.parse\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "import os\n",
    "\n",
    "from lidbox.meta import (\n",
    "    common_voice,\n",
    "    generate_label2target,\n",
    "    verify_integrity,\n",
    "    read_audio_durations,\n",
    "    random_oversampling_on_split\n",
    ")\n",
    "\n",
    "\n",
    "test = pd.read_csv(\"/tf/datasets/new_test.tsv\", sep=\"\\t\")\n",
    "\n",
    "test[\"path\"] = test[\"path\"].apply(lambda x: x[:-3] + \"mp3\")\n",
    "\n",
    "test[\"split\"] = \"test\"\n",
    "meta = pd.concat([test])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ef2bd2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta.loc[((meta[\"locale\"] != \"kz\") & ~(((meta[\"split\"] == \"dev\") | (meta[\"split\"] == \"test\")) & ((meta[\"locale\"] == \"ru\") | (meta[\"locale\"] == \"kz\") | (meta[\"locale\"] == \"en\")))), \"path\"] = \"/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/\" + meta.loc[((meta[\"locale\"] != \"kz\") & ~(((meta[\"split\"] == \"dev\") | (meta[\"split\"] == \"test\")) & ((meta[\"locale\"] == \"ru\") | (meta[\"locale\"] == \"kz\") | (meta[\"locale\"] == \"en\"))))][\"locale\"]  + \"/clips/\" + meta.loc[((meta[\"locale\"] != \"kz\") & ~(((meta[\"split\"] == \"dev\") | (meta[\"split\"] == \"test\")) & ((meta[\"locale\"] == \"ru\") | (meta[\"locale\"] == \"kz\") | (meta[\"locale\"] == \"en\"))))][\"path\"]\n",
    "targets = {\"kz\": 0, \"ru\": 1, \"en\":2, \"other\":3}\n",
    "meta[\"target\"] = meta[\"locale\"]\n",
    "meta.loc[(meta[\"locale\"] != \"kz\") & (meta[\"locale\"] != \"ru\") & (meta[\"locale\"]!=\"en\"), \"target\"] = \"other\"\n",
    "meta = meta.loc[meta[\"path\"] != \"/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/kz/clips/5f590a130a73c.mp3\"]\n",
    "meta = meta.loc[meta[\"path\"] != \"/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/kz/clips/5ef9bd9ba7029.mp3\"]\n",
    "\n",
    "meta[\"id\"] = meta[\"Unnamed: 0\"].apply(str)\n",
    "meta[\"target\"] = meta[\"target\"].map(targets)\n",
    "\n",
    "\n",
    "workdir = \"/tf/datasets/transformer\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "441726da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       /tf/datasets/vox/en_test/shrDRhToGpY__U__S133-...\n",
       "1       /tf/datasets/vox/en_test/mzfg0RGJnV8__U__S123-...\n",
       "2       /tf/datasets/vox/en_test/-_PPCH3y0eE__U__S1---...\n",
       "3       /tf/datasets/vox/en_test/DQMxvGYyu6Q__U__S0---...\n",
       "4       /tf/datasets/vox/en_test/x4lfSc7PrB0__U__S0---...\n",
       "                              ...                        \n",
       "9995    /tf/datasets/vox/en_test/KLiy94kfZI4__U__S133-...\n",
       "9996    /tf/datasets/vox/en_test/YTlliEr5LOA__U__S113-...\n",
       "9997    /tf/datasets/vox/en_test/bSs0gNq6Kkc__U__S0---...\n",
       "9998    /tf/datasets/vox/en_test/Da7c-BY6MDA__U__S2---...\n",
       "9999    /tf/datasets/vox/en_test/VWvPndMo1F8__U__S24--...\n",
       "Name: path, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta.loc[(meta[\"split\"] == \"test\") & (meta[\"locale\"] == \"ru\"), \"path\"] = meta.loc[(meta[\"split\"] == \"test\") & (meta[\"locale\"] == \"ru\")][\"path\"].apply(lambda x: f\"/tf/datasets/vox/ru_test/{x}\")\n",
    "meta.loc[(meta[\"split\"] == \"test\") & (meta[\"locale\"] == \"ru\"), \"path\"]\n",
    "meta.loc[(meta[\"split\"] == \"test\") & (meta[\"locale\"] == \"kz\"), \"path\"] = meta.loc[(meta[\"split\"] == \"test\") & (meta[\"locale\"] == \"kz\")][\"path\"].apply(lambda x: f\"/tf/datasets/vox/kz_test/{x}\")\n",
    "meta.loc[(meta[\"split\"] == \"test\") & (meta[\"locale\"] == \"kz\"), \"path\"] \n",
    "meta.loc[(meta[\"split\"] == \"test\") & (meta[\"locale\"] == \"en\"), \"path\"] = meta.loc[(meta[\"split\"] == \"test\") & (meta[\"locale\"] == \"en\")][\"path\"].apply(lambda x: f\"/tf/datasets/vox/en_test/{x}\")\n",
    "meta.loc[(meta[\"split\"] == \"test\") & (meta[\"locale\"] == \"en\"), \"path\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d6ea0381",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta.loc[meta[\"split\"]==\"test\", \"Unnamed: 0\"] = meta.loc[meta[\"split\"]==\"test\"][\"path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0b65537f",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta[\"id\"] = meta[\"Unnamed: 0\"].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "06e4b6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta.loc[meta[\"split\"] == \"test\", \"id\"] = meta.loc[meta[\"split\"] == \"test\"][\"path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b5d73faf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>locale</th>\n",
       "      <th>split</th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/en_test/shrDRhToGpY__U__S133---0944.430-0958.260.mp3</th>\n",
       "      <td>/tf/datasets/vox/en_test/shrDRhToGpY__U__S133-...</td>\n",
       "      <td>en</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>/tf/datasets/vox/en_test/shrDRhToGpY__U__S133-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/en_test/mzfg0RGJnV8__U__S123---0427.020-0444.670.mp3</th>\n",
       "      <td>/tf/datasets/vox/en_test/mzfg0RGJnV8__U__S123-...</td>\n",
       "      <td>en</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>/tf/datasets/vox/en_test/mzfg0RGJnV8__U__S123-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/en_test/-_PPCH3y0eE__U__S1---0398.760-0403.940.mp3</th>\n",
       "      <td>/tf/datasets/vox/en_test/-_PPCH3y0eE__U__S1---...</td>\n",
       "      <td>en</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>/tf/datasets/vox/en_test/-_PPCH3y0eE__U__S1---...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/en_test/DQMxvGYyu6Q__U__S0---1473.480-1485.720.mp3</th>\n",
       "      <td>/tf/datasets/vox/en_test/DQMxvGYyu6Q__U__S0---...</td>\n",
       "      <td>en</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>/tf/datasets/vox/en_test/DQMxvGYyu6Q__U__S0---...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/en_test/x4lfSc7PrB0__U__S0---0125.230-0140.900.mp3</th>\n",
       "      <td>/tf/datasets/vox/en_test/x4lfSc7PrB0__U__S0---...</td>\n",
       "      <td>en</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>/tf/datasets/vox/en_test/x4lfSc7PrB0__U__S0---...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/it/clips/common_voice_it_20015623.mp3</th>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>it</td>\n",
       "      <td>test</td>\n",
       "      <td>3</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/uk/clips/common_voice_uk_23554602.mp3</th>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>uk</td>\n",
       "      <td>test</td>\n",
       "      <td>3</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/tr/clips/common_voice_tr_20416266.mp3</th>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>tr</td>\n",
       "      <td>test</td>\n",
       "      <td>3</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/it/clips/common_voice_it_20263173.mp3</th>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>it</td>\n",
       "      <td>test</td>\n",
       "      <td>3</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/es/clips/common_voice_es_20283066.mp3</th>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>es</td>\n",
       "      <td>test</td>\n",
       "      <td>3</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51137 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                 path  \\\n",
       "Unnamed: 0                                                                                              \n",
       "/tf/datasets/vox/en_test/shrDRhToGpY__U__S133--...  /tf/datasets/vox/en_test/shrDRhToGpY__U__S133-...   \n",
       "/tf/datasets/vox/en_test/mzfg0RGJnV8__U__S123--...  /tf/datasets/vox/en_test/mzfg0RGJnV8__U__S123-...   \n",
       "/tf/datasets/vox/en_test/-_PPCH3y0eE__U__S1---0...  /tf/datasets/vox/en_test/-_PPCH3y0eE__U__S1---...   \n",
       "/tf/datasets/vox/en_test/DQMxvGYyu6Q__U__S0---1...  /tf/datasets/vox/en_test/DQMxvGYyu6Q__U__S0---...   \n",
       "/tf/datasets/vox/en_test/x4lfSc7PrB0__U__S0---0...  /tf/datasets/vox/en_test/x4lfSc7PrB0__U__S0---...   \n",
       "...                                                                                               ...   \n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...   \n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...   \n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...   \n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...   \n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...   \n",
       "\n",
       "                                                   locale split  target  \\\n",
       "Unnamed: 0                                                                \n",
       "/tf/datasets/vox/en_test/shrDRhToGpY__U__S133--...     en  test       2   \n",
       "/tf/datasets/vox/en_test/mzfg0RGJnV8__U__S123--...     en  test       2   \n",
       "/tf/datasets/vox/en_test/-_PPCH3y0eE__U__S1---0...     en  test       2   \n",
       "/tf/datasets/vox/en_test/DQMxvGYyu6Q__U__S0---1...     en  test       2   \n",
       "/tf/datasets/vox/en_test/x4lfSc7PrB0__U__S0---0...     en  test       2   \n",
       "...                                                   ...   ...     ...   \n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...     it  test       3   \n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...     uk  test       3   \n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...     tr  test       3   \n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...     it  test       3   \n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...     es  test       3   \n",
       "\n",
       "                                                                                                   id  \n",
       "Unnamed: 0                                                                                             \n",
       "/tf/datasets/vox/en_test/shrDRhToGpY__U__S133--...  /tf/datasets/vox/en_test/shrDRhToGpY__U__S133-...  \n",
       "/tf/datasets/vox/en_test/mzfg0RGJnV8__U__S123--...  /tf/datasets/vox/en_test/mzfg0RGJnV8__U__S123-...  \n",
       "/tf/datasets/vox/en_test/-_PPCH3y0eE__U__S1---0...  /tf/datasets/vox/en_test/-_PPCH3y0eE__U__S1---...  \n",
       "/tf/datasets/vox/en_test/DQMxvGYyu6Q__U__S0---1...  /tf/datasets/vox/en_test/DQMxvGYyu6Q__U__S0---...  \n",
       "/tf/datasets/vox/en_test/x4lfSc7PrB0__U__S0---0...  /tf/datasets/vox/en_test/x4lfSc7PrB0__U__S0---...  \n",
       "...                                                                                               ...  \n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...  \n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...  \n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...  \n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...  \n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...  \n",
       "\n",
       "[51137 rows x 5 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta = meta.set_index(\"Unnamed: 0\")\n",
    "meta.loc[meta[\"split\"]==\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bf7d14a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta.loc[meta[\"split\"] == \"test\"] = meta.loc[(meta[\"split\"] == \"test\") & (meta[\"target\"] != 3)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a531fa29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>locale</th>\n",
       "      <th>split</th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/en_test/shrDRhToGpY__U__S133---0944.430-0958.260.mp3</th>\n",
       "      <td>/tf/datasets/vox/en_test/shrDRhToGpY__U__S133-...</td>\n",
       "      <td>en</td>\n",
       "      <td>test</td>\n",
       "      <td>2.0</td>\n",
       "      <td>/tf/datasets/vox/en_test/shrDRhToGpY__U__S133-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/en_test/mzfg0RGJnV8__U__S123---0427.020-0444.670.mp3</th>\n",
       "      <td>/tf/datasets/vox/en_test/mzfg0RGJnV8__U__S123-...</td>\n",
       "      <td>en</td>\n",
       "      <td>test</td>\n",
       "      <td>2.0</td>\n",
       "      <td>/tf/datasets/vox/en_test/mzfg0RGJnV8__U__S123-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/en_test/-_PPCH3y0eE__U__S1---0398.760-0403.940.mp3</th>\n",
       "      <td>/tf/datasets/vox/en_test/-_PPCH3y0eE__U__S1---...</td>\n",
       "      <td>en</td>\n",
       "      <td>test</td>\n",
       "      <td>2.0</td>\n",
       "      <td>/tf/datasets/vox/en_test/-_PPCH3y0eE__U__S1---...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/en_test/DQMxvGYyu6Q__U__S0---1473.480-1485.720.mp3</th>\n",
       "      <td>/tf/datasets/vox/en_test/DQMxvGYyu6Q__U__S0---...</td>\n",
       "      <td>en</td>\n",
       "      <td>test</td>\n",
       "      <td>2.0</td>\n",
       "      <td>/tf/datasets/vox/en_test/DQMxvGYyu6Q__U__S0---...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/en_test/x4lfSc7PrB0__U__S0---0125.230-0140.900.mp3</th>\n",
       "      <td>/tf/datasets/vox/en_test/x4lfSc7PrB0__U__S0---...</td>\n",
       "      <td>en</td>\n",
       "      <td>test</td>\n",
       "      <td>2.0</td>\n",
       "      <td>/tf/datasets/vox/en_test/x4lfSc7PrB0__U__S0---...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/kz_test/rCpb0p_lyxI__U__S25---0107.830-0127.780.mp3</th>\n",
       "      <td>/tf/datasets/vox/kz_test/rCpb0p_lyxI__U__S25--...</td>\n",
       "      <td>kz</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/tf/datasets/vox/kz_test/rCpb0p_lyxI__U__S25--...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/kz_test/BkLVX9wf2YI__U__S26---0236.830-0241.550.mp3</th>\n",
       "      <td>/tf/datasets/vox/kz_test/BkLVX9wf2YI__U__S26--...</td>\n",
       "      <td>kz</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/tf/datasets/vox/kz_test/BkLVX9wf2YI__U__S26--...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/kz_test/RqdH-JD8TpM__U__S78---0466.720-0470.860.mp3</th>\n",
       "      <td>/tf/datasets/vox/kz_test/RqdH-JD8TpM__U__S78--...</td>\n",
       "      <td>kz</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/tf/datasets/vox/kz_test/RqdH-JD8TpM__U__S78--...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/kz_test/oCjW4Jy6azE__U__S110---0669.320-0675.220.mp3</th>\n",
       "      <td>/tf/datasets/vox/kz_test/oCjW4Jy6azE__U__S110-...</td>\n",
       "      <td>kz</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/tf/datasets/vox/kz_test/oCjW4Jy6azE__U__S110-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/kz_test/cwyX-Vjxep4__U__S30---0302.770-0318.540.mp3</th>\n",
       "      <td>/tf/datasets/vox/kz_test/cwyX-Vjxep4__U__S30--...</td>\n",
       "      <td>kz</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/tf/datasets/vox/kz_test/cwyX-Vjxep4__U__S30--...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36053 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                 path  \\\n",
       "Unnamed: 0                                                                                              \n",
       "/tf/datasets/vox/en_test/shrDRhToGpY__U__S133--...  /tf/datasets/vox/en_test/shrDRhToGpY__U__S133-...   \n",
       "/tf/datasets/vox/en_test/mzfg0RGJnV8__U__S123--...  /tf/datasets/vox/en_test/mzfg0RGJnV8__U__S123-...   \n",
       "/tf/datasets/vox/en_test/-_PPCH3y0eE__U__S1---0...  /tf/datasets/vox/en_test/-_PPCH3y0eE__U__S1---...   \n",
       "/tf/datasets/vox/en_test/DQMxvGYyu6Q__U__S0---1...  /tf/datasets/vox/en_test/DQMxvGYyu6Q__U__S0---...   \n",
       "/tf/datasets/vox/en_test/x4lfSc7PrB0__U__S0---0...  /tf/datasets/vox/en_test/x4lfSc7PrB0__U__S0---...   \n",
       "...                                                                                               ...   \n",
       "/tf/datasets/vox/kz_test/rCpb0p_lyxI__U__S25---...  /tf/datasets/vox/kz_test/rCpb0p_lyxI__U__S25--...   \n",
       "/tf/datasets/vox/kz_test/BkLVX9wf2YI__U__S26---...  /tf/datasets/vox/kz_test/BkLVX9wf2YI__U__S26--...   \n",
       "/tf/datasets/vox/kz_test/RqdH-JD8TpM__U__S78---...  /tf/datasets/vox/kz_test/RqdH-JD8TpM__U__S78--...   \n",
       "/tf/datasets/vox/kz_test/oCjW4Jy6azE__U__S110--...  /tf/datasets/vox/kz_test/oCjW4Jy6azE__U__S110-...   \n",
       "/tf/datasets/vox/kz_test/cwyX-Vjxep4__U__S30---...  /tf/datasets/vox/kz_test/cwyX-Vjxep4__U__S30--...   \n",
       "\n",
       "                                                   locale split  target  \\\n",
       "Unnamed: 0                                                                \n",
       "/tf/datasets/vox/en_test/shrDRhToGpY__U__S133--...     en  test     2.0   \n",
       "/tf/datasets/vox/en_test/mzfg0RGJnV8__U__S123--...     en  test     2.0   \n",
       "/tf/datasets/vox/en_test/-_PPCH3y0eE__U__S1---0...     en  test     2.0   \n",
       "/tf/datasets/vox/en_test/DQMxvGYyu6Q__U__S0---1...     en  test     2.0   \n",
       "/tf/datasets/vox/en_test/x4lfSc7PrB0__U__S0---0...     en  test     2.0   \n",
       "...                                                   ...   ...     ...   \n",
       "/tf/datasets/vox/kz_test/rCpb0p_lyxI__U__S25---...     kz  test     0.0   \n",
       "/tf/datasets/vox/kz_test/BkLVX9wf2YI__U__S26---...     kz  test     0.0   \n",
       "/tf/datasets/vox/kz_test/RqdH-JD8TpM__U__S78---...     kz  test     0.0   \n",
       "/tf/datasets/vox/kz_test/oCjW4Jy6azE__U__S110--...     kz  test     0.0   \n",
       "/tf/datasets/vox/kz_test/cwyX-Vjxep4__U__S30---...     kz  test     0.0   \n",
       "\n",
       "                                                                                                   id  \n",
       "Unnamed: 0                                                                                             \n",
       "/tf/datasets/vox/en_test/shrDRhToGpY__U__S133--...  /tf/datasets/vox/en_test/shrDRhToGpY__U__S133-...  \n",
       "/tf/datasets/vox/en_test/mzfg0RGJnV8__U__S123--...  /tf/datasets/vox/en_test/mzfg0RGJnV8__U__S123-...  \n",
       "/tf/datasets/vox/en_test/-_PPCH3y0eE__U__S1---0...  /tf/datasets/vox/en_test/-_PPCH3y0eE__U__S1---...  \n",
       "/tf/datasets/vox/en_test/DQMxvGYyu6Q__U__S0---1...  /tf/datasets/vox/en_test/DQMxvGYyu6Q__U__S0---...  \n",
       "/tf/datasets/vox/en_test/x4lfSc7PrB0__U__S0---0...  /tf/datasets/vox/en_test/x4lfSc7PrB0__U__S0---...  \n",
       "...                                                                                               ...  \n",
       "/tf/datasets/vox/kz_test/rCpb0p_lyxI__U__S25---...  /tf/datasets/vox/kz_test/rCpb0p_lyxI__U__S25--...  \n",
       "/tf/datasets/vox/kz_test/BkLVX9wf2YI__U__S26---...  /tf/datasets/vox/kz_test/BkLVX9wf2YI__U__S26--...  \n",
       "/tf/datasets/vox/kz_test/RqdH-JD8TpM__U__S78---...  /tf/datasets/vox/kz_test/RqdH-JD8TpM__U__S78--...  \n",
       "/tf/datasets/vox/kz_test/oCjW4Jy6azE__U__S110--...  /tf/datasets/vox/kz_test/oCjW4Jy6azE__U__S110-...  \n",
       "/tf/datasets/vox/kz_test/cwyX-Vjxep4__U__S30---...  /tf/datasets/vox/kz_test/cwyX-Vjxep4__U__S30--...  \n",
       "\n",
       "[36053 rows x 5 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta.loc[meta[\"split\"]==\"test\", \"id\"] = meta.loc[meta[\"split\"]==\"test\"][\"path\"]\n",
    "meta.loc[meta[\"split\"]==\"test\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "867458a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[hubconf] can not import upstream.byol_a.hubconf: No module named 'easydict'... Pass.\n",
      "[hubconf] can not import upstream.decoar.hubconf: No module named 'mxnet'... Pass.\n",
      "[hubconf] can not import upstream.wav2vec2_hug.hubconf: No module named 'transformers'... Pass.\n",
      "[hubconf] can not import upstream.pase.hubconf: No module named 'pase'... Pass.\n",
      "2021-06-30 16:01:49.417 I filelock: Lock 140119416137232 acquired on /root/.cache/torch/hub/s3prl_cache/55805839eb58b56972be4a9994ca99c862d2572cfd74ae26c916e8ced5d45a7a.lock\n",
      "Using cache found in /root/.cache/torch/hub/s3prl_cache/55805839eb58b56972be4a9994ca99c862d2572cfd74ae26c916e8ced5d45a7a\n",
      "for https://www.dropbox.com/s/3wgynxmod77ha1z/states-1000000.ckpt?dl=0\n",
      "2021-06-30 16:01:49.418 I filelock: Lock 140119416137232 released on /root/.cache/torch/hub/s3prl_cache/55805839eb58b56972be4a9994ca99c862d2572cfd74ae26c916e8ced5d45a7a.lock\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/s3prl_s3prl_master\n",
      "/root/anaconda3/lib/python3.7/site-packages/torchaudio/functional.py:318: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n",
      "  \"At least one mel filterbank has all zero values. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[UpstreamExpert] - Using the default upstream expert config\n"
     ]
    }
   ],
   "source": [
    "newtest_ds = AudiosDataset(meta.loc[meta[\"split\"]==\"test\"][\"path\"], meta.loc[meta[\"split\"]==\"test\"][\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e22574a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders[\"new_test\"] = DataLoader(\n",
    "        newtest_ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        drop_last=True,\n",
    "    )\n",
    "DEVICE = 'cuda'\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "33a4c566",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4506/4506 [42:57<00:00,  1.75it/s]  \n"
     ]
    }
   ],
   "source": [
    "true_labels = []\n",
    "predicted_labels = []\n",
    "for batch in tqdm(loaders[\"new_test\"]):\n",
    "    model.eval()\n",
    "    prediction = model(batch[\"representation\"].to(DEVICE)).detach().cpu()\n",
    "    predicted_labels.extend(torch.argmax(prediction, dim=1).tolist())\n",
    "    true_labels.extend(batch[\"target\"].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "85cc81bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          kz       0.39      1.00      0.56     13941\n",
      "          ru       0.00      0.00      0.00     12107\n",
      "          en       0.04      0.00      0.00     10000\n",
      "       other       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.39     36048\n",
      "   macro avg       0.11      0.25      0.14     36048\n",
      "weighted avg       0.16      0.39      0.22     36048\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(true_labels, predicted_labels, target_names=list(targets.keys()), labels=range(4))\n",
    "print(report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4dfb3e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
