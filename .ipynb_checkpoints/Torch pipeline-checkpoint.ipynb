{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a200657",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "################################################################################\n",
      "### WARNING, path does not exist: KALDI_ROOT=/mnt/matylda5/iveselyk/Tools/kaldi-trunk\n",
      "###          (please add 'export KALDI_ROOT=<your_path>' in your $HOME/.profile)\n",
      "###          (or run as: KALDI_ROOT=<your_path> python <your_script>.py)\n",
      "################################################################################\n",
      "\n",
      "/root/anaconda3/lib/python3.7/site-packages/torchaudio/backend/utils.py:54: UserWarning: \"sox\" backend is being deprecated. The default backend will be changed to \"sox_io\" backend in 0.8.0 and \"sox\" backend will be removed in 0.9.0. Please migrate to \"sox_io\" backend. Please refer to https://github.com/pytorch/audio/issues/903 for the detail.\n",
      "  '\"sox\" backend is being deprecated. '\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2039683e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np_rng = np.random.default_rng(1)\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import urllib.parse\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "import os\n",
    "\n",
    "from lidbox.meta import (\n",
    "    common_voice,\n",
    "    generate_label2target,\n",
    "    verify_integrity,\n",
    "    read_audio_durations,\n",
    "    random_oversampling_on_split\n",
    ")\n",
    "\n",
    "\n",
    "train = pd.read_csv(\"/tf/datasets/train.tsv\", sep=\"\\t\")\n",
    "test = pd.read_csv(\"/tf/datasets/test.tsv\", sep=\"\\t\")\n",
    "dev = pd.read_csv(\"/tf/datasets/dev.tsv\", sep=\"\\t\")\n",
    "\n",
    "train[\"path\"] = train[\"path\"].apply(lambda x: x[:-3] + \"mp3\")\n",
    "test[\"path\"] = test[\"path\"].apply(lambda x: x[:-3] + \"mp3\")\n",
    "dev[\"path\"] = dev[\"path\"].apply(lambda x: x[:-3] + \"mp3\")\n",
    "\n",
    "train[\"split\"] = \"train\"\n",
    "test[\"split\"] = \"test\"\n",
    "dev[\"split\"] = \"dev\"\n",
    "#test = test.sample(30000, replace=False)\n",
    "meta = pd.concat([train, test, dev])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ff92bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-16 02:55:50.369 I numexpr.utils: Note: detected 96 virtual cores but NumExpr set to maximum of 64, check \"NUMEXPR_MAX_THREADS\" environment variable.\n",
      "2021-06-16 02:55:50.370 I numexpr.utils: Note: NumExpr detected 96 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2021-06-16 02:55:50.371 I numexpr.utils: NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>path</th>\n",
       "      <th>locale</th>\n",
       "      <th>split</th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1486</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>ru</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>1486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56701</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>kz</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>56701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3364</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>ru</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>3364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>110475</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>rw</td>\n",
       "      <td>train</td>\n",
       "      <td>3</td>\n",
       "      <td>110475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45384</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>en</td>\n",
       "      <td>train</td>\n",
       "      <td>2</td>\n",
       "      <td>45384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30751</th>\n",
       "      <td>2677</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>ru</td>\n",
       "      <td>dev</td>\n",
       "      <td>1</td>\n",
       "      <td>2677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30752</th>\n",
       "      <td>881</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>ru</td>\n",
       "      <td>dev</td>\n",
       "      <td>1</td>\n",
       "      <td>881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30753</th>\n",
       "      <td>68709</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>kz</td>\n",
       "      <td>dev</td>\n",
       "      <td>0</td>\n",
       "      <td>68709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30754</th>\n",
       "      <td>249025</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>en</td>\n",
       "      <td>dev</td>\n",
       "      <td>2</td>\n",
       "      <td>249025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30755</th>\n",
       "      <td>2986</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>uk</td>\n",
       "      <td>dev</td>\n",
       "      <td>3</td>\n",
       "      <td>2986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168971 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                               path locale  \\\n",
       "0            1486  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...     ru   \n",
       "1           56701  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...     kz   \n",
       "2            3364  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...     ru   \n",
       "3          110475  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...     rw   \n",
       "4           45384  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...     en   \n",
       "...           ...                                                ...    ...   \n",
       "30751        2677  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...     ru   \n",
       "30752         881  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...     ru   \n",
       "30753       68709  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...     kz   \n",
       "30754      249025  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...     en   \n",
       "30755        2986  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...     uk   \n",
       "\n",
       "       split  target      id  \n",
       "0      train       1    1486  \n",
       "1      train       0   56701  \n",
       "2      train       1    3364  \n",
       "3      train       3  110475  \n",
       "4      train       2   45384  \n",
       "...      ...     ...     ...  \n",
       "30751    dev       1    2677  \n",
       "30752    dev       1     881  \n",
       "30753    dev       0   68709  \n",
       "30754    dev       2  249025  \n",
       "30755    dev       3    2986  \n",
       "\n",
       "[168971 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta.loc[meta[\"locale\"] != \"kz\", \"path\"] = \"/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/\" +  meta.loc[meta[\"locale\"] != \"kz\"][\"locale\"] + \"/clips/\" + meta.loc[meta[\"locale\"] != \"kz\"][\"path\"]\n",
    "targets = {\"kz\": 0, \"ru\": 1, \"en\":2, \"other\":3}\n",
    "meta[\"target\"] = meta[\"locale\"]\n",
    "meta.loc[(meta[\"locale\"] != \"kz\") & (meta[\"locale\"] != \"ru\") & (meta[\"locale\"]!=\"en\"), \"target\"] = \"other\"\n",
    "meta = meta.loc[meta[\"path\"] != \"/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/kz/clips/5f590a130a73c.mp3\"]\n",
    "meta = meta.loc[meta[\"path\"] != \"/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/kz/clips/5ef9bd9ba7029.mp3\"]\n",
    "\n",
    "meta[\"id\"] = meta[\"Unnamed: 0\"].apply(str)\n",
    "meta[\"target\"] = meta[\"target\"].map(targets)\n",
    "\n",
    "meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c50a60ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "import math\n",
    "\n",
    "def _get_sample(path, resample=None):\n",
    "  effects = [\n",
    "    [\"remix\", \"1\"]\n",
    "  ]\n",
    "  if resample:\n",
    "    effects.append([\"rate\", f'{resample}'])\n",
    "  return torchaudio.sox_effects.apply_effects_file(path, effects=effects)\n",
    "\n",
    "SAMPLE_RIR_PATH = os.path.join(os.getcwd(), \"rir.wav\")\n",
    "\n",
    "def get_rir_sample(*, resample=None, processed=False):\n",
    "    rir_raw, sample_rate = _get_sample(SAMPLE_RIR_PATH, resample=resample)\n",
    "    if not processed:\n",
    "        return rir_raw, sample_rate\n",
    "    rir = rir_raw[:, int(sample_rate*1.01):int(sample_rate*1.3)]\n",
    "    rir = rir / torch.norm(rir, p=2)\n",
    "    rir = torch.flip(rir, [1])\n",
    "    return rir, sample_rate\n",
    "\n",
    "class AudiosDataset(Dataset):\n",
    "    def __init__(self, paths=None, targets=None, augment=False) -> None:\n",
    "        self.paths = paths\n",
    "        self.targets = targets\n",
    "        self.augment = augment\n",
    "        self.rir = get_rir_sample()[0]\n",
    "        \n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> dict:\n",
    "        y, sr = torchaudio.load(self.paths.iloc[idx], normalization=True)\n",
    "        \"\"\"\n",
    "        if self.augment:\n",
    "            effects = [\n",
    "                    [\"lowpass\", \"-1\", \"300\"], \n",
    "                    [\"speed\", f\"{random.uniform(0.7, 1.3)}\"],  # change speed\n",
    "                  ]\n",
    "            y, sr = torchaudio.sox_effects.apply_effects_tensor(\n",
    "                y, sr, effects)\n",
    "        #\n",
    "            \n",
    "        if self.augment:\n",
    "            # augment sound in order to imitate the room change\n",
    "            rir = self.rir[:, int(16000*1.1):int(16000*1.3)]\n",
    "            rir = rir / torch.norm(rir, p=2)\n",
    "            rir = torch.flip(rir, [1])\n",
    "            y = torch.nn.functional.conv1d(y[None, ...], rir[None, ...])[0]\n",
    "        \n",
    "        \"\"\"\n",
    "        y = torchaudio.transforms.Resample(orig_freq=sr, new_freq=16000)(y)\n",
    "        y = torchaudio.transforms.Vad(sample_rate = 16000)(y)\n",
    "\n",
    "        \"\"\"\n",
    "        if self.augment:\n",
    "            y = (0.5)*torch.randn(y.shape)\n",
    "        \"\"\"\n",
    "        # convert to spectogram\n",
    "        spectogram = torchaudio.transforms.MelSpectrogram()(y)\n",
    "        #spectogram = torch.log(spectogram + 1e-5)\n",
    "        melspectogram_db = torchaudio.transforms.AmplitudeToDB()(spectogram)\n",
    "        \n",
    "        #Make sure all spectrograms are the same size\n",
    "        fixed_length = 12 * (16000//200)\n",
    "        \n",
    "        if melspectogram_db.shape[2] < fixed_length:\n",
    "            melspectogram_db = torch.nn.functional.pad(\n",
    "              melspectogram_db, (0, fixed_length - melspectogram_db.shape[2]))\n",
    "        else:\n",
    "            melspectogram_db = melspectogram_db[:, :, :fixed_length]\n",
    "        \n",
    "        spectogram = melspectogram_db\n",
    "        \n",
    "        if self.augment:\n",
    "\n",
    "            spectogram = torchaudio.transforms.FrequencyMasking(100)(spectogram)\n",
    "            spectogram = torchaudio.transforms.TimeMasking(100)(spectogram)\n",
    "        \n",
    "        # returning result\n",
    "        result = {\"spec\": spectogram, \"target\":self.targets.iloc[idx]}\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eb34ec7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = AudiosDataset(meta[\"path\"], meta[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "046b2dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "train_ds = AudiosDataset(meta.loc[meta[\"split\"]==\"train\"][\"path\"], meta.loc[meta[\"split\"]==\"train\"][\"target\"], augment=True)\n",
    "val_ds = AudiosDataset(meta.loc[meta[\"split\"]==\"dev\"][\"path\"], meta.loc[meta[\"split\"]==\"dev\"][\"target\"])\n",
    "test_ds = AudiosDataset(meta.loc[meta[\"split\"]==\"test\"][\"path\"], meta.loc[meta[\"split\"]==\"test\"][\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "86a3c3c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'spec': tensor([[[-100.0000, -100.0000, -100.0000,  ...,    0.0000,    0.0000,\n",
      "             0.0000],\n",
      "         [   4.6951,   12.7690,    8.0257,  ...,    0.0000,    0.0000,\n",
      "             0.0000],\n",
      "         [  12.0064,   20.0803,   15.3369,  ...,    0.0000,    0.0000,\n",
      "             0.0000],\n",
      "         ...,\n",
      "         [  22.3348,   23.4628,   23.1085,  ...,    0.0000,    0.0000,\n",
      "             0.0000],\n",
      "         [  23.0709,   18.7987,   23.5499,  ...,    0.0000,    0.0000,\n",
      "             0.0000],\n",
      "         [  17.9024,   21.4223,   22.0901,  ...,    0.0000,    0.0000,\n",
      "             0.0000]]]), 'target': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.7/site-packages/torchaudio/functional.py:318: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n",
      "  \"At least one mel filterbank has all zero values. \"\n",
      "/root/anaconda3/lib/python3.7/site-packages/torch/functional.py:516: UserWarning: stft will require the return_complex parameter be explicitly  specified in a future PyTorch release. Use return_complex=False  to preserve the current behavior or return_complex=True to return  a complex output. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:653.)\n",
      "  normalized, onesided, return_complex)\n",
      "/root/anaconda3/lib/python3.7/site-packages/torch/functional.py:516: UserWarning: The function torch.rfft is deprecated and will be removed in a future PyTorch release. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.fft or torch.fft.rfft. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:590.)\n",
      "  normalized, onesided, return_complex)\n"
     ]
    }
   ],
   "source": [
    "for i in train_ds:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a8d47377",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_workers = 10\n",
    "loaders = {\n",
    "    \"train\": DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        drop_last=True,\n",
    "    ),\n",
    "    \"valid\": DataLoader(\n",
    "        val_ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        drop_last=True,\n",
    "    ),\n",
    "    \"test\":DataLoader(\n",
    "        test_ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        drop_last=True,\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2fc2f280",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import  models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "model = models.resnet34(pretrained=True)\n",
    "model.conv1=nn.Conv2d(1, model.conv1.out_channels, \n",
    "                      kernel_size=model.conv1.kernel_size[0], \n",
    "                      stride=model.conv1.stride[0], \n",
    "                      padding=model.conv1.padding[0])\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "0aed55af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train(model, opt, scheduler, loss_fn, epochs, data_tr, data_val, max_stable=5):\n",
    "    best_val_loss = 1e9\n",
    "    counter = 0\n",
    "    for epoch in range(epochs):\n",
    "        #tic = time()\n",
    "        print('* Epoch %d/%d' % (epoch+1, epochs))\n",
    "\n",
    "        avg_loss = 0\n",
    "        model.train()  # train mode\n",
    "        for batch in tqdm(data_tr):\n",
    "            loss = 0\n",
    "            # data to device\n",
    "            X_batch, Y_batch = batch[\"spec\"], batch[\"target\"]\n",
    "            #print(X_batch.shape)\n",
    "            X_batch = X_batch.to(DEVICE)\n",
    "            Y_batch = Y_batch.to(DEVICE)\n",
    "            # set parameter gradients to zero\n",
    "            opt.zero_grad()\n",
    "            # forward\n",
    "            Y_pred = model(X_batch)\n",
    "            #print(Y_pred)\n",
    "            loss = loss_fn(Y_pred, Y_batch)# forward-pass\n",
    "            loss.backward()  # backward-pass\n",
    "            opt.step()  # update weights\n",
    "            if not scheduler is None:\n",
    "                scheduler.step()\n",
    "            # calculate loss to show the user\n",
    "            avg_loss += loss / len(data_tr)\n",
    "      #  toc = time()\n",
    "        print('loss: %f' % avg_loss)\n",
    "        # show intermediate results\n",
    "        model.eval()  # testing mode\n",
    "        val_loss = 0\n",
    "        print(\"start validation\")\n",
    "        for v_b in tqdm(data_val):\n",
    "            X_val, Y_val = v_b[\"spec\"], v_b[\"target\"]\n",
    "            Y_hat = model(X_val.to(DEVICE)).detach().cpu()# detach and put into cpu\n",
    "            val_loss += loss_fn(Y_hat, Y_val)\n",
    "        val_loss /= len(data_val)\n",
    "        print( f\"validation loss: {val_loss}\")\n",
    "        if val_loss <= best_val_loss and val_loss > 0:\n",
    "            counter = 0\n",
    "            print(\"Save new model!\")\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), f'best_model.h5')\n",
    "            best_patn = f'{epoch}_{best_val_loss}.h5'\n",
    "        else:\n",
    "            counter += 1\n",
    "        if counter == max_stable:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "7c901982",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2576 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2576/2576 [07:11<00:00,  5.97it/s]\n",
      "  0%|          | 0/961 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.654073\n",
      "start validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 961/961 [02:37<00:00,  6.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.8601071238517761\n",
      "Save new model!\n",
      "* Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2576/2576 [07:37<00:00,  5.64it/s]\n",
      "  0%|          | 0/961 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.526455\n",
      "start validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 961/961 [02:29<00:00,  6.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.3954550325870514\n",
      "Save new model!\n",
      "* Epoch 3/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2576/2576 [06:54<00:00,  6.21it/s]\n",
      "  0%|          | 0/961 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.469784\n",
      "start validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 961/961 [02:47<00:00,  5.73it/s]\n",
      "  0%|          | 0/2576 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.5551520586013794\n",
      "* Epoch 4/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2576/2576 [07:28<00:00,  5.74it/s]\n",
      "  0%|          | 0/961 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.428406\n",
      "start validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 961/961 [02:35<00:00,  6.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.5290905833244324\n",
      "* Epoch 5/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2576/2576 [07:22<00:00,  5.82it/s]\n",
      "  0%|          | 0/961 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.398306\n",
      "start validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 961/961 [02:34<00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.38806942105293274\n",
      "Save new model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2576 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Epoch 6/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2576/2576 [06:55<00:00,  6.19it/s]\n",
      "  0%|          | 0/961 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.371820\n",
      "start validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 961/961 [02:41<00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.4634988307952881\n",
      "* Epoch 7/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2576/2576 [07:26<00:00,  5.77it/s]\n",
      "  0%|          | 0/961 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.349526\n",
      "start validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 961/961 [02:36<00:00,  6.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.3907879889011383\n",
      "* Epoch 8/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2576/2576 [07:26<00:00,  5.77it/s]\n",
      "  0%|          | 0/961 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.327548\n",
      "start validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 961/961 [02:37<00:00,  6.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.2315412014722824\n",
      "Save new model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2576 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Epoch 9/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2576/2576 [07:14<00:00,  5.93it/s]\n",
      "  0%|          | 0/961 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.310639\n",
      "start validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 961/961 [02:30<00:00,  6.37it/s]\n",
      "  0%|          | 0/2576 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.29240575432777405\n",
      "* Epoch 10/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2576/2576 [07:18<00:00,  5.87it/s]\n",
      "  0%|          | 0/961 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.295653\n",
      "start validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 961/961 [02:38<00:00,  6.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.5641764402389526\n",
      "* Epoch 11/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2576/2576 [07:22<00:00,  5.83it/s]\n",
      "  0%|          | 0/961 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.275224\n",
      "start validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 961/961 [02:34<00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.5109254121780396\n",
      "* Epoch 12/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2576/2576 [07:15<00:00,  5.92it/s]\n",
      "  0%|          | 0/961 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.262520\n",
      "start validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 961/961 [02:33<00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.23857124149799347\n",
      "* Epoch 13/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2576/2576 [07:13<00:00,  5.95it/s]\n",
      "  0%|          | 0/961 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.250046\n",
      "start validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 961/961 [02:35<00:00,  6.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.26080694794654846\n"
     ]
    }
   ],
   "source": [
    "DEVICE = 'cuda'\n",
    "max_epochs = 100\n",
    "model = model.to(DEVICE)\n",
    "#torch.cuda.empty_cache()\n",
    "loss_fn =  nn.CrossEntropyLoss()\n",
    "optimaizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimaizer, T_0=5, T_mult=1, eta_min=1e-8, last_epoch=-1)\n",
    "train(model, optimaizer,scheduler, loss_fn, max_epochs, loaders[\"train\"], loaders[\"valid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cdef8f63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"best_model.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "ae7fcf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = []\n",
    "predicted_labels = []\n",
    "for batch in loaders[\"test\"]:\n",
    "    model.eval()\n",
    "    prediction = model(batch[\"spec\"].to(DEVICE)).detach().cpu()\n",
    "    predicted_labels.extend(torch.argmax(prediction, dim=1).tolist())\n",
    "    true_labels.extend(batch[\"target\"].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "b7c74c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          kz       1.00      1.00      1.00     17337\n",
      "          ru       0.79      0.88      0.83     10374\n",
      "          en       0.82      0.87      0.85     12956\n",
      "       other       0.84      0.73      0.78     15077\n",
      "\n",
      "    accuracy                           0.87     55744\n",
      "   macro avg       0.86      0.87      0.86     55744\n",
      "weighted avg       0.88      0.87      0.87     55744\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(true_labels, predicted_labels, target_names=list(targets.keys()), labels=range(4))\n",
    "print(report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb0c371",
   "metadata": {},
   "source": [
    "## Testing on VOX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a9fb9181",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np_rng = np.random.default_rng(1)\n",
    "\n",
    "\n",
    "import urllib.parse\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "import os\n",
    "\n",
    "from lidbox.meta import (\n",
    "    common_voice,\n",
    "    generate_label2target,\n",
    "    verify_integrity,\n",
    "    read_audio_durations,\n",
    "    random_oversampling_on_split\n",
    ")\n",
    "\n",
    "\n",
    "test = pd.read_csv(\"/tf/datasets/new_test.tsv\", sep=\"\\t\")\n",
    "\n",
    "test[\"path\"] = test[\"path\"].apply(lambda x: x[:-3] + \"mp3\")\n",
    "\n",
    "test[\"split\"] = \"test\"\n",
    "meta = pd.concat([train, test, dev])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8daedc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta.loc[((meta[\"locale\"] != \"kz\") & ~(((meta[\"split\"] == \"dev\") | (meta[\"split\"] == \"test\")) & ((meta[\"locale\"] == \"ru\") | (meta[\"locale\"] == \"kz\") | (meta[\"locale\"] == \"en\")))), \"path\"] = \"/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/\" + meta.loc[((meta[\"locale\"] != \"kz\") & ~(((meta[\"split\"] == \"dev\") | (meta[\"split\"] == \"test\")) & ((meta[\"locale\"] == \"ru\") | (meta[\"locale\"] == \"kz\") | (meta[\"locale\"] == \"en\"))))][\"locale\"]  + \"/clips/\" + meta.loc[((meta[\"locale\"] != \"kz\") & ~(((meta[\"split\"] == \"dev\") | (meta[\"split\"] == \"test\")) & ((meta[\"locale\"] == \"ru\") | (meta[\"locale\"] == \"kz\") | (meta[\"locale\"] == \"en\"))))][\"path\"]\n",
    "targets = {\"kz\": 0, \"ru\": 1, \"en\":2, \"other\":3}\n",
    "meta[\"target\"] = meta[\"locale\"]\n",
    "meta.loc[(meta[\"locale\"] != \"kz\") & (meta[\"locale\"] != \"ru\") & (meta[\"locale\"]!=\"en\"), \"target\"] = \"other\"\n",
    "meta = meta.loc[meta[\"path\"] != \"/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/kz/clips/5f590a130a73c.mp3\"]\n",
    "meta = meta.loc[meta[\"path\"] != \"/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/kz/clips/5ef9bd9ba7029.mp3\"]\n",
    "\n",
    "meta[\"id\"] = meta[\"Unnamed: 0\"].apply(str)\n",
    "meta[\"target\"] = meta[\"target\"].map(targets)\n",
    "\n",
    "\n",
    "workdir = \"/tf/datasets/transformer\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4346bdab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       /tf/datasets/vox/en_test/shrDRhToGpY__U__S133-...\n",
       "1       /tf/datasets/vox/en_test/mzfg0RGJnV8__U__S123-...\n",
       "2       /tf/datasets/vox/en_test/-_PPCH3y0eE__U__S1---...\n",
       "3       /tf/datasets/vox/en_test/DQMxvGYyu6Q__U__S0---...\n",
       "4       /tf/datasets/vox/en_test/x4lfSc7PrB0__U__S0---...\n",
       "                              ...                        \n",
       "9995    /tf/datasets/vox/en_test/KLiy94kfZI4__U__S133-...\n",
       "9996    /tf/datasets/vox/en_test/YTlliEr5LOA__U__S113-...\n",
       "9997    /tf/datasets/vox/en_test/bSs0gNq6Kkc__U__S0---...\n",
       "9998    /tf/datasets/vox/en_test/Da7c-BY6MDA__U__S2---...\n",
       "9999    /tf/datasets/vox/en_test/VWvPndMo1F8__U__S24--...\n",
       "Name: path, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta.loc[(meta[\"split\"] == \"test\") & (meta[\"locale\"] == \"ru\"), \"path\"] = meta.loc[(meta[\"split\"] == \"test\") & (meta[\"locale\"] == \"ru\")][\"path\"].apply(lambda x: f\"/tf/datasets/vox/ru_test/{x}\")\n",
    "meta.loc[(meta[\"split\"] == \"test\") & (meta[\"locale\"] == \"ru\"), \"path\"]\n",
    "meta.loc[(meta[\"split\"] == \"test\") & (meta[\"locale\"] == \"kz\"), \"path\"] = meta.loc[(meta[\"split\"] == \"test\") & (meta[\"locale\"] == \"kz\")][\"path\"].apply(lambda x: f\"/tf/datasets/vox/kz_test/{x}\")\n",
    "meta.loc[(meta[\"split\"] == \"test\") & (meta[\"locale\"] == \"kz\"), \"path\"] \n",
    "meta.loc[(meta[\"split\"] == \"test\") & (meta[\"locale\"] == \"en\"), \"path\"] = meta.loc[(meta[\"split\"] == \"test\") & (meta[\"locale\"] == \"en\")][\"path\"].apply(lambda x: f\"/tf/datasets/vox/en_test/{x}\")\n",
    "meta.loc[(meta[\"split\"] == \"test\") & (meta[\"locale\"] == \"en\"), \"path\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "391340f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta.loc[meta[\"split\"]==\"test\", \"Unnamed: 0\"] = meta.loc[meta[\"split\"]==\"test\"][\"path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d921905f",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta[\"id\"] = meta[\"Unnamed: 0\"].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "05490c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta.loc[meta[\"split\"] == \"test\", \"id\"] = meta.loc[meta[\"split\"] == \"test\"][\"path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1c1c18b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>locale</th>\n",
       "      <th>split</th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/en_test/shrDRhToGpY__U__S133---0944.430-0958.260.mp3</th>\n",
       "      <td>/tf/datasets/vox/en_test/shrDRhToGpY__U__S133-...</td>\n",
       "      <td>en</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>/tf/datasets/vox/en_test/shrDRhToGpY__U__S133-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/en_test/mzfg0RGJnV8__U__S123---0427.020-0444.670.mp3</th>\n",
       "      <td>/tf/datasets/vox/en_test/mzfg0RGJnV8__U__S123-...</td>\n",
       "      <td>en</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>/tf/datasets/vox/en_test/mzfg0RGJnV8__U__S123-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/en_test/-_PPCH3y0eE__U__S1---0398.760-0403.940.mp3</th>\n",
       "      <td>/tf/datasets/vox/en_test/-_PPCH3y0eE__U__S1---...</td>\n",
       "      <td>en</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>/tf/datasets/vox/en_test/-_PPCH3y0eE__U__S1---...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/en_test/DQMxvGYyu6Q__U__S0---1473.480-1485.720.mp3</th>\n",
       "      <td>/tf/datasets/vox/en_test/DQMxvGYyu6Q__U__S0---...</td>\n",
       "      <td>en</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>/tf/datasets/vox/en_test/DQMxvGYyu6Q__U__S0---...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/en_test/x4lfSc7PrB0__U__S0---0125.230-0140.900.mp3</th>\n",
       "      <td>/tf/datasets/vox/en_test/x4lfSc7PrB0__U__S0---...</td>\n",
       "      <td>en</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>/tf/datasets/vox/en_test/x4lfSc7PrB0__U__S0---...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/it/clips/common_voice_it_20015623.mp3</th>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>it</td>\n",
       "      <td>test</td>\n",
       "      <td>3</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/uk/clips/common_voice_uk_23554602.mp3</th>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>uk</td>\n",
       "      <td>test</td>\n",
       "      <td>3</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/tr/clips/common_voice_tr_20416266.mp3</th>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>tr</td>\n",
       "      <td>test</td>\n",
       "      <td>3</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/it/clips/common_voice_it_20263173.mp3</th>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>it</td>\n",
       "      <td>test</td>\n",
       "      <td>3</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/es/clips/common_voice_es_20283066.mp3</th>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>es</td>\n",
       "      <td>test</td>\n",
       "      <td>3</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51137 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                 path  \\\n",
       "Unnamed: 0                                                                                              \n",
       "/tf/datasets/vox/en_test/shrDRhToGpY__U__S133--...  /tf/datasets/vox/en_test/shrDRhToGpY__U__S133-...   \n",
       "/tf/datasets/vox/en_test/mzfg0RGJnV8__U__S123--...  /tf/datasets/vox/en_test/mzfg0RGJnV8__U__S123-...   \n",
       "/tf/datasets/vox/en_test/-_PPCH3y0eE__U__S1---0...  /tf/datasets/vox/en_test/-_PPCH3y0eE__U__S1---...   \n",
       "/tf/datasets/vox/en_test/DQMxvGYyu6Q__U__S0---1...  /tf/datasets/vox/en_test/DQMxvGYyu6Q__U__S0---...   \n",
       "/tf/datasets/vox/en_test/x4lfSc7PrB0__U__S0---0...  /tf/datasets/vox/en_test/x4lfSc7PrB0__U__S0---...   \n",
       "...                                                                                               ...   \n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...   \n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...   \n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...   \n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...   \n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...   \n",
       "\n",
       "                                                   locale split  target  \\\n",
       "Unnamed: 0                                                                \n",
       "/tf/datasets/vox/en_test/shrDRhToGpY__U__S133--...     en  test       2   \n",
       "/tf/datasets/vox/en_test/mzfg0RGJnV8__U__S123--...     en  test       2   \n",
       "/tf/datasets/vox/en_test/-_PPCH3y0eE__U__S1---0...     en  test       2   \n",
       "/tf/datasets/vox/en_test/DQMxvGYyu6Q__U__S0---1...     en  test       2   \n",
       "/tf/datasets/vox/en_test/x4lfSc7PrB0__U__S0---0...     en  test       2   \n",
       "...                                                   ...   ...     ...   \n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...     it  test       3   \n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...     uk  test       3   \n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...     tr  test       3   \n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...     it  test       3   \n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...     es  test       3   \n",
       "\n",
       "                                                                                                   id  \n",
       "Unnamed: 0                                                                                             \n",
       "/tf/datasets/vox/en_test/shrDRhToGpY__U__S133--...  /tf/datasets/vox/en_test/shrDRhToGpY__U__S133-...  \n",
       "/tf/datasets/vox/en_test/mzfg0RGJnV8__U__S123--...  /tf/datasets/vox/en_test/mzfg0RGJnV8__U__S123-...  \n",
       "/tf/datasets/vox/en_test/-_PPCH3y0eE__U__S1---0...  /tf/datasets/vox/en_test/-_PPCH3y0eE__U__S1---...  \n",
       "/tf/datasets/vox/en_test/DQMxvGYyu6Q__U__S0---1...  /tf/datasets/vox/en_test/DQMxvGYyu6Q__U__S0---...  \n",
       "/tf/datasets/vox/en_test/x4lfSc7PrB0__U__S0---0...  /tf/datasets/vox/en_test/x4lfSc7PrB0__U__S0---...  \n",
       "...                                                                                               ...  \n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...  \n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...  \n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...  \n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...  \n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...  \n",
       "\n",
       "[51137 rows x 5 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta = meta.set_index(\"Unnamed: 0\")\n",
    "meta.loc[meta[\"split\"]==\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "858f61d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta.loc[meta[\"split\"] == \"test\"] = meta.loc[(meta[\"split\"] == \"test\") & (meta[\"target\"] != 3)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9825fa78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>locale</th>\n",
       "      <th>split</th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/en_test/shrDRhToGpY__U__S133---0944.430-0958.260.mp3</th>\n",
       "      <td>/tf/datasets/vox/en_test/shrDRhToGpY__U__S133-...</td>\n",
       "      <td>en</td>\n",
       "      <td>test</td>\n",
       "      <td>2.0</td>\n",
       "      <td>/tf/datasets/vox/en_test/shrDRhToGpY__U__S133-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/en_test/mzfg0RGJnV8__U__S123---0427.020-0444.670.mp3</th>\n",
       "      <td>/tf/datasets/vox/en_test/mzfg0RGJnV8__U__S123-...</td>\n",
       "      <td>en</td>\n",
       "      <td>test</td>\n",
       "      <td>2.0</td>\n",
       "      <td>/tf/datasets/vox/en_test/mzfg0RGJnV8__U__S123-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/en_test/-_PPCH3y0eE__U__S1---0398.760-0403.940.mp3</th>\n",
       "      <td>/tf/datasets/vox/en_test/-_PPCH3y0eE__U__S1---...</td>\n",
       "      <td>en</td>\n",
       "      <td>test</td>\n",
       "      <td>2.0</td>\n",
       "      <td>/tf/datasets/vox/en_test/-_PPCH3y0eE__U__S1---...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/en_test/DQMxvGYyu6Q__U__S0---1473.480-1485.720.mp3</th>\n",
       "      <td>/tf/datasets/vox/en_test/DQMxvGYyu6Q__U__S0---...</td>\n",
       "      <td>en</td>\n",
       "      <td>test</td>\n",
       "      <td>2.0</td>\n",
       "      <td>/tf/datasets/vox/en_test/DQMxvGYyu6Q__U__S0---...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/en_test/x4lfSc7PrB0__U__S0---0125.230-0140.900.mp3</th>\n",
       "      <td>/tf/datasets/vox/en_test/x4lfSc7PrB0__U__S0---...</td>\n",
       "      <td>en</td>\n",
       "      <td>test</td>\n",
       "      <td>2.0</td>\n",
       "      <td>/tf/datasets/vox/en_test/x4lfSc7PrB0__U__S0---...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/kz_test/rCpb0p_lyxI__U__S25---0107.830-0127.780.mp3</th>\n",
       "      <td>/tf/datasets/vox/kz_test/rCpb0p_lyxI__U__S25--...</td>\n",
       "      <td>kz</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/tf/datasets/vox/kz_test/rCpb0p_lyxI__U__S25--...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/kz_test/BkLVX9wf2YI__U__S26---0236.830-0241.550.mp3</th>\n",
       "      <td>/tf/datasets/vox/kz_test/BkLVX9wf2YI__U__S26--...</td>\n",
       "      <td>kz</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/tf/datasets/vox/kz_test/BkLVX9wf2YI__U__S26--...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/kz_test/RqdH-JD8TpM__U__S78---0466.720-0470.860.mp3</th>\n",
       "      <td>/tf/datasets/vox/kz_test/RqdH-JD8TpM__U__S78--...</td>\n",
       "      <td>kz</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/tf/datasets/vox/kz_test/RqdH-JD8TpM__U__S78--...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/kz_test/oCjW4Jy6azE__U__S110---0669.320-0675.220.mp3</th>\n",
       "      <td>/tf/datasets/vox/kz_test/oCjW4Jy6azE__U__S110-...</td>\n",
       "      <td>kz</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/tf/datasets/vox/kz_test/oCjW4Jy6azE__U__S110-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/kz_test/cwyX-Vjxep4__U__S30---0302.770-0318.540.mp3</th>\n",
       "      <td>/tf/datasets/vox/kz_test/cwyX-Vjxep4__U__S30--...</td>\n",
       "      <td>kz</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/tf/datasets/vox/kz_test/cwyX-Vjxep4__U__S30--...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36053 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                 path  \\\n",
       "Unnamed: 0                                                                                              \n",
       "/tf/datasets/vox/en_test/shrDRhToGpY__U__S133--...  /tf/datasets/vox/en_test/shrDRhToGpY__U__S133-...   \n",
       "/tf/datasets/vox/en_test/mzfg0RGJnV8__U__S123--...  /tf/datasets/vox/en_test/mzfg0RGJnV8__U__S123-...   \n",
       "/tf/datasets/vox/en_test/-_PPCH3y0eE__U__S1---0...  /tf/datasets/vox/en_test/-_PPCH3y0eE__U__S1---...   \n",
       "/tf/datasets/vox/en_test/DQMxvGYyu6Q__U__S0---1...  /tf/datasets/vox/en_test/DQMxvGYyu6Q__U__S0---...   \n",
       "/tf/datasets/vox/en_test/x4lfSc7PrB0__U__S0---0...  /tf/datasets/vox/en_test/x4lfSc7PrB0__U__S0---...   \n",
       "...                                                                                               ...   \n",
       "/tf/datasets/vox/kz_test/rCpb0p_lyxI__U__S25---...  /tf/datasets/vox/kz_test/rCpb0p_lyxI__U__S25--...   \n",
       "/tf/datasets/vox/kz_test/BkLVX9wf2YI__U__S26---...  /tf/datasets/vox/kz_test/BkLVX9wf2YI__U__S26--...   \n",
       "/tf/datasets/vox/kz_test/RqdH-JD8TpM__U__S78---...  /tf/datasets/vox/kz_test/RqdH-JD8TpM__U__S78--...   \n",
       "/tf/datasets/vox/kz_test/oCjW4Jy6azE__U__S110--...  /tf/datasets/vox/kz_test/oCjW4Jy6azE__U__S110-...   \n",
       "/tf/datasets/vox/kz_test/cwyX-Vjxep4__U__S30---...  /tf/datasets/vox/kz_test/cwyX-Vjxep4__U__S30--...   \n",
       "\n",
       "                                                   locale split  target  \\\n",
       "Unnamed: 0                                                                \n",
       "/tf/datasets/vox/en_test/shrDRhToGpY__U__S133--...     en  test     2.0   \n",
       "/tf/datasets/vox/en_test/mzfg0RGJnV8__U__S123--...     en  test     2.0   \n",
       "/tf/datasets/vox/en_test/-_PPCH3y0eE__U__S1---0...     en  test     2.0   \n",
       "/tf/datasets/vox/en_test/DQMxvGYyu6Q__U__S0---1...     en  test     2.0   \n",
       "/tf/datasets/vox/en_test/x4lfSc7PrB0__U__S0---0...     en  test     2.0   \n",
       "...                                                   ...   ...     ...   \n",
       "/tf/datasets/vox/kz_test/rCpb0p_lyxI__U__S25---...     kz  test     0.0   \n",
       "/tf/datasets/vox/kz_test/BkLVX9wf2YI__U__S26---...     kz  test     0.0   \n",
       "/tf/datasets/vox/kz_test/RqdH-JD8TpM__U__S78---...     kz  test     0.0   \n",
       "/tf/datasets/vox/kz_test/oCjW4Jy6azE__U__S110--...     kz  test     0.0   \n",
       "/tf/datasets/vox/kz_test/cwyX-Vjxep4__U__S30---...     kz  test     0.0   \n",
       "\n",
       "                                                                                                   id  \n",
       "Unnamed: 0                                                                                             \n",
       "/tf/datasets/vox/en_test/shrDRhToGpY__U__S133--...  /tf/datasets/vox/en_test/shrDRhToGpY__U__S133-...  \n",
       "/tf/datasets/vox/en_test/mzfg0RGJnV8__U__S123--...  /tf/datasets/vox/en_test/mzfg0RGJnV8__U__S123-...  \n",
       "/tf/datasets/vox/en_test/-_PPCH3y0eE__U__S1---0...  /tf/datasets/vox/en_test/-_PPCH3y0eE__U__S1---...  \n",
       "/tf/datasets/vox/en_test/DQMxvGYyu6Q__U__S0---1...  /tf/datasets/vox/en_test/DQMxvGYyu6Q__U__S0---...  \n",
       "/tf/datasets/vox/en_test/x4lfSc7PrB0__U__S0---0...  /tf/datasets/vox/en_test/x4lfSc7PrB0__U__S0---...  \n",
       "...                                                                                               ...  \n",
       "/tf/datasets/vox/kz_test/rCpb0p_lyxI__U__S25---...  /tf/datasets/vox/kz_test/rCpb0p_lyxI__U__S25--...  \n",
       "/tf/datasets/vox/kz_test/BkLVX9wf2YI__U__S26---...  /tf/datasets/vox/kz_test/BkLVX9wf2YI__U__S26--...  \n",
       "/tf/datasets/vox/kz_test/RqdH-JD8TpM__U__S78---...  /tf/datasets/vox/kz_test/RqdH-JD8TpM__U__S78--...  \n",
       "/tf/datasets/vox/kz_test/oCjW4Jy6azE__U__S110--...  /tf/datasets/vox/kz_test/oCjW4Jy6azE__U__S110-...  \n",
       "/tf/datasets/vox/kz_test/cwyX-Vjxep4__U__S30---...  /tf/datasets/vox/kz_test/cwyX-Vjxep4__U__S30--...  \n",
       "\n",
       "[36053 rows x 5 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta.loc[meta[\"split\"]==\"test\", \"id\"] = meta.loc[meta[\"split\"]==\"test\"][\"path\"]\n",
    "meta.loc[meta[\"split\"]==\"test\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fb73151d",
   "metadata": {},
   "outputs": [],
   "source": [
    "newtest_ds = AudiosDataset(meta.loc[meta[\"split\"]==\"test\"][\"path\"], meta.loc[meta[\"split\"]==\"test\"][\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ec6438cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders[\"new_test\"] = DataLoader(\n",
    "        newtest_ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        drop_last=True,\n",
    "    )\n",
    "DEVICE = 'cuda'\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "644ca029",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = []\n",
    "predicted_labels = []\n",
    "for batch in loaders[\"new_test\"]:\n",
    "    model.eval()\n",
    "    prediction = model(batch[\"spec\"].to(DEVICE)).detach().cpu()\n",
    "    predicted_labels.extend(torch.argmax(prediction, dim=1).tolist())\n",
    "    true_labels.extend(batch[\"target\"].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4b33b87a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          kz       0.35      0.67      0.46     13925\n",
      "          ru       0.33      0.01      0.02     12107\n",
      "          en       0.26      0.12      0.17     10000\n",
      "       other       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.30     36032\n",
      "   macro avg       0.23      0.20      0.16     36032\n",
      "weighted avg       0.32      0.30      0.23     36032\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(true_labels, predicted_labels, target_names=list(targets.keys()), labels=range(4))\n",
    "print(report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6927d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
