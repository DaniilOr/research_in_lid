{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00f06192",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "################################################################################\n",
      "### WARNING, path does not exist: KALDI_ROOT=/mnt/matylda5/iveselyk/Tools/kaldi-trunk\n",
      "###          (please add 'export KALDI_ROOT=<your_path>' in your $HOME/.profile)\n",
      "###          (or run as: KALDI_ROOT=<your_path> python <your_script>.py)\n",
      "################################################################################\n",
      "\n",
      "/root/anaconda3/lib/python3.7/site-packages/torchaudio/backend/utils.py:54: UserWarning: \"sox\" backend is being deprecated. The default backend will be changed to \"sox_io\" backend in 0.8.0 and \"sox\" backend will be removed in 0.9.0. Please migrate to \"sox_io\" backend. Please refer to https://github.com/pytorch/audio/issues/903 for the detail.\n",
      "  '\"sox\" backend is being deprecated. '\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c93586b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jun 16 06:55:16 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.116.00   Driver Version: 418.116.00   CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM3...  On   | 00000000:59:00.0 Off |                    0 |\n",
      "| N/A   35C    P0    49W / 350W |     13MiB / 32480MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c73fdb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np_rng = np.random.default_rng(1)\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import urllib.parse\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "import os\n",
    "\n",
    "from lidbox.meta import (\n",
    "    common_voice,\n",
    "    generate_label2target,\n",
    "    verify_integrity,\n",
    "    read_audio_durations,\n",
    "    random_oversampling_on_split\n",
    ")\n",
    "\n",
    "\n",
    "train = pd.read_csv(\"/tf/datasets/train.tsv\", sep=\"\\t\")\n",
    "test = pd.read_csv(\"/tf/datasets/test.tsv\", sep=\"\\t\")\n",
    "dev = pd.read_csv(\"/tf/datasets/dev.tsv\", sep=\"\\t\")\n",
    "\n",
    "train[\"path\"] = train[\"path\"].apply(lambda x: x[:-3] + \"mp3\")\n",
    "test[\"path\"] = test[\"path\"].apply(lambda x: x[:-3] + \"mp3\")\n",
    "dev[\"path\"] = dev[\"path\"].apply(lambda x: x[:-3] + \"mp3\")\n",
    "\n",
    "train[\"split\"] = \"train\"\n",
    "test[\"split\"] = \"test\"\n",
    "dev[\"split\"] = \"dev\"\n",
    "#test = test.sample(30000, replace=False)\n",
    "meta = pd.concat([train, test, dev])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0e9ebf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-16 07:03:39.263 I numexpr.utils: Note: detected 96 virtual cores but NumExpr set to maximum of 64, check \"NUMEXPR_MAX_THREADS\" environment variable.\n",
      "2021-06-16 07:03:39.264 I numexpr.utils: Note: NumExpr detected 96 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2021-06-16 07:03:39.264 I numexpr.utils: NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>path</th>\n",
       "      <th>locale</th>\n",
       "      <th>split</th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1486</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>ru</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>1486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56701</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>kz</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>56701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3364</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>ru</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>3364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>110475</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>rw</td>\n",
       "      <td>train</td>\n",
       "      <td>3</td>\n",
       "      <td>110475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45384</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>en</td>\n",
       "      <td>train</td>\n",
       "      <td>2</td>\n",
       "      <td>45384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30751</th>\n",
       "      <td>2677</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>ru</td>\n",
       "      <td>dev</td>\n",
       "      <td>1</td>\n",
       "      <td>2677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30752</th>\n",
       "      <td>881</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>ru</td>\n",
       "      <td>dev</td>\n",
       "      <td>1</td>\n",
       "      <td>881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30753</th>\n",
       "      <td>68709</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>kz</td>\n",
       "      <td>dev</td>\n",
       "      <td>0</td>\n",
       "      <td>68709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30754</th>\n",
       "      <td>249025</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>en</td>\n",
       "      <td>dev</td>\n",
       "      <td>2</td>\n",
       "      <td>249025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30755</th>\n",
       "      <td>2986</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>uk</td>\n",
       "      <td>dev</td>\n",
       "      <td>3</td>\n",
       "      <td>2986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168971 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                               path locale  \\\n",
       "0            1486  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...     ru   \n",
       "1           56701  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...     kz   \n",
       "2            3364  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...     ru   \n",
       "3          110475  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...     rw   \n",
       "4           45384  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...     en   \n",
       "...           ...                                                ...    ...   \n",
       "30751        2677  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...     ru   \n",
       "30752         881  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...     ru   \n",
       "30753       68709  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...     kz   \n",
       "30754      249025  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...     en   \n",
       "30755        2986  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...     uk   \n",
       "\n",
       "       split  target      id  \n",
       "0      train       1    1486  \n",
       "1      train       0   56701  \n",
       "2      train       1    3364  \n",
       "3      train       3  110475  \n",
       "4      train       2   45384  \n",
       "...      ...     ...     ...  \n",
       "30751    dev       1    2677  \n",
       "30752    dev       1     881  \n",
       "30753    dev       0   68709  \n",
       "30754    dev       2  249025  \n",
       "30755    dev       3    2986  \n",
       "\n",
       "[168971 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta.loc[meta[\"locale\"] != \"kz\", \"path\"] = \"/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/\" +  meta.loc[meta[\"locale\"] != \"kz\"][\"locale\"] + \"/clips/\" + meta.loc[meta[\"locale\"] != \"kz\"][\"path\"]\n",
    "targets = {\"kz\": 0, \"ru\": 1, \"en\":2, \"other\":3}\n",
    "meta[\"target\"] = meta[\"locale\"]\n",
    "meta.loc[(meta[\"locale\"] != \"kz\") & (meta[\"locale\"] != \"ru\") & (meta[\"locale\"]!=\"en\"), \"target\"] = \"other\"\n",
    "meta = meta.loc[meta[\"path\"] != \"/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/kz/clips/5f590a130a73c.mp3\"]\n",
    "meta = meta.loc[meta[\"path\"] != \"/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/kz/clips/5ef9bd9ba7029.mp3\"]\n",
    "\n",
    "meta[\"id\"] = meta[\"Unnamed: 0\"].apply(str)\n",
    "meta[\"target\"] = meta[\"target\"].map(targets)\n",
    "\n",
    "meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4aac02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "import math\n",
    "DEVICE = 'cuda'\n",
    "def _get_sample(path, resample=None):\n",
    "  effects = [\n",
    "    [\"remix\", \"1\"]\n",
    "  ]\n",
    "  if resample:\n",
    "    effects.append([\"rate\", f'{resample}'])\n",
    "  return torchaudio.sox_effects.apply_effects_file(path, effects=effects)\n",
    "\n",
    "SAMPLE_RIR_PATH = os.path.join(os.getcwd(), \"rir.wav\")\n",
    "\n",
    "def get_rir_sample(*, resample=None, processed=False):\n",
    "    rir_raw, sample_rate = _get_sample(SAMPLE_RIR_PATH, resample=resample)\n",
    "    if not processed:\n",
    "        return rir_raw, sample_rate\n",
    "    rir = rir_raw[:, int(sample_rate*1.01):int(sample_rate*1.3)]\n",
    "    rir = rir / torch.norm(rir, p=2)\n",
    "    rir = torch.flip(rir, [1])\n",
    "    return rir, sample_rate\n",
    "\n",
    "class AudiosDataset(Dataset):\n",
    "    def __init__(self, paths=None, targets=None, augment=False) -> None:\n",
    "        self.paths = paths\n",
    "        self.targets = targets\n",
    "        self.augment = augment\n",
    "        self.extractor = torch.hub.load('s3prl/s3prl', 'audio_albert').to(DEVICE)\n",
    "        self.rir = get_rir_sample()[0]\n",
    "        \n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> dict:\n",
    "        y, sr = torchaudio.load(self.paths.iloc[idx], normalization=True)\n",
    "        \"\"\"\n",
    "        if self.augment:\n",
    "            effects = [\n",
    "                    [\"lowpass\", \"-1\", \"300\"], \n",
    "                    [\"speed\", f\"{random.uniform(0.7, 1.3)}\"],  # change speed\n",
    "                  ]\n",
    "            y, sr = torchaudio.sox_effects.apply_effects_tensor(\n",
    "                y, sr, effects)\n",
    "        #\n",
    "            \n",
    "        if self.augment:\n",
    "            # augment sound in order to imitate the room change\n",
    "            rir = self.rir[:, int(16000*1.1):int(16000*1.3)]\n",
    "            rir = rir / torch.norm(rir, p=2)\n",
    "            rir = torch.flip(rir, [1])\n",
    "            y = torch.nn.functional.conv1d(y[None, ...], rir[None, ...])[0]\n",
    "        \n",
    "        \"\"\"\n",
    "        y = torchaudio.transforms.Resample(orig_freq=sr, new_freq=16000)(y)\n",
    "        y = torchaudio.transforms.Vad(sample_rate = 16000)(y)\n",
    "\n",
    "        \"\"\"\n",
    "        if self.augment:\n",
    "            y = (0.5)*torch.randn(y.shape)\n",
    "        \"\"\"\n",
    "        fixed_length = 1024\n",
    "        with torch.no_grad():\n",
    "            representation = self.extractor(y.to(DEVICE))[0]\n",
    "        # returning result\n",
    "        representation = representation.permute(1, 0)\n",
    "        if representation.shape[1] < fixed_length:\n",
    "            representation = torch.nn.functional.pad(\n",
    "              representation, (0, fixed_length - representation.shape[1]))\n",
    "        else:\n",
    "            representation = representation[:, :fixed_length]\n",
    "        representation = representation.permute(1, 0)\n",
    "        result = {\"target\":self.targets.iloc[idx], \"representation\":representation}\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75116708",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/s3prl_s3prl_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[hubconf] can not import upstream.byol_a.hubconf: No module named 'easydict'... Pass.\n",
      "[hubconf] can not import upstream.decoar.hubconf: No module named 'mxnet'... Pass.\n",
      "[hubconf] can not import upstream.wav2vec2_hug.hubconf: No module named 'transformers'... Pass.\n",
      "[hubconf] can not import upstream.pase.hubconf: No module named 'pase'... Pass.\n",
      "[hubconf] can not import upstream.byol_a.hubconf: No module named 'easydict'... Pass.\n",
      "[hubconf] can not import upstream.decoar.hubconf: No module named 'mxnet'... Pass.\n",
      "[hubconf] can not import upstream.wav2vec2_hug.hubconf: No module named 'transformers'... Pass.\n",
      "[hubconf] can not import upstream.pase.hubconf: No module named 'pase'... Pass.\n",
      "2021-06-16 07:03:41.412 I filelock: Lock 140089916591888 acquired on /root/.cache/torch/hub/s3prl_cache/55805839eb58b56972be4a9994ca99c862d2572cfd74ae26c916e8ced5d45a7a.lock\n",
      "Using cache found in /root/.cache/torch/hub/s3prl_cache/55805839eb58b56972be4a9994ca99c862d2572cfd74ae26c916e8ced5d45a7a\n",
      "for https://www.dropbox.com/s/3wgynxmod77ha1z/states-1000000.ckpt?dl=0\n",
      "2021-06-16 07:03:41.412 I filelock: Lock 140089916591888 released on /root/.cache/torch/hub/s3prl_cache/55805839eb58b56972be4a9994ca99c862d2572cfd74ae26c916e8ced5d45a7a.lock\n",
      "[UpstreamExpert] - Using the default upstream expert config\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.7/site-packages/torchaudio/functional.py:318: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n",
      "  \"At least one mel filterbank has all zero values. \"\n",
      "/root/anaconda3/lib/python3.7/site-packages/torch/functional.py:516: UserWarning: stft will require the return_complex parameter be explicitly  specified in a future PyTorch release. Use return_complex=False  to preserve the current behavior or return_complex=True to return  a complex output. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:653.)\n",
      "  normalized, onesided, return_complex)\n",
      "/root/anaconda3/lib/python3.7/site-packages/torch/functional.py:516: UserWarning: The function torch.rfft is deprecated and will be removed in a future PyTorch release. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.fft or torch.fft.rfft. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:590.)\n",
      "  normalized, onesided, return_complex)\n"
     ]
    }
   ],
   "source": [
    "ds = AudiosDataset(meta[\"path\"], meta[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df5c8e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[hubconf] can not import upstream.byol_a.hubconf: No module named 'easydict'... Pass.\n",
      "[hubconf] can not import upstream.decoar.hubconf: No module named 'mxnet'... Pass.\n",
      "[hubconf] can not import upstream.wav2vec2_hug.hubconf: No module named 'transformers'... Pass.\n",
      "[hubconf] can not import upstream.pase.hubconf: No module named 'pase'... Pass.\n",
      "2021-06-16 07:03:45.991 I filelock: Lock 140087490421520 acquired on /root/.cache/torch/hub/s3prl_cache/55805839eb58b56972be4a9994ca99c862d2572cfd74ae26c916e8ced5d45a7a.lock\n",
      "Using cache found in /root/.cache/torch/hub/s3prl_cache/55805839eb58b56972be4a9994ca99c862d2572cfd74ae26c916e8ced5d45a7a\n",
      "for https://www.dropbox.com/s/3wgynxmod77ha1z/states-1000000.ckpt?dl=0\n",
      "2021-06-16 07:03:45.992 I filelock: Lock 140087490421520 released on /root/.cache/torch/hub/s3prl_cache/55805839eb58b56972be4a9994ca99c862d2572cfd74ae26c916e8ced5d45a7a.lock\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/s3prl_s3prl_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[UpstreamExpert] - Using the default upstream expert config\n",
      "[hubconf] can not import upstream.byol_a.hubconf: No module named 'easydict'... Pass.\n",
      "[hubconf] can not import upstream.decoar.hubconf: No module named 'mxnet'... Pass.\n",
      "[hubconf] can not import upstream.wav2vec2_hug.hubconf: No module named 'transformers'... Pass.\n",
      "[hubconf] can not import upstream.pase.hubconf: No module named 'pase'... Pass.\n",
      "2021-06-16 07:03:46.238 I filelock: Lock 140087490033808 acquired on /root/.cache/torch/hub/s3prl_cache/55805839eb58b56972be4a9994ca99c862d2572cfd74ae26c916e8ced5d45a7a.lock\n",
      "Using cache found in /root/.cache/torch/hub/s3prl_cache/55805839eb58b56972be4a9994ca99c862d2572cfd74ae26c916e8ced5d45a7a\n",
      "for https://www.dropbox.com/s/3wgynxmod77ha1z/states-1000000.ckpt?dl=0\n",
      "2021-06-16 07:03:46.238 I filelock: Lock 140087490033808 released on /root/.cache/torch/hub/s3prl_cache/55805839eb58b56972be4a9994ca99c862d2572cfd74ae26c916e8ced5d45a7a.lock\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/s3prl_s3prl_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[UpstreamExpert] - Using the default upstream expert config\n",
      "[hubconf] can not import upstream.byol_a.hubconf: No module named 'easydict'... Pass.\n",
      "[hubconf] can not import upstream.decoar.hubconf: No module named 'mxnet'... Pass.\n",
      "[hubconf] can not import upstream.wav2vec2_hug.hubconf: No module named 'transformers'... Pass.\n",
      "[hubconf] can not import upstream.pase.hubconf: No module named 'pase'... Pass.\n",
      "2021-06-16 07:03:46.486 I filelock: Lock 140087490128208 acquired on /root/.cache/torch/hub/s3prl_cache/55805839eb58b56972be4a9994ca99c862d2572cfd74ae26c916e8ced5d45a7a.lock\n",
      "Using cache found in /root/.cache/torch/hub/s3prl_cache/55805839eb58b56972be4a9994ca99c862d2572cfd74ae26c916e8ced5d45a7a\n",
      "for https://www.dropbox.com/s/3wgynxmod77ha1z/states-1000000.ckpt?dl=0\n",
      "2021-06-16 07:03:46.486 I filelock: Lock 140087490128208 released on /root/.cache/torch/hub/s3prl_cache/55805839eb58b56972be4a9994ca99c862d2572cfd74ae26c916e8ced5d45a7a.lock\n",
      "[UpstreamExpert] - Using the default upstream expert config\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/s3prl_s3prl_master\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "train_ds = AudiosDataset(meta.loc[meta[\"split\"]==\"train\"][\"path\"], meta.loc[meta[\"split\"]==\"train\"][\"target\"], augment=True)\n",
    "val_ds = AudiosDataset(meta.loc[meta[\"split\"]==\"dev\"][\"path\"], meta.loc[meta[\"split\"]==\"dev\"][\"target\"])\n",
    "test_ds = AudiosDataset(meta.loc[meta[\"split\"]==\"test\"][\"path\"], meta.loc[meta[\"split\"]==\"test\"][\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38ff9c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "import math\n",
    "import torch\n",
    "DEVICE = 'cuda'\n",
    "def _get_sample(path, resample=None):\n",
    "  effects = [\n",
    "    [\"remix\", \"1\"]\n",
    "  ]\n",
    "  if resample:\n",
    "    effects.append([\"rate\", f'{resample}'])\n",
    "  return torchaudio.sox_effects.apply_effects_file(path, effects=effects)\n",
    "\n",
    "SAMPLE_RIR_PATH = os.path.join(os.getcwd(), \"rir.wav\")\n",
    "\n",
    "def get_rir_sample(*, resample=None, processed=False):\n",
    "    rir_raw, sample_rate = _get_sample(SAMPLE_RIR_PATH, resample=resample)\n",
    "    if not processed:\n",
    "        return rir_raw, sample_rate\n",
    "    rir = rir_raw[:, int(sample_rate*1.01):int(sample_rate*1.3)]\n",
    "    rir = rir / torch.norm(rir, p=2)\n",
    "    rir = torch.flip(rir, [1])\n",
    "    return rir, sample_rate\n",
    "\n",
    "class AudiosDataset(Dataset):\n",
    "    def __init__(self, paths=None, targets=None, augment=False) -> None:\n",
    "        self.paths = paths\n",
    "        self.targets = targets\n",
    "        self.augment = augment\n",
    "        self.extractor = torch.hub.load('s3prl/s3prl', 'audio_albert').to(DEVICE)\n",
    "        self.rir = get_rir_sample()[0]\n",
    "        \n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> dict:\n",
    "        y, sr = torchaudio.load(self.paths.iloc[idx], normalization=True)\n",
    "        \"\"\"\n",
    "        if self.augment:\n",
    "            effects = [\n",
    "                    [\"lowpass\", \"-1\", \"300\"], \n",
    "                    [\"speed\", f\"{random.uniform(0.7, 1.3)}\"],  # change speed\n",
    "                  ]\n",
    "            y, sr = torchaudio.sox_effects.apply_effects_tensor(\n",
    "                y, sr, effects)\n",
    "        #\n",
    "            \n",
    "        if self.augment:\n",
    "            # augment sound in order to imitate the room change\n",
    "            rir = self.rir[:, int(16000*1.1):int(16000*1.3)]\n",
    "            rir = rir / torch.norm(rir, p=2)\n",
    "            rir = torch.flip(rir, [1])\n",
    "            y = torch.nn.functional.conv1d(y[None, ...], rir[None, ...])[0]\n",
    "        \n",
    "        \"\"\"\n",
    "        y = torchaudio.transforms.Resample(orig_freq=sr, new_freq=16000)(y)\n",
    "        y = torchaudio.transforms.Vad(sample_rate = 16000)(y)\n",
    "\n",
    "        \"\"\"\n",
    "        if self.augment:\n",
    "            y = (0.5)*torch.randn(y.shape)\n",
    "        \"\"\"\n",
    "        fixed_length = 16000 * 12\n",
    "        \n",
    "        # returning result\n",
    "        if y.shape[1] < fixed_length:\n",
    "            y = torch.nn.functional.pad(\n",
    "              y, (0, fixed_length - y.shape[1]))\n",
    "        else:\n",
    "            y = y[:, :fixed_length]\n",
    "        result = {\"target\":self.targets.iloc[idx], \"representation\":y}\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c099747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[hubconf] can not import upstream.byol_a.hubconf: No module named 'easydict'... Pass.\n",
      "[hubconf] can not import upstream.decoar.hubconf: No module named 'mxnet'... Pass.\n",
      "[hubconf] can not import upstream.wav2vec2_hug.hubconf: No module named 'transformers'... Pass.\n",
      "[hubconf] can not import upstream.pase.hubconf: No module named 'pase'... Pass.\n",
      "2021-06-16 07:04:14.150 I filelock: Lock 140087489826960 acquired on /root/.cache/torch/hub/s3prl_cache/55805839eb58b56972be4a9994ca99c862d2572cfd74ae26c916e8ced5d45a7a.lock\n",
      "Using cache found in /root/.cache/torch/hub/s3prl_cache/55805839eb58b56972be4a9994ca99c862d2572cfd74ae26c916e8ced5d45a7a\n",
      "for https://www.dropbox.com/s/3wgynxmod77ha1z/states-1000000.ckpt?dl=0\n",
      "2021-06-16 07:04:14.151 I filelock: Lock 140087489826960 released on /root/.cache/torch/hub/s3prl_cache/55805839eb58b56972be4a9994ca99c862d2572cfd74ae26c916e8ced5d45a7a.lock\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/s3prl_s3prl_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[UpstreamExpert] - Using the default upstream expert config\n",
      "torch.Size([1, 192000])\n"
     ]
    }
   ],
   "source": [
    "ds = AudiosDataset(meta[\"path\"], meta[\"target\"])\n",
    "for i in ds:\n",
    "    print(i['representation'].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3110317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[hubconf] can not import upstream.byol_a.hubconf: No module named 'easydict'... Pass.\n",
      "[hubconf] can not import upstream.decoar.hubconf: No module named 'mxnet'... Pass.\n",
      "[hubconf] can not import upstream.wav2vec2_hug.hubconf: No module named 'transformers'... Pass.\n",
      "[hubconf] can not import upstream.pase.hubconf: No module named 'pase'... Pass.\n",
      "2021-06-16 07:04:15.457 I filelock: Lock 140088624499408 acquired on /root/.cache/torch/hub/s3prl_cache/55805839eb58b56972be4a9994ca99c862d2572cfd74ae26c916e8ced5d45a7a.lock\n",
      "Using cache found in /root/.cache/torch/hub/s3prl_cache/55805839eb58b56972be4a9994ca99c862d2572cfd74ae26c916e8ced5d45a7a\n",
      "for https://www.dropbox.com/s/3wgynxmod77ha1z/states-1000000.ckpt?dl=0\n",
      "2021-06-16 07:04:15.457 I filelock: Lock 140088624499408 released on /root/.cache/torch/hub/s3prl_cache/55805839eb58b56972be4a9994ca99c862d2572cfd74ae26c916e8ced5d45a7a.lock\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/s3prl_s3prl_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[UpstreamExpert] - Using the default upstream expert config\n",
      "[hubconf] can not import upstream.byol_a.hubconf: No module named 'easydict'... Pass.\n",
      "[hubconf] can not import upstream.decoar.hubconf: No module named 'mxnet'... Pass.\n",
      "[hubconf] can not import upstream.wav2vec2_hug.hubconf: No module named 'transformers'... Pass.\n",
      "[hubconf] can not import upstream.pase.hubconf: No module named 'pase'... Pass.\n",
      "2021-06-16 07:04:15.719 I filelock: Lock 140089770107728 acquired on /root/.cache/torch/hub/s3prl_cache/55805839eb58b56972be4a9994ca99c862d2572cfd74ae26c916e8ced5d45a7a.lock\n",
      "Using cache found in /root/.cache/torch/hub/s3prl_cache/55805839eb58b56972be4a9994ca99c862d2572cfd74ae26c916e8ced5d45a7a\n",
      "for https://www.dropbox.com/s/3wgynxmod77ha1z/states-1000000.ckpt?dl=0\n",
      "2021-06-16 07:04:15.720 I filelock: Lock 140089770107728 released on /root/.cache/torch/hub/s3prl_cache/55805839eb58b56972be4a9994ca99c862d2572cfd74ae26c916e8ced5d45a7a.lock\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/s3prl_s3prl_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[UpstreamExpert] - Using the default upstream expert config\n",
      "[hubconf] can not import upstream.byol_a.hubconf: No module named 'easydict'... Pass.\n",
      "[hubconf] can not import upstream.decoar.hubconf: No module named 'mxnet'... Pass.\n",
      "[hubconf] can not import upstream.wav2vec2_hug.hubconf: No module named 'transformers'... Pass.\n",
      "[hubconf] can not import upstream.pase.hubconf: No module named 'pase'... Pass.\n",
      "2021-06-16 07:04:15.975 I filelock: Lock 140089769070160 acquired on /root/.cache/torch/hub/s3prl_cache/55805839eb58b56972be4a9994ca99c862d2572cfd74ae26c916e8ced5d45a7a.lock\n",
      "Using cache found in /root/.cache/torch/hub/s3prl_cache/55805839eb58b56972be4a9994ca99c862d2572cfd74ae26c916e8ced5d45a7a\n",
      "for https://www.dropbox.com/s/3wgynxmod77ha1z/states-1000000.ckpt?dl=0\n",
      "2021-06-16 07:04:15.975 I filelock: Lock 140089769070160 released on /root/.cache/torch/hub/s3prl_cache/55805839eb58b56972be4a9994ca99c862d2572cfd74ae26c916e8ced5d45a7a.lock\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/s3prl_s3prl_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[UpstreamExpert] - Using the default upstream expert config\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "train_ds = AudiosDataset(meta.loc[meta[\"split\"]==\"train\"][\"path\"], meta.loc[meta[\"split\"]==\"train\"][\"target\"], augment=True)\n",
    "val_ds = AudiosDataset(meta.loc[meta[\"split\"]==\"dev\"][\"path\"], meta.loc[meta[\"split\"]==\"dev\"][\"target\"])\n",
    "test_ds = AudiosDataset(meta.loc[meta[\"split\"]==\"test\"][\"path\"], meta.loc[meta[\"split\"]==\"test\"][\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b3fe8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_workers = 10\n",
    "loaders = {\n",
    "    \"train\": DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        drop_last=True,\n",
    "    ),\n",
    "    \"valid\": DataLoader(\n",
    "        val_ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        drop_last=True,\n",
    "    ),\n",
    "    \"test\":DataLoader(\n",
    "        test_ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        drop_last=True,\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "991cb3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[hubconf] can not import upstream.byol_a.hubconf: No module named 'easydict'... Pass.\n",
      "[hubconf] can not import upstream.decoar.hubconf: No module named 'mxnet'... Pass.\n",
      "[hubconf] can not import upstream.wav2vec2_hug.hubconf: No module named 'transformers'... Pass.\n",
      "[hubconf] can not import upstream.pase.hubconf: No module named 'pase'... Pass.\n",
      "2021-06-16 07:04:22.938 I filelock: Lock 140087491210576 acquired on /root/.cache/torch/hub/s3prl_cache/55805839eb58b56972be4a9994ca99c862d2572cfd74ae26c916e8ced5d45a7a.lock\n",
      "Using cache found in /root/.cache/torch/hub/s3prl_cache/55805839eb58b56972be4a9994ca99c862d2572cfd74ae26c916e8ced5d45a7a\n",
      "for https://www.dropbox.com/s/3wgynxmod77ha1z/states-1000000.ckpt?dl=0\n",
      "2021-06-16 07:04:22.938 I filelock: Lock 140087491210576 released on /root/.cache/torch/hub/s3prl_cache/55805839eb58b56972be4a9994ca99c862d2572cfd74ae26c916e8ced5d45a7a.lock\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/s3prl_s3prl_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[UpstreamExpert] - Using the default upstream expert config\n"
     ]
    }
   ],
   "source": [
    "m = torch.hub.load('s3prl/s3prl', 'audio_albert').to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2d2b345",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, extractor):\n",
    "        super().__init__()\n",
    "        self.extractor = extractor\n",
    "        self.rnn = nn.LSTM(input_size=768, hidden_size=512, num_layers=5, bidirectional=True, batch_first=True, dropout=0.7)\n",
    "        self.classifier = nn.Sequential(\n",
    "                    nn.Linear(1024, 512),\n",
    "                    nn.BatchNorm1d(512),\n",
    "                    nn.Dropout(0.5),\n",
    "                    nn.Linear(512, 4)\n",
    "                    )\n",
    "    def forward(self, x):\n",
    "        with  torch.no_grad():\n",
    "            features = self.extractor(torch.squeeze(x))\n",
    "        features = torch.stack(features)\n",
    "        res, (c1, h1) = self.rnn(features[:, 0, :].unsqueeze(1))\n",
    "        for i in range(1, features.shape[1]):\n",
    "            res, (c1, h1) = self.rnn(features[:, i, :].unsqueeze(1), (c1, h1))\n",
    "        res = self.classifier(res[:, -1, :])\n",
    "        return F.log_softmax(res, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26f0d83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Classifier(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "727f771f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train(model, opt, scheduler, loss_fn, epochs, data_tr, data_val, max_stable=5):\n",
    "    best_val_loss = 1e9\n",
    "    counter = 0\n",
    "    for epoch in range(epochs):\n",
    "        #tic = time()\n",
    "        print('* Epoch %d/%d' % (epoch+1, epochs))\n",
    "\n",
    "        avg_loss = 0\n",
    "        model.train()  # train mode\n",
    "        for batch in tqdm(data_tr):\n",
    "            loss = 0\n",
    "            # data to device\n",
    "            X_batch, Y_batch = batch[\"representation\"], batch[\"target\"]\n",
    "            #print(X_batch.shape)\n",
    "            X_batch = X_batch.to(DEVICE)\n",
    "            Y_batch = Y_batch.to(DEVICE)\n",
    "            # set parameter gradients to zero\n",
    "            opt.zero_grad()\n",
    "            # forward\n",
    "            Y_pred = model(X_batch)\n",
    "            #print(Y_pred)\n",
    "            loss = loss_fn(Y_pred, Y_batch)# forward-pass\n",
    "            loss.backward()  # backward-pass\n",
    "            opt.step()  # update weights\n",
    "            if not scheduler is None:\n",
    "                scheduler.step()\n",
    "            # calculate loss to show the user\n",
    "            avg_loss += loss / len(data_tr)\n",
    "      #  toc = time()\n",
    "        print('loss: %f' % avg_loss)\n",
    "        # show intermediate results\n",
    "        model.eval()  # testing mode\n",
    "        val_loss = 0\n",
    "        print(\"start validation\")\n",
    "        for v_b in tqdm(data_val):\n",
    "            X_val, Y_val = v_b[\"representation\"], v_b[\"target\"]\n",
    "            Y_hat = model(X_val.to(DEVICE)).detach().cpu()# detach and put into cpu\n",
    "            val_loss += loss_fn(Y_pred, Y_batch)\n",
    "        val_loss /= len(data_val)\n",
    "        print( f\"validation loss: {val_loss}\")\n",
    "        if val_loss <= best_val_loss and val_loss > 0:\n",
    "            counter = 0\n",
    "            print(\"Save new model!\")\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), f'best_model.h5')\n",
    "            best_patn = f'{epoch}_{best_val_loss}.h5'\n",
    "        else:\n",
    "            counter += 1\n",
    "        if counter == max_stable:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5b394d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2576 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2576/2576 [3:52:13<00:00,  5.41s/it]  \n",
      "  0%|          | 0/961 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.870235\n",
      "start validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/961 [00:55<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'spec'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-3fab47c5fffa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0moptimaizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamW\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCosineAnnealingWarmRestarts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimaizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT_0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT_mult\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meta_min\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimaizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"valid\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-269fc26b3e75>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, opt, scheduler, loss_fn, epochs, data_tr, data_val, max_stable)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"start validation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mv_b\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv_b\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"spec\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_b\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"target\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0mY_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# detach and put into cpu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mval_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'spec'"
     ]
    }
   ],
   "source": [
    "DEVICE = 'cuda'\n",
    "max_epochs = 100\n",
    "model = model.to(DEVICE)\n",
    "#torch.cuda.empty_cache()\n",
    "loss_fn =  nn.CrossEntropyLoss()\n",
    "optimaizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimaizer, T_0=5, T_mult=1, eta_min=1e-8, last_epoch=-1)\n",
    "train(model, optimaizer,scheduler, loss_fn, max_epochs, loaders[\"train\"], loaders[\"valid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294fdf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ec6c80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
