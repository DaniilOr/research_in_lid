{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b028f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "################################################################################\n",
      "### WARNING, path does not exist: KALDI_ROOT=/mnt/matylda5/iveselyk/Tools/kaldi-trunk\n",
      "###          (please add 'export KALDI_ROOT=<your_path>' in your $HOME/.profile)\n",
      "###          (or run as: KALDI_ROOT=<your_path> python <your_script>.py)\n",
      "################################################################################\n",
      "\n",
      "/root/anaconda3/lib/python3.7/site-packages/torchaudio/backend/utils.py:54: UserWarning: \"sox\" backend is being deprecated. The default backend will be changed to \"sox_io\" backend in 0.8.0 and \"sox\" backend will be removed in 0.9.0. Please migrate to \"sox_io\" backend. Please refer to https://github.com/pytorch/audio/issues/903 for the detail.\n",
      "  '\"sox\" backend is being deprecated. '\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5f03c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np_rng = np.random.default_rng(1)\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import urllib.parse\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "import os\n",
    "\n",
    "from lidbox.meta import (\n",
    "    common_voice,\n",
    "    generate_label2target,\n",
    "    verify_integrity,\n",
    "    read_audio_durations,\n",
    "    random_oversampling_on_split\n",
    ")\n",
    "\n",
    "\n",
    "train = pd.read_csv(\"/tf/datasets/train.tsv\", sep=\"\\t\")\n",
    "test = pd.read_csv(\"/tf/datasets/test.tsv\", sep=\"\\t\")\n",
    "dev = pd.read_csv(\"/tf/datasets/dev.tsv\", sep=\"\\t\")\n",
    "\n",
    "train[\"path\"] = train[\"path\"].apply(lambda x: x[:-3] + \"mp3\")\n",
    "test[\"path\"] = test[\"path\"].apply(lambda x: x[:-3] + \"mp3\")\n",
    "dev[\"path\"] = dev[\"path\"].apply(lambda x: x[:-3] + \"mp3\")\n",
    "\n",
    "train[\"split\"] = \"train\"\n",
    "test[\"split\"] = \"test\"\n",
    "dev[\"split\"] = \"dev\"\n",
    "#test = test.sample(30000, replace=False)\n",
    "meta = pd.concat([train, test, dev])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fdbfdd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-27 10:34:17.597 I numexpr.utils: Note: detected 96 virtual cores but NumExpr set to maximum of 64, check \"NUMEXPR_MAX_THREADS\" environment variable.\n",
      "2021-06-27 10:34:17.598 I numexpr.utils: Note: NumExpr detected 96 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2021-06-27 10:34:17.598 I numexpr.utils: NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>path</th>\n",
       "      <th>locale</th>\n",
       "      <th>split</th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1486</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>ru</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>1486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56701</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>kz</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>56701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3364</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>ru</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>3364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>110475</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>rw</td>\n",
       "      <td>train</td>\n",
       "      <td>3</td>\n",
       "      <td>110475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45384</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>en</td>\n",
       "      <td>train</td>\n",
       "      <td>2</td>\n",
       "      <td>45384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30751</th>\n",
       "      <td>2677</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>ru</td>\n",
       "      <td>dev</td>\n",
       "      <td>1</td>\n",
       "      <td>2677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30752</th>\n",
       "      <td>881</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>ru</td>\n",
       "      <td>dev</td>\n",
       "      <td>1</td>\n",
       "      <td>881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30753</th>\n",
       "      <td>68709</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>kz</td>\n",
       "      <td>dev</td>\n",
       "      <td>0</td>\n",
       "      <td>68709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30754</th>\n",
       "      <td>249025</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>en</td>\n",
       "      <td>dev</td>\n",
       "      <td>2</td>\n",
       "      <td>249025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30755</th>\n",
       "      <td>2986</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>uk</td>\n",
       "      <td>dev</td>\n",
       "      <td>3</td>\n",
       "      <td>2986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168971 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                               path locale  \\\n",
       "0            1486  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...     ru   \n",
       "1           56701  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...     kz   \n",
       "2            3364  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...     ru   \n",
       "3          110475  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...     rw   \n",
       "4           45384  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...     en   \n",
       "...           ...                                                ...    ...   \n",
       "30751        2677  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...     ru   \n",
       "30752         881  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...     ru   \n",
       "30753       68709  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...     kz   \n",
       "30754      249025  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...     en   \n",
       "30755        2986  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...     uk   \n",
       "\n",
       "       split  target      id  \n",
       "0      train       1    1486  \n",
       "1      train       0   56701  \n",
       "2      train       1    3364  \n",
       "3      train       3  110475  \n",
       "4      train       2   45384  \n",
       "...      ...     ...     ...  \n",
       "30751    dev       1    2677  \n",
       "30752    dev       1     881  \n",
       "30753    dev       0   68709  \n",
       "30754    dev       2  249025  \n",
       "30755    dev       3    2986  \n",
       "\n",
       "[168971 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta.loc[meta[\"locale\"] != \"kz\", \"path\"] = \"/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/\" +  meta.loc[meta[\"locale\"] != \"kz\"][\"locale\"] + \"/clips/\" + meta.loc[meta[\"locale\"] != \"kz\"][\"path\"]\n",
    "targets = {\"kz\": 0, \"ru\": 1, \"en\":2, \"other\":3}\n",
    "meta[\"target\"] = meta[\"locale\"]\n",
    "meta.loc[(meta[\"locale\"] != \"kz\") & (meta[\"locale\"] != \"ru\") & (meta[\"locale\"]!=\"en\"), \"target\"] = \"other\"\n",
    "meta = meta.loc[meta[\"path\"] != \"/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/kz/clips/5f590a130a73c.mp3\"]\n",
    "meta = meta.loc[meta[\"path\"] != \"/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/kz/clips/5ef9bd9ba7029.mp3\"]\n",
    "\n",
    "meta[\"id\"] = meta[\"Unnamed: 0\"].apply(str)\n",
    "meta[\"target\"] = meta[\"target\"].map(targets)\n",
    "\n",
    "meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e4c5a21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "import math\n",
    "\n",
    "def _get_sample(path, resample=None):\n",
    "  effects = [\n",
    "    [\"remix\", \"1\"]\n",
    "  ]\n",
    "  if resample:\n",
    "    effects.append([\"rate\", f'{resample}'])\n",
    "  return torchaudio.sox_effects.apply_effects_file(path, effects=effects)\n",
    "\n",
    "SAMPLE_RIR_PATH = os.path.join(os.getcwd(), \"rir.wav\")\n",
    "\n",
    "def get_rir_sample(*, resample=None, processed=False):\n",
    "    rir_raw, sample_rate = _get_sample(SAMPLE_RIR_PATH, resample=resample)\n",
    "    if not processed:\n",
    "        return rir_raw, sample_rate\n",
    "    rir = rir_raw[:, int(sample_rate*1.01):int(sample_rate*1.3)]\n",
    "    rir = rir / torch.norm(rir, p=2)\n",
    "    rir = torch.flip(rir, [1])\n",
    "    return rir, sample_rate\n",
    "\n",
    "class AudiosDataset(Dataset):\n",
    "    def __init__(self, paths=None, targets=None, augment=False) -> None:\n",
    "        self.paths = paths\n",
    "        self.targets = targets\n",
    "        self.augment = augment\n",
    "        self.rir = get_rir_sample()[0]\n",
    "        \n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> dict:\n",
    "        y, sr = torchaudio.load(self.paths.iloc[idx])\n",
    "        \"\"\"\n",
    "        if self.augment:\n",
    "            effects = [\n",
    "                    [\"lowpass\", \"-1\", \"300\"], \n",
    "                    [\"speed\", f\"{random.uniform(0.7, 1.3)}\"],  # change speed\n",
    "                  ]\n",
    "            y, sr = torchaudio.sox_effects.apply_effects_tensor(\n",
    "                y, sr, effects)\n",
    "        #\n",
    "            \n",
    "        if self.augment:\n",
    "            # augment sound in order to imitate the room change\n",
    "            rir = self.rir[:, int(16000*1.1):int(16000*1.3)]\n",
    "            rir = rir / torch.norm(rir, p=2)\n",
    "            rir = torch.flip(rir, [1])\n",
    "            y = torch.nn.functional.conv1d(y[None, ...], rir[None, ...])[0]\n",
    "        \n",
    "        \"\"\"\n",
    "        y = torchaudio.transforms.Resample(orig_freq=sr, new_freq=16000)(y)\n",
    "        y = torchaudio.transforms.Vad(sample_rate = 16000)(y)\n",
    "\n",
    "        \"\"\"\n",
    "        if self.augment:\n",
    "            y = (0.5)*torch.randn(y.shape)\n",
    "        \"\"\"\n",
    "        # convert to spectogram\n",
    "        spectogram = torchaudio.transforms.MFCC(n_mfcc=30)(y)\n",
    "        #spectogram = torch.log(spectogram + 1e-5)\n",
    "        melspectogram_db = torchaudio.transforms.AmplitudeToDB()(spectogram)\n",
    "        \n",
    "        #Make sure all spectrograms are the same size\n",
    "        fixed_length = 8 * (16000//200)\n",
    "        \n",
    "        if melspectogram_db.shape[2] < fixed_length:\n",
    "            melspectogram_db = torch.nn.functional.pad(\n",
    "              melspectogram_db, (0, fixed_length - melspectogram_db.shape[2]))\n",
    "        else:\n",
    "            melspectogram_db = melspectogram_db[:, :, :fixed_length]\n",
    "        \n",
    "        spectogram = melspectogram_db\n",
    "        \n",
    "        if self.augment:\n",
    "\n",
    "            spectogram = torchaudio.transforms.FrequencyMasking(100)(spectogram)\n",
    "            spectogram = torchaudio.transforms.TimeMasking(100)(spectogram)\n",
    "        \n",
    "        # returning result\n",
    "        result = {\"spec\": spectogram, \"target\":self.targets.iloc[idx]}\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "62697419",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "train_ds = AudiosDataset(meta.loc[meta[\"split\"]==\"train\"].sample(frac=1)[\"path\"], meta.loc[meta[\"split\"]==\"train\"][\"target\"], augment=True)\n",
    "val_ds = AudiosDataset(meta.loc[meta[\"split\"]==\"dev\"].sample(frac=1)[\"path\"], meta.loc[meta[\"split\"]==\"dev\"][\"target\"])\n",
    "test_ds = AudiosDataset(meta.loc[meta[\"split\"]==\"test\"].sample(frac=1)[\"path\"], meta.loc[meta[\"split\"]==\"test\"][\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d22ea244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 30, 640])\n"
     ]
    }
   ],
   "source": [
    "for i in train_ds:\n",
    "    print(i['spec'].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "77492ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "num_workers = 20\n",
    "loaders = {\n",
    "    \"train\": DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        drop_last=True,\n",
    "    ),\n",
    "    \"valid\": DataLoader(\n",
    "        val_ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        drop_last=True,\n",
    "    ),\n",
    "    \"test\":DataLoader(\n",
    "        test_ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        drop_last=True,\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8676c455",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "class simpleTDNN(nn.Module):\n",
    "\n",
    "    def __init__(self, numSpkrs, p_dropout):\n",
    "        super(simpleTDNN, self).__init__()\n",
    "        self.tdnn1 = nn.Conv1d(in_channels=30, out_channels=128, kernel_size=5, dilation=1)\n",
    "        self.bn_tdnn1 = nn.BatchNorm1d(128, momentum=0.1, affine=False)\n",
    "        self.dropout_tdnn1 = nn.Dropout(p=p_dropout)\n",
    "\n",
    "        self.tdnn2 = nn.Conv1d(in_channels=128, out_channels=128, kernel_size=5, dilation=2)\n",
    "        self.bn_tdnn2 = nn.BatchNorm1d(128, momentum=0.1, affine=False)\n",
    "        self.dropout_tdnn2 = nn.Dropout(p=p_dropout)\n",
    "\n",
    "        self.tdnn3 = nn.Conv1d(in_channels=128, out_channels=128, kernel_size=1, dilation=1)\n",
    "        self.bn_tdnn3 = nn.BatchNorm1d(128, momentum=0.1, affine=False)\n",
    "        self.dropout_tdnn3 = nn.Dropout(p=p_dropout)\n",
    "\n",
    "        self.fc1 = nn.Linear(2*128,128)\n",
    "        self.bn_fc1 = nn.BatchNorm1d(128, momentum=0.1, affine=False)\n",
    "        self.dropout_fc1 = nn.Dropout(p=p_dropout)\n",
    "\n",
    "        self.fc2 = nn.Linear(128,64)\n",
    "        self.bn_fc2 = nn.BatchNorm1d(64, momentum=0.1, affine=False)\n",
    "        self.dropout_fc2 = nn.Dropout(p=p_dropout)\n",
    "\n",
    "        self.fc3 = nn.Linear(64,numSpkrs)\n",
    "\n",
    "    def forward(self, x, eps):\n",
    "        # Note: x must be (batch_size, feat_dim, chunk_len)\n",
    "\n",
    "        x = self.dropout_tdnn1(self.bn_tdnn1(F.relu(self.tdnn1(x))))\n",
    "        x = self.dropout_tdnn2(self.bn_tdnn2(F.relu(self.tdnn2(x))))\n",
    "        x = self.dropout_tdnn3(self.bn_tdnn3(F.relu(self.tdnn3(x))))\n",
    "\n",
    "        if self.training:\n",
    "            x = x + torch.randn(x.size()).cuda()*eps\n",
    "        stats = torch.cat((x.mean(dim=2), x.std(dim=2)), dim=1)\n",
    "        x = self.dropout_fc1(self.bn_fc1(F.relu(self.fc1(stats))))\n",
    "        x = self.dropout_fc2(self.bn_fc2(F.relu(self.fc2(x))))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class xvecTDNN(nn.Module):\n",
    "\n",
    "    def __init__(self, numSpkrs, p_dropout):\n",
    "        super(xvecTDNN, self).__init__()\n",
    "        self.tdnn1 = nn.Conv1d(in_channels=30, out_channels=512, kernel_size=5, dilation=1)\n",
    "        self.bn_tdnn1 = nn.BatchNorm1d(512, momentum=0.1, affine=False)\n",
    "        self.dropout_tdnn1 = nn.Dropout(p=p_dropout)\n",
    "\n",
    "        self.tdnn2 = nn.Conv1d(in_channels=512, out_channels=512, kernel_size=5, dilation=2)\n",
    "        self.bn_tdnn2 = nn.BatchNorm1d(512, momentum=0.1, affine=False)\n",
    "        self.dropout_tdnn2 = nn.Dropout(p=p_dropout)\n",
    "\n",
    "        self.tdnn3 = nn.Conv1d(in_channels=512, out_channels=512, kernel_size=7, dilation=3)\n",
    "        self.bn_tdnn3 = nn.BatchNorm1d(512, momentum=0.1, affine=False)\n",
    "        self.dropout_tdnn3 = nn.Dropout(p=p_dropout)\n",
    "\n",
    "        self.tdnn4 = nn.Conv1d(in_channels=512, out_channels=512, kernel_size=1, dilation=1)\n",
    "        self.bn_tdnn4 = nn.BatchNorm1d(512, momentum=0.1, affine=False)\n",
    "        self.dropout_tdnn4 = nn.Dropout(p=p_dropout)\n",
    "\n",
    "        self.tdnn5 = nn.Conv1d(in_channels=512, out_channels=1500, kernel_size=1, dilation=1)\n",
    "        self.bn_tdnn5 = nn.BatchNorm1d(1500, momentum=0.1, affine=False)\n",
    "        self.dropout_tdnn5 = nn.Dropout(p=p_dropout)\n",
    "\n",
    "        self.fc1 = nn.Linear(3000,512)\n",
    "        self.bn_fc1 = nn.BatchNorm1d(512, momentum=0.1, affine=False)\n",
    "        self.dropout_fc1 = nn.Dropout(p=p_dropout)\n",
    "\n",
    "        self.fc2 = nn.Linear(512,512)\n",
    "        self.bn_fc2 = nn.BatchNorm1d(512, momentum=0.1, affine=False)\n",
    "        self.dropout_fc2 = nn.Dropout(p=p_dropout)\n",
    "\n",
    "        self.fc3 = nn.Linear(512,numSpkrs)\n",
    "\n",
    "    def forward(self, x, eps):\n",
    "        # Note: x must be (batch_size, feat_dim, chunk_len)\n",
    "\n",
    "        x = self.dropout_tdnn1(self.bn_tdnn1(F.relu(self.tdnn1(x))))\n",
    "        x = self.dropout_tdnn2(self.bn_tdnn2(F.relu(self.tdnn2(x))))\n",
    "        x = self.dropout_tdnn3(self.bn_tdnn3(F.relu(self.tdnn3(x))))\n",
    "        x = self.dropout_tdnn4(self.bn_tdnn4(F.relu(self.tdnn4(x))))\n",
    "        x = self.dropout_tdnn5(self.bn_tdnn5(F.relu(self.tdnn5(x))))\n",
    "\n",
    "        if self.training:\n",
    "            shape = x.size()\n",
    "            noise = torch.cuda.FloatTensor(shape)\n",
    "            torch.randn(shape, out=noise)\n",
    "            x += noise*eps\n",
    "\n",
    "        stats = torch.cat((x.mean(dim=2), x.std(dim=2)), dim=1)\n",
    "        x = self.dropout_fc1(self.bn_fc1(F.relu(self.fc1(stats))))\n",
    "        x = self.dropout_fc2(self.bn_fc2(F.relu(self.fc2(x))))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class proto_xvecTDNN(nn.Module):\n",
    "\n",
    "    def __init__(self, numSpkrs, p_dropout):\n",
    "        super(proto_xvecTDNN, self).__init__()\n",
    "        self.tdnn1 = nn.Conv1d(in_channels=30, out_channels=512, kernel_size=5, dilation=1)\n",
    "        self.bn_tdnn1 = nn.BatchNorm1d(512, momentum=0.1, affine=False)\n",
    "        self.dropout_tdnn1 = nn.Dropout(p=p_dropout)\n",
    "\n",
    "        self.tdnn2 = nn.Conv1d(in_channels=512, out_channels=512, kernel_size=5, dilation=2)\n",
    "        self.bn_tdnn2 = nn.BatchNorm1d(512, momentum=0.1, affine=False)\n",
    "        self.dropout_tdnn2 = nn.Dropout(p=p_dropout)\n",
    "\n",
    "        self.tdnn3 = nn.Conv1d(in_channels=512, out_channels=512, kernel_size=7, dilation=3)\n",
    "        self.bn_tdnn3 = nn.BatchNorm1d(512, momentum=0.1, affine=False)\n",
    "        self.dropout_tdnn3 = nn.Dropout(p=p_dropout)\n",
    "\n",
    "        self.tdnn4 = nn.Conv1d(in_channels=512, out_channels=512, kernel_size=1, dilation=1)\n",
    "        self.bn_tdnn4 = nn.BatchNorm1d(512, momentum=0.1, affine=False)\n",
    "        self.dropout_tdnn4 = nn.Dropout(p=p_dropout)\n",
    "\n",
    "        self.tdnn5 = nn.Conv1d(in_channels=512, out_channels=1500, kernel_size=1, dilation=1)\n",
    "        self.bn_tdnn5 = nn.BatchNorm1d(1500, momentum=0.1, affine=False)\n",
    "        self.dropout_tdnn5 = nn.Dropout(p=p_dropout)\n",
    "\n",
    "        self.fc1 = nn.Linear(3000,512)\n",
    "        self.bn_fc1 = nn.BatchNorm1d(512, momentum=0.1, affine=False)\n",
    "        self.dropout_fc1 = nn.Dropout(p=p_dropout)\n",
    "\n",
    "        self.fc2 = nn.Linear(512,512)\n",
    "        self.bn_fc2 = nn.BatchNorm1d(512, momentum=0.1, affine=False)\n",
    "        self.dropout_fc2 = nn.Dropout(p=p_dropout)\n",
    "\n",
    "        self.fc3 = nn.Linear(512,512)\n",
    "        self.bn_fc3 = nn.BatchNorm1d(512, momentum=0.1, affine=False)\n",
    "        self.dropout_fc3 = nn.Dropout(p=p_dropout)\n",
    "\n",
    "        self.fc4 = nn.Linear(512,512)\n",
    "\n",
    "    def forward(self, x, eps):\n",
    "        # Note: x must be (batch_size, feat_dim, chunk_len)\n",
    "\n",
    "        x = self.dropout_tdnn1(self.bn_tdnn1(F.relu(self.tdnn1(x))))\n",
    "        x = self.dropout_tdnn2(self.bn_tdnn2(F.relu(self.tdnn2(x))))\n",
    "        x = self.dropout_tdnn3(self.bn_tdnn3(F.relu(self.tdnn3(x))))\n",
    "        x = self.dropout_tdnn4(self.bn_tdnn4(F.relu(self.tdnn4(x))))\n",
    "        x = self.dropout_tdnn5(self.bn_tdnn5(F.relu(self.tdnn5(x))))\n",
    "\n",
    "        if self.training:\n",
    "            shape = x.size()\n",
    "            noise = torch.cuda.FloatTensor(shape)\n",
    "            torch.randn(shape, out=noise)\n",
    "            x += noise*eps\n",
    "\n",
    "        stats = torch.cat((x.mean(dim=2), x.std(dim=2)), dim=1)\n",
    "        x = self.dropout_fc1(self.bn_fc1(F.relu(self.fc1(stats))))\n",
    "        x = self.dropout_fc2(self.bn_fc2(F.relu(self.fc2(x))))\n",
    "        x = self.dropout_fc3(self.bn_fc3(F.relu(self.fc3(x))))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class relation_encoder_xvecTDNN(nn.Module):\n",
    "\n",
    "    def __init__(self, numSpkrs, p_dropout):\n",
    "        super(relation_encoder_xvecTDNN, self).__init__()\n",
    "        self.tdnn1 = nn.Conv1d(in_channels=30, out_channels=512, kernel_size=5, dilation=1)\n",
    "        self.bn_tdnn1 = nn.BatchNorm1d(512, momentum=0.1, affine=False)\n",
    "        self.dropout_tdnn1 = nn.Dropout(p=p_dropout)\n",
    "\n",
    "        self.tdnn2 = nn.Conv1d(in_channels=512, out_channels=512, kernel_size=5, dilation=2)\n",
    "        self.bn_tdnn2 = nn.BatchNorm1d(512, momentum=0.1, affine=False)\n",
    "        self.dropout_tdnn2 = nn.Dropout(p=p_dropout)\n",
    "\n",
    "        self.tdnn3 = nn.Conv1d(in_channels=512, out_channels=512, kernel_size=7, dilation=3)\n",
    "        self.bn_tdnn3 = nn.BatchNorm1d(512, momentum=0.1, affine=False)\n",
    "        self.dropout_tdnn3 = nn.Dropout(p=p_dropout)\n",
    "\n",
    "        self.tdnn4 = nn.Conv1d(in_channels=512, out_channels=512, kernel_size=1, dilation=1)\n",
    "        self.bn_tdnn4 = nn.BatchNorm1d(512, momentum=0.1, affine=False)\n",
    "        self.dropout_tdnn4 = nn.Dropout(p=p_dropout)\n",
    "\n",
    "        self.tdnn5 = nn.Conv1d(in_channels=512, out_channels=1500, kernel_size=1, dilation=1)\n",
    "        self.bn_tdnn5 = nn.BatchNorm1d(1500, momentum=0.1, affine=False)\n",
    "        self.dropout_tdnn5 = nn.Dropout(p=p_dropout)\n",
    "\n",
    "        self.fc1 = nn.Linear(3000,512)\n",
    "        self.bn_fc1 = nn.BatchNorm1d(512, momentum=0.1, affine=False)\n",
    "        self.dropout_fc1 = nn.Dropout(p=p_dropout)\n",
    "\n",
    "        self.fc2 = nn.Linear(512,512)\n",
    "        self.bn_fc2 = nn.BatchNorm1d(512, momentum=0.1, affine=False)\n",
    "        self.dropout_fc2 = nn.Dropout(p=p_dropout)\n",
    "\n",
    "        self.fc3 = nn.Linear(512,512)\n",
    "\n",
    "    def forward(self, x, eps=1e-9):\n",
    "        # Note: x must be (batch_size, feat_dim, chunk_len)\n",
    "\n",
    "        x = self.dropout_tdnn1(self.bn_tdnn1(F.relu(self.tdnn1(x))))\n",
    "        x = self.dropout_tdnn2(self.bn_tdnn2(F.relu(self.tdnn2(x))))\n",
    "        x = self.dropout_tdnn3(self.bn_tdnn3(F.relu(self.tdnn3(x))))\n",
    "        x = self.dropout_tdnn4(self.bn_tdnn4(F.relu(self.tdnn4(x))))\n",
    "        x = self.dropout_tdnn5(self.bn_tdnn5(F.relu(self.tdnn5(x))))\n",
    "\n",
    "        if self.training:\n",
    "            shape = x.size()\n",
    "            noise = torch.cuda.FloatTensor(shape)\n",
    "            torch.randn(shape, out=noise)\n",
    "            x += noise*eps\n",
    "\n",
    "        stats = torch.cat((x.mean(dim=2), x.std(dim=2)), dim=1)\n",
    "        x = self.dropout_fc1(self.bn_fc1(F.relu(self.fc1(stats))))\n",
    "        x = self.dropout_fc2(self.bn_fc2(F.relu(self.fc2(x))))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5554da5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class classifier(nn.Module):\n",
    "\n",
    "    def __init__(self, n_classes):\n",
    "        super(classifier, self).__init__()\n",
    "        self.clf = nn.Sequential(\n",
    "                    nn.Linear(512, 256),\n",
    "                    nn.ReLU(),\n",
    "                    nn.BatchNorm1d(256),\n",
    "                    nn.Dropout(0.5),\n",
    "                    nn.Linear(256, n_classes),\n",
    "                    nn.Softmax(dim=1),\n",
    "                    )\n",
    "    def forward(self, x):\n",
    "        # Note: x must be (batch_size, feat_dim, chunk_len)\n",
    "        return self.clf(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "24e5b3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = xvecTDNN(4, 0.8)\n",
    "clf1 = classifier(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078b0fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in loaders['train']:\n",
    "    print(i['spec'].shape)\n",
    "    reshaped = i['spec'].squeeze(1)#.permute(0,2,1)\n",
    "    print(reshaped.shape)\n",
    "    r = extractor(reshaped.to('cuda'), 1e-5)\n",
    "    print(r.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eec7b8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034c380a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865d0799",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8759a01d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "14857e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 640])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected 3-dimensional input for 3-dimensional weight [512, 30, 5], but got 4-dimensional input of size [1, 1, 128, 640] instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-d03cd13e5ae7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'spec'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'spec'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-19aa4694b1f0>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, eps)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;31m# Note: x must be (batch_size, feat_dim, chunk_len)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_tdnn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn_tdnn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtdnn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_tdnn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn_tdnn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtdnn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_tdnn3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn_tdnn3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtdnn3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    257\u001b[0m                             _single(0), self.dilation, self.groups)\n\u001b[1;32m    258\u001b[0m         return F.conv1d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 259\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected 3-dimensional input for 3-dimensional weight [512, 30, 5], but got 4-dimensional input of size [1, 1, 128, 640] instead"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "for i in train_ds:\n",
    "    print(i['spec'].shape)\n",
    "    y = extractor(i['spec'].unsqueeze(0), 1e-9)\n",
    "    print(y.shape)\n",
    "    if c == 10:\n",
    "        break\n",
    "    else:\n",
    "        c+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "03d840ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-27 10:47:57.623 I speechbrain.pretrained.fetching: Fetch hyperparams.yaml: Using existing file/symlink in pretrained_models/spkrec-xvect-voxceleb/hyperparams.yaml.\n",
      "2021-06-27 10:47:57.723 I speechbrain.pretrained.fetching: Fetch embedding_model.ckpt: Using existing file/symlink in pretrained_models/spkrec-xvect-voxceleb/embedding_model.ckpt.\n",
      "2021-06-27 10:47:57.724 I speechbrain.pretrained.fetching: Fetch mean_var_norm_emb.ckpt: Using existing file/symlink in pretrained_models/spkrec-xvect-voxceleb/mean_var_norm_emb.ckpt.\n",
      "2021-06-27 10:47:57.724 I speechbrain.pretrained.fetching: Fetch classifier.ckpt: Using existing file/symlink in pretrained_models/spkrec-xvect-voxceleb/classifier.ckpt.\n",
      "2021-06-27 10:47:57.725 I speechbrain.pretrained.fetching: Fetch label_encoder.txt: Using existing file/symlink in pretrained_models/spkrec-xvect-voxceleb/label_encoder.ckpt.\n",
      "2021-06-27 10:47:57.725 I speechbrain.utils.parameter_transfer: Loading pretrained files for: embedding_model, mean_var_norm_emb, classifier, label_encoder\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "div() got an unexpected keyword argument 'rounding_mode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/speechbrain/lobes/models/Xvector.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, lens)\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() got an unexpected keyword argument 'lengths'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-08c9af4a324b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEncoderClassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_hparams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"speechbrain/spkrec-xvect-voxceleb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msavedir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pretrained_models/spkrec-xvect-voxceleb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msignal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mtorchaudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/speechbrain/pretrained/interfaces.py\u001b[0m in \u001b[0;36mencode_batch\u001b[0;34m(self, wavs, wav_lens, normalize)\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0mfeats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwavs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0mfeats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_var_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwav_lens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwav_lens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             embeddings = self.hparams.mean_var_norm_emb(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/speechbrain/lobes/models/Xvector.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, lens)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/speechbrain/nnet/CNN.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"same\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m             x = self._manage_padding(\n\u001b[0;32m--> 395\u001b[0;31m                 \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m             )\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/speechbrain/nnet/CNN.py\u001b[0m in \u001b[0;36m_manage_padding\u001b[0;34m(self, x, kernel_size, dilation, stride)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0;31m# Time padding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         \u001b[0mpadding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_padding_elem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m         \u001b[0;31m# Applying padding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/speechbrain/nnet/CNN.py\u001b[0m in \u001b[0;36mget_padding_elem\u001b[0;34m(L_in, stride, kernel_size, dilation)\u001b[0m\n\u001b[1;32m   1053\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m         \u001b[0mtot_padding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdilation\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkernel_size\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1055\u001b[0;31m         \u001b[0mhalf_padding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtot_padding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrounding_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"floor\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1056\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1057\u001b[0m         \u001b[0mpadding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mhalf_padding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhalf_padding\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: div() got an unexpected keyword argument 'rounding_mode'"
     ]
    }
   ],
   "source": [
    "import torchaudio\n",
    "from speechbrain.pretrained import EncoderClassifier\n",
    "classifier = EncoderClassifier.from_hparams(source=\"speechbrain/spkrec-xvect-voxceleb\", savedir=\"pretrained_models/spkrec-xvect-voxceleb\")\n",
    "signal, fs =torchaudio.load(meta.iloc[0]['path'])\n",
    "embeddings = classifier.encode_batch(signal.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27126744",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
