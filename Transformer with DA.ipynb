{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f6f4ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "################################################################################\n",
      "### WARNING, path does not exist: KALDI_ROOT=/mnt/matylda5/iveselyk/Tools/kaldi-trunk\n",
      "###          (please add 'export KALDI_ROOT=<your_path>' in your $HOME/.profile)\n",
      "###          (or run as: KALDI_ROOT=<your_path> python <your_script>.py)\n",
      "################################################################################\n",
      "\n",
      "/root/anaconda3/lib/python3.7/site-packages/torchaudio/backend/utils.py:54: UserWarning: \"sox\" backend is being deprecated. The default backend will be changed to \"sox_io\" backend in 0.8.0 and \"sox\" backend will be removed in 0.9.0. Please migrate to \"sox_io\" backend. Please refer to https://github.com/pytorch/audio/issues/903 for the detail.\n",
      "  '\"sox\" backend is being deprecated. '\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53979b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np_rng = np.random.default_rng(1)\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import urllib.parse\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "import os\n",
    "\n",
    "from lidbox.meta import (\n",
    "    common_voice,\n",
    "    generate_label2target,\n",
    "    verify_integrity,\n",
    "    read_audio_durations,\n",
    "    random_oversampling_on_split\n",
    ")\n",
    "\n",
    "\n",
    "train = pd.read_csv(\"/tf/datasets/train.tsv\", sep=\"\\t\")\n",
    "test = pd.read_csv(\"/tf/datasets/test.tsv\", sep=\"\\t\")\n",
    "dev = pd.read_csv(\"/tf/datasets/dev.tsv\", sep=\"\\t\")\n",
    "\n",
    "train[\"path\"] = train[\"path\"].apply(lambda x: x[:-3] + \"mp3\")\n",
    "test[\"path\"] = test[\"path\"].apply(lambda x: x[:-3] + \"mp3\")\n",
    "dev[\"path\"] = dev[\"path\"].apply(lambda x: x[:-3] + \"mp3\")\n",
    "\n",
    "train[\"split\"] = \"train\"\n",
    "test[\"split\"] = \"test\"\n",
    "dev[\"split\"] = \"dev\"\n",
    "vox = pd.read_csv(\"/tf/datasets/new_dev.tsv\", sep=\"\\t\")\n",
    "\n",
    "#test = test.sample(30000, replace=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ceb5e8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vox = pd.concat([vox] * 4)\n",
    "vox = vox.iloc[:82449]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0baf13c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((82449, 3), (82449, 4))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vox.shape, train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d20ffcb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>path</th>\n",
       "      <th>locale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>535</td>\n",
       "      <td>common_voice_ta_19093662.mp3</td>\n",
       "      <td>ta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>147407</td>\n",
       "      <td>common_voice_es_20252168.mp3</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53670</td>\n",
       "      <td>common_voice_it_23740290.mp3</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6394</td>\n",
       "      <td>common_voice_pl_22062475.mp3</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>272713</td>\n",
       "      <td>common_voice_fr_23921769.mp3</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24394</th>\n",
       "      <td>855</td>\n",
       "      <td>/tf/datasets/vox/ru_dev/6c0Fse9NrvQ__U__S102--...</td>\n",
       "      <td>ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24395</th>\n",
       "      <td>882</td>\n",
       "      <td>/tf/datasets/vox/ru_dev/n0uowclQ704__U__S136--...</td>\n",
       "      <td>ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24396</th>\n",
       "      <td>252</td>\n",
       "      <td>/tf/datasets/vox/ru_dev/3QNx2bMb7tM__U__S0---0...</td>\n",
       "      <td>ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24397</th>\n",
       "      <td>2796</td>\n",
       "      <td>/tf/datasets/vox/ru_dev/CfBlKGX094o__U__S278--...</td>\n",
       "      <td>ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24398</th>\n",
       "      <td>313</td>\n",
       "      <td>/tf/datasets/vox/ru_dev/PlqiRe7CEOY__U__S17---...</td>\n",
       "      <td>ru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82449 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                               path locale\n",
       "0             535                       common_voice_ta_19093662.mp3     ta\n",
       "1          147407                       common_voice_es_20252168.mp3     es\n",
       "2           53670                       common_voice_it_23740290.mp3     it\n",
       "3            6394                       common_voice_pl_22062475.mp3     pl\n",
       "4          272713                       common_voice_fr_23921769.mp3     fr\n",
       "...           ...                                                ...    ...\n",
       "24394         855  /tf/datasets/vox/ru_dev/6c0Fse9NrvQ__U__S102--...     ru\n",
       "24395         882  /tf/datasets/vox/ru_dev/n0uowclQ704__U__S136--...     ru\n",
       "24396         252  /tf/datasets/vox/ru_dev/3QNx2bMb7tM__U__S0---0...     ru\n",
       "24397        2796  /tf/datasets/vox/ru_dev/CfBlKGX094o__U__S278--...     ru\n",
       "24398         313  /tf/datasets/vox/ru_dev/PlqiRe7CEOY__U__S17---...     ru\n",
       "\n",
       "[82449 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vox.loc[vox['locale'] == 'ru', 'path'] = vox.loc[vox['locale'] == 'ru', 'path'].apply(lambda x: f\"/tf/datasets/vox/ru_dev/{x}\")\n",
    "vox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8c84092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>path</th>\n",
       "      <th>locale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>535</td>\n",
       "      <td>common_voice_ta_19093662.mp3</td>\n",
       "      <td>ta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>147407</td>\n",
       "      <td>common_voice_es_20252168.mp3</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53670</td>\n",
       "      <td>common_voice_it_23740290.mp3</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6394</td>\n",
       "      <td>common_voice_pl_22062475.mp3</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>272713</td>\n",
       "      <td>common_voice_fr_23921769.mp3</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24394</th>\n",
       "      <td>855</td>\n",
       "      <td>/tf/datasets/vox/ru_dev/6c0Fse9NrvQ__U__S102--...</td>\n",
       "      <td>ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24395</th>\n",
       "      <td>882</td>\n",
       "      <td>/tf/datasets/vox/ru_dev/n0uowclQ704__U__S136--...</td>\n",
       "      <td>ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24396</th>\n",
       "      <td>252</td>\n",
       "      <td>/tf/datasets/vox/ru_dev/3QNx2bMb7tM__U__S0---0...</td>\n",
       "      <td>ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24397</th>\n",
       "      <td>2796</td>\n",
       "      <td>/tf/datasets/vox/ru_dev/CfBlKGX094o__U__S278--...</td>\n",
       "      <td>ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24398</th>\n",
       "      <td>313</td>\n",
       "      <td>/tf/datasets/vox/ru_dev/PlqiRe7CEOY__U__S17---...</td>\n",
       "      <td>ru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82449 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                               path locale\n",
       "0             535                       common_voice_ta_19093662.mp3     ta\n",
       "1          147407                       common_voice_es_20252168.mp3     es\n",
       "2           53670                       common_voice_it_23740290.mp3     it\n",
       "3            6394                       common_voice_pl_22062475.mp3     pl\n",
       "4          272713                       common_voice_fr_23921769.mp3     fr\n",
       "...           ...                                                ...    ...\n",
       "24394         855  /tf/datasets/vox/ru_dev/6c0Fse9NrvQ__U__S102--...     ru\n",
       "24395         882  /tf/datasets/vox/ru_dev/n0uowclQ704__U__S136--...     ru\n",
       "24396         252  /tf/datasets/vox/ru_dev/3QNx2bMb7tM__U__S0---0...     ru\n",
       "24397        2796  /tf/datasets/vox/ru_dev/CfBlKGX094o__U__S278--...     ru\n",
       "24398         313  /tf/datasets/vox/ru_dev/PlqiRe7CEOY__U__S17---...     ru\n",
       "\n",
       "[82449 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vox.loc[vox['locale'] == 'en', 'path'] = vox.loc[vox['locale'] == 'en', 'path'].apply(lambda x: f\"/tf/datasets/vox/en_dev/{x}\")\n",
    "vox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40bfcc9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>path</th>\n",
       "      <th>locale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>535</td>\n",
       "      <td>common_voice_ta_19093662.mp3</td>\n",
       "      <td>ta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>147407</td>\n",
       "      <td>common_voice_es_20252168.mp3</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53670</td>\n",
       "      <td>common_voice_it_23740290.mp3</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6394</td>\n",
       "      <td>common_voice_pl_22062475.mp3</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>272713</td>\n",
       "      <td>common_voice_fr_23921769.mp3</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24394</th>\n",
       "      <td>855</td>\n",
       "      <td>/tf/datasets/vox/ru_dev/6c0Fse9NrvQ__U__S102--...</td>\n",
       "      <td>ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24395</th>\n",
       "      <td>882</td>\n",
       "      <td>/tf/datasets/vox/ru_dev/n0uowclQ704__U__S136--...</td>\n",
       "      <td>ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24396</th>\n",
       "      <td>252</td>\n",
       "      <td>/tf/datasets/vox/ru_dev/3QNx2bMb7tM__U__S0---0...</td>\n",
       "      <td>ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24397</th>\n",
       "      <td>2796</td>\n",
       "      <td>/tf/datasets/vox/ru_dev/CfBlKGX094o__U__S278--...</td>\n",
       "      <td>ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24398</th>\n",
       "      <td>313</td>\n",
       "      <td>/tf/datasets/vox/ru_dev/PlqiRe7CEOY__U__S17---...</td>\n",
       "      <td>ru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82449 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                               path locale\n",
       "0             535                       common_voice_ta_19093662.mp3     ta\n",
       "1          147407                       common_voice_es_20252168.mp3     es\n",
       "2           53670                       common_voice_it_23740290.mp3     it\n",
       "3            6394                       common_voice_pl_22062475.mp3     pl\n",
       "4          272713                       common_voice_fr_23921769.mp3     fr\n",
       "...           ...                                                ...    ...\n",
       "24394         855  /tf/datasets/vox/ru_dev/6c0Fse9NrvQ__U__S102--...     ru\n",
       "24395         882  /tf/datasets/vox/ru_dev/n0uowclQ704__U__S136--...     ru\n",
       "24396         252  /tf/datasets/vox/ru_dev/3QNx2bMb7tM__U__S0---0...     ru\n",
       "24397        2796  /tf/datasets/vox/ru_dev/CfBlKGX094o__U__S278--...     ru\n",
       "24398         313  /tf/datasets/vox/ru_dev/PlqiRe7CEOY__U__S17---...     ru\n",
       "\n",
       "[82449 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vox.loc[vox['locale'] == 'kz', 'path'] = vox.loc[vox['locale'] == 'kz', 'path'].apply(lambda x: f\"/tf/datasets/vox/kz_dev/{x}\")\n",
    "vox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2ccda09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>path</th>\n",
       "      <th>locale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15966</th>\n",
       "      <td>1021</td>\n",
       "      <td>/tf/datasets/vox/kz_dev/4QuKKCY5mAo__U__S151--...</td>\n",
       "      <td>kz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15967</th>\n",
       "      <td>3210</td>\n",
       "      <td>/tf/datasets/vox/kz_dev/YNTYeSoy0HM__U__S285--...</td>\n",
       "      <td>kz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15968</th>\n",
       "      <td>1849</td>\n",
       "      <td>/tf/datasets/vox/kz_dev/Gu-TfzMwS6g__U__S271--...</td>\n",
       "      <td>kz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15969</th>\n",
       "      <td>108</td>\n",
       "      <td>/tf/datasets/vox/kz_dev/ASsJmutpNjg__U__S19---...</td>\n",
       "      <td>kz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15970</th>\n",
       "      <td>49</td>\n",
       "      <td>/tf/datasets/vox/kz_dev/O0YlWuOb-YQ__U__S16---...</td>\n",
       "      <td>kz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23083</th>\n",
       "      <td>356</td>\n",
       "      <td>/tf/datasets/vox/kz_dev/23UJ403sOxA__U__S128--...</td>\n",
       "      <td>kz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23084</th>\n",
       "      <td>545</td>\n",
       "      <td>/tf/datasets/vox/kz_dev/c2VaP6HXWS0__U__S41---...</td>\n",
       "      <td>kz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23085</th>\n",
       "      <td>250</td>\n",
       "      <td>/tf/datasets/vox/kz_dev/xg8wrC8Gao4__U__S119--...</td>\n",
       "      <td>kz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23086</th>\n",
       "      <td>2330</td>\n",
       "      <td>/tf/datasets/vox/kz_dev/HIPlXLT3aYw__U__S149--...</td>\n",
       "      <td>kz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23087</th>\n",
       "      <td>1211</td>\n",
       "      <td>/tf/datasets/vox/kz_dev/BoTd0MzNHD0__U__S190--...</td>\n",
       "      <td>kz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21366 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                               path locale\n",
       "15966        1021  /tf/datasets/vox/kz_dev/4QuKKCY5mAo__U__S151--...     kz\n",
       "15967        3210  /tf/datasets/vox/kz_dev/YNTYeSoy0HM__U__S285--...     kz\n",
       "15968        1849  /tf/datasets/vox/kz_dev/Gu-TfzMwS6g__U__S271--...     kz\n",
       "15969         108  /tf/datasets/vox/kz_dev/ASsJmutpNjg__U__S19---...     kz\n",
       "15970          49  /tf/datasets/vox/kz_dev/O0YlWuOb-YQ__U__S16---...     kz\n",
       "...           ...                                                ...    ...\n",
       "23083         356  /tf/datasets/vox/kz_dev/23UJ403sOxA__U__S128--...     kz\n",
       "23084         545  /tf/datasets/vox/kz_dev/c2VaP6HXWS0__U__S41---...     kz\n",
       "23085         250  /tf/datasets/vox/kz_dev/xg8wrC8Gao4__U__S119--...     kz\n",
       "23086        2330  /tf/datasets/vox/kz_dev/HIPlXLT3aYw__U__S149--...     kz\n",
       "23087        1211  /tf/datasets/vox/kz_dev/BoTd0MzNHD0__U__S190--...     kz\n",
       "\n",
       "[21366 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vox.loc[vox['locale'] == 'kz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1773aad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-07 03:05:32.049 I numexpr.utils: Note: detected 96 virtual cores but NumExpr set to maximum of 64, check \"NUMEXPR_MAX_THREADS\" environment variable.\n",
      "2021-07-07 03:05:32.050 I numexpr.utils: Note: NumExpr detected 96 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2021-07-07 03:05:32.051 I numexpr.utils: NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "vox.loc[(vox['locale'] != \"kz\") & (vox['locale'] != \"ru\") & (vox['locale']  != \"en\"), \"path\"] = \"/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/\" + vox.loc[(vox['locale'] != \"kz\") & (vox['locale'] != \"ru\") & (vox['locale']  != \"en\")][\"locale\"]  + \"/clips/\" + vox.loc[(vox['locale'] != \"kz\") & (vox['locale'] != \"ru\") & (vox['locale']  != \"en\")][\"path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba72c6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vox = vox.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "763f7e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"target_domain\"] = vox['path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "120778a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.concat([train, test, dev])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6da73e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>path</th>\n",
       "      <th>locale</th>\n",
       "      <th>split</th>\n",
       "      <th>target_domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1486</td>\n",
       "      <td>common_voice_ru_19559882.mp3</td>\n",
       "      <td>ru</td>\n",
       "      <td>train</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56701</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>kz</td>\n",
       "      <td>train</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3364</td>\n",
       "      <td>common_voice_ru_20957735.mp3</td>\n",
       "      <td>ru</td>\n",
       "      <td>train</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>110475</td>\n",
       "      <td>common_voice_rw_22681269.mp3</td>\n",
       "      <td>rw</td>\n",
       "      <td>train</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45384</td>\n",
       "      <td>common_voice_en_20767496.mp3</td>\n",
       "      <td>en</td>\n",
       "      <td>train</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30751</th>\n",
       "      <td>2677</td>\n",
       "      <td>common_voice_ru_18947939.mp3</td>\n",
       "      <td>ru</td>\n",
       "      <td>dev</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30752</th>\n",
       "      <td>881</td>\n",
       "      <td>common_voice_ru_18853495.mp3</td>\n",
       "      <td>ru</td>\n",
       "      <td>dev</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30753</th>\n",
       "      <td>68709</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>kz</td>\n",
       "      <td>dev</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30754</th>\n",
       "      <td>249025</td>\n",
       "      <td>common_voice_en_21725213.mp3</td>\n",
       "      <td>en</td>\n",
       "      <td>dev</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30755</th>\n",
       "      <td>2986</td>\n",
       "      <td>common_voice_uk_21566937.mp3</td>\n",
       "      <td>uk</td>\n",
       "      <td>dev</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168973 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                               path locale  \\\n",
       "0            1486                       common_voice_ru_19559882.mp3     ru   \n",
       "1           56701  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...     kz   \n",
       "2            3364                       common_voice_ru_20957735.mp3     ru   \n",
       "3          110475                       common_voice_rw_22681269.mp3     rw   \n",
       "4           45384                       common_voice_en_20767496.mp3     en   \n",
       "...           ...                                                ...    ...   \n",
       "30751        2677                       common_voice_ru_18947939.mp3     ru   \n",
       "30752         881                       common_voice_ru_18853495.mp3     ru   \n",
       "30753       68709  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...     kz   \n",
       "30754      249025                       common_voice_en_21725213.mp3     en   \n",
       "30755        2986                       common_voice_uk_21566937.mp3     uk   \n",
       "\n",
       "       split                                      target_domain  \n",
       "0      train  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...  \n",
       "1      train  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...  \n",
       "2      train  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...  \n",
       "3      train  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...  \n",
       "4      train  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...  \n",
       "...      ...                                                ...  \n",
       "30751    dev                                                NaN  \n",
       "30752    dev                                                NaN  \n",
       "30753    dev                                                NaN  \n",
       "30754    dev                                                NaN  \n",
       "30755    dev                                                NaN  \n",
       "\n",
       "[168973 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "faa7d0d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>path</th>\n",
       "      <th>locale</th>\n",
       "      <th>split</th>\n",
       "      <th>target_domain</th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1486</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>ru</td>\n",
       "      <td>train</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>1</td>\n",
       "      <td>1486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56701</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>kz</td>\n",
       "      <td>train</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>0</td>\n",
       "      <td>56701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3364</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>ru</td>\n",
       "      <td>train</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>1</td>\n",
       "      <td>3364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>110475</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>rw</td>\n",
       "      <td>train</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>3</td>\n",
       "      <td>110475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45384</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>en</td>\n",
       "      <td>train</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>2</td>\n",
       "      <td>45384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30751</th>\n",
       "      <td>2677</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>ru</td>\n",
       "      <td>dev</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30752</th>\n",
       "      <td>881</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>ru</td>\n",
       "      <td>dev</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30753</th>\n",
       "      <td>68709</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>kz</td>\n",
       "      <td>dev</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>68709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30754</th>\n",
       "      <td>249025</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>en</td>\n",
       "      <td>dev</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>249025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30755</th>\n",
       "      <td>2986</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>uk</td>\n",
       "      <td>dev</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>2986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168971 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                               path locale  \\\n",
       "0            1486  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...     ru   \n",
       "1           56701  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...     kz   \n",
       "2            3364  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...     ru   \n",
       "3          110475  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...     rw   \n",
       "4           45384  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...     en   \n",
       "...           ...                                                ...    ...   \n",
       "30751        2677  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...     ru   \n",
       "30752         881  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...     ru   \n",
       "30753       68709  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...     kz   \n",
       "30754      249025  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...     en   \n",
       "30755        2986  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...     uk   \n",
       "\n",
       "       split                                      target_domain  target  \\\n",
       "0      train  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...       1   \n",
       "1      train  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...       0   \n",
       "2      train  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...       1   \n",
       "3      train  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...       3   \n",
       "4      train  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...       2   \n",
       "...      ...                                                ...     ...   \n",
       "30751    dev                                                NaN       1   \n",
       "30752    dev                                                NaN       1   \n",
       "30753    dev                                                NaN       0   \n",
       "30754    dev                                                NaN       2   \n",
       "30755    dev                                                NaN       3   \n",
       "\n",
       "           id  \n",
       "0        1486  \n",
       "1       56701  \n",
       "2        3364  \n",
       "3      110475  \n",
       "4       45384  \n",
       "...       ...  \n",
       "30751    2677  \n",
       "30752     881  \n",
       "30753   68709  \n",
       "30754  249025  \n",
       "30755    2986  \n",
       "\n",
       "[168971 rows x 7 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta.loc[meta[\"locale\"] != \"kz\", \"path\"] = \"/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/\" +  meta.loc[meta[\"locale\"] != \"kz\"][\"locale\"] + \"/clips/\" + meta.loc[meta[\"locale\"] != \"kz\"][\"path\"]\n",
    "targets = {\"kz\": 0, \"ru\": 1, \"en\":2, \"other\":3}\n",
    "meta[\"target\"] = meta[\"locale\"]\n",
    "meta.loc[(meta[\"locale\"] != \"kz\") & (meta[\"locale\"] != \"ru\") & (meta[\"locale\"]!=\"en\"), \"target\"] = \"other\"\n",
    "meta = meta.loc[meta[\"path\"] != \"/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/kz/clips/5f590a130a73c.mp3\"]\n",
    "meta = meta.loc[meta[\"path\"] != \"/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/kz/clips/5ef9bd9ba7029.mp3\"]\n",
    "\n",
    "meta[\"id\"] = meta[\"Unnamed: 0\"].apply(str)\n",
    "meta[\"target\"] = meta[\"target\"].map(targets)\n",
    "\n",
    "meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d69e795a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "import math\n",
    "DEVICE = 'cuda'\n",
    "def _get_sample(path, resample=None):\n",
    "  effects = [\n",
    "    [\"remix\", \"1\"]\n",
    "  ]\n",
    "  if resample:\n",
    "    effects.append([\"rate\", f'{resample}'])\n",
    "  return torchaudio.sox_effects.apply_effects_file(path, effects=effects)\n",
    "\n",
    "SAMPLE_RIR_PATH = os.path.join(os.getcwd(), \"rir.wav\")\n",
    "\n",
    "def get_rir_sample(*, resample=None, processed=False):\n",
    "    rir_raw, sample_rate = _get_sample(SAMPLE_RIR_PATH, resample=resample)\n",
    "    if not processed:\n",
    "        return rir_raw, sample_rate\n",
    "    rir = rir_raw[:, int(sample_rate*1.01):int(sample_rate*1.3)]\n",
    "    rir = rir / torch.norm(rir, p=2)\n",
    "    rir = torch.flip(rir, [1])\n",
    "    return rir, sample_rate\n",
    "\n",
    "class AudiosDataset(Dataset):\n",
    "    def __init__(self, paths=None, targets=None, tg=None, augment=False) -> None:\n",
    "        self.paths = paths\n",
    "        self.targets = targets\n",
    "        self.augment = augment\n",
    "        self.target_domain = tg\n",
    "        self.rir = get_rir_sample()[0]\n",
    "        \n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> dict:\n",
    "        y, sr = torchaudio.load(self.paths.iloc[idx], normalization=True)\n",
    "        \n",
    "        y = torchaudio.transforms.Resample(orig_freq=sr, new_freq=16000)(y)\n",
    "        y = torchaudio.transforms.Vad(sample_rate = 16000)(y)\n",
    "\n",
    "     \n",
    "        fixed_length = 16000 * 12\n",
    "        \n",
    "        # returning result\n",
    "        if y.shape[1] < fixed_length:\n",
    "            y = torch.nn.functional.pad(\n",
    "              y, (0, fixed_length - y.shape[1]))\n",
    "        else:\n",
    "            y = y[:, :fixed_length]\n",
    "        representation = y\n",
    "        \n",
    "        \n",
    "        if self.target_domain is None:\n",
    "            y = []\n",
    "        else:\n",
    "            y, sr = torchaudio.load(self.target_domain.iloc[idx], normalization=True)\n",
    "\n",
    "\n",
    "            y = torchaudio.transforms.Resample(orig_freq=sr, new_freq=16000)(y)\n",
    "            y = torchaudio.transforms.Vad(sample_rate = 16000)(y)\n",
    "\n",
    "\n",
    "            fixed_length = 16000 * 12\n",
    "\n",
    "            # returning result\n",
    "            if y.shape[1] < fixed_length:\n",
    "                y = torch.nn.functional.pad(\n",
    "                  y, (0, fixed_length - y.shape[1]))\n",
    "            else:\n",
    "                y = y[:, :fixed_length]\n",
    "        \n",
    "        result = {\"target\":self.targets.iloc[idx], \"representation\":representation, \"target_domain\": y}\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49f32bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = AudiosDataset(meta[\"path\"], meta[\"target\"], meta[\"target_domain\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0940af2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "train_ds = AudiosDataset(meta.loc[meta[\"split\"]==\"train\"][\"path\"], meta.loc[meta[\"split\"]==\"train\"][\"target\"],  meta.loc[meta[\"split\"]==\"train\"][\"target_domain\"], augment=True)\n",
    "val_ds = AudiosDataset(meta.loc[meta[\"split\"]==\"dev\"][\"path\"], meta.loc[meta[\"split\"]==\"dev\"][\"target\"])\n",
    "test_ds = AudiosDataset(meta.loc[meta[\"split\"]==\"test\"][\"path\"], meta.loc[meta[\"split\"]==\"test\"][\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65e048af",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "num_workers = 10\n",
    "loaders = {\n",
    "    \"train\": DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        drop_last=True,\n",
    "    ),\n",
    "    \"valid\": DataLoader(\n",
    "        val_ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        drop_last=True,\n",
    "    ),\n",
    "    \"test\":DataLoader(\n",
    "        test_ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        drop_last=True,\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ebe4d0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/s3prl_s3prl_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[hubconf] can not import upstream.byol_a.hubconf: No module named 'easydict'... Pass.\n",
      "[hubconf] can not import upstream.decoar.hubconf: No module named 'mxnet'... Pass.\n",
      "[hubconf] can not import upstream.wav2vec2_hug.hubconf: No module named 'transformers'... Pass.\n",
      "[hubconf] can not import upstream.pase.hubconf: No module named 'pase'... Pass.\n",
      "[hubconf] can not import upstream.byol_a.hubconf: No module named 'easydict'... Pass.\n",
      "[hubconf] can not import upstream.decoar.hubconf: No module named 'mxnet'... Pass.\n",
      "[hubconf] can not import upstream.wav2vec2_hug.hubconf: No module named 'transformers'... Pass.\n",
      "[hubconf] can not import upstream.pase.hubconf: No module named 'pase'... Pass.\n",
      "2021-07-07 03:05:50.991 I filelock: Lock 139785345586768 acquired on /root/.cache/torch/hub/s3prl_cache/55805839eb58b56972be4a9994ca99c862d2572cfd74ae26c916e8ced5d45a7a.lock\n",
      "Using cache found in /root/.cache/torch/hub/s3prl_cache/55805839eb58b56972be4a9994ca99c862d2572cfd74ae26c916e8ced5d45a7a\n",
      "for https://www.dropbox.com/s/3wgynxmod77ha1z/states-1000000.ckpt?dl=0\n",
      "2021-07-07 03:05:50.992 I filelock: Lock 139785345586768 released on /root/.cache/torch/hub/s3prl_cache/55805839eb58b56972be4a9994ca99c862d2572cfd74ae26c916e8ced5d45a7a.lock\n",
      "[UpstreamExpert] - Using the default upstream expert config\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.7/site-packages/torchaudio/functional.py:318: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n",
      "  \"At least one mel filterbank has all zero values. \"\n",
      "/root/anaconda3/lib/python3.7/site-packages/torch/functional.py:516: UserWarning: stft will require the return_complex parameter be explicitly  specified in a future PyTorch release. Use return_complex=False  to preserve the current behavior or return_complex=True to return  a complex output. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:653.)\n",
      "  normalized, onesided, return_complex)\n",
      "/root/anaconda3/lib/python3.7/site-packages/torch/functional.py:516: UserWarning: The function torch.rfft is deprecated and will be removed in a future PyTorch release. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.fft or torch.fft.rfft. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:590.)\n",
      "  normalized, onesided, return_complex)\n"
     ]
    }
   ],
   "source": [
    "DEVICE = 'cuda'\n",
    "m = torch.hub.load('s3prl/s3prl', 'audio_albert').to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "776941d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "class Extractor(nn.Module):\n",
    "    def __init__(self, extractor):\n",
    "        super().__init__()\n",
    "        self.extractor = extractor\n",
    "\n",
    "        self.rnn = nn.LSTM(input_size=768, hidden_size=512, num_layers=5, bidirectional=True, batch_first=True, dropout=0.7)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        features = self.extractor(torch.squeeze(x))\n",
    "        features = torch.stack(features)\n",
    "        res, _ = self.rnn(features)\n",
    "        return res[:, -1, :]\n",
    "    \n",
    "    \n",
    "    \n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.classifier = nn.Sequential(\n",
    "                    nn.Linear(1024, 256),\n",
    "                    nn.ReLU(),\n",
    "                    nn.BatchNorm1d(256),\n",
    "                    nn.Dropout(0.5),\n",
    "                    nn.Linear(256, 4),\n",
    "                    )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        res = self.classifier(x)\n",
    "        return F.log_softmax(res, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d86b7d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = Extractor(m)\n",
    "C1 = Classifier()\n",
    "C2 = Classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aa832ee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.load_state_dict(torch.load(\"extractor.h5\"))\n",
    "C1.load_state_dict(torch.load(\"clf1.h5\"))\n",
    "C2.load_state_dict(torch.load(\"clf2.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a97e4cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "opt_g = optim.Adam(G.parameters(),\n",
    "                                    lr=5e-5, weight_decay=0.0005)\n",
    "\n",
    "opt_c1 = optim.Adam(C1.parameters(),\n",
    "                                     lr=5e-5, weight_decay=0.0005)\n",
    "opt_c2 = optim.Adam(C2.parameters(),\n",
    "                                     lr=5e-5, weight_decay=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "64214ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def discrepancy(out1, out2):\n",
    "        return torch.mean(torch.abs((out1) - (out2)))\n",
    "\n",
    "def reset_grad():\n",
    "    opt_g.zero_grad()\n",
    "    opt_c1.zero_grad()\n",
    "    opt_c2.zero_grad()\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "def train(criterion, epochs, data_tr, data_val, max_stable=5, num_K = 1):\n",
    "    best_val_loss = 1e9\n",
    "    counter = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        #tic = time()\n",
    "        print('* Epoch %d/%d' % (epoch+1, epochs))\n",
    "\n",
    "        avg_loss = 0\n",
    "        G.train()\n",
    "        C1.train()\n",
    "        C2.train()  # train mode\n",
    "        for batch in tqdm(data_tr):\n",
    "            loss = 0\n",
    "            # data to device\n",
    "            X_batch, Y_batch, targ = batch[\"representation\"], batch[\"target\"], batch[\"target_domain\"]\n",
    "            #print(X_batch.shape)\n",
    "            X_batch = X_batch.to(DEVICE)\n",
    "            Y_batch = Y_batch.to(DEVICE)\n",
    "            targ = targ.to(DEVICE)\n",
    "            # set parameter gradients to zero\n",
    "            reset_grad()\n",
    "            # forward\n",
    "            features = G(X_batch)\n",
    "            output_s1 = C1(features)\n",
    "            output_s2 = C2(features)\n",
    "\n",
    "            loss_s1 = criterion(output_s1, Y_batch)\n",
    "            loss_s2 = criterion(output_s2, Y_batch)\n",
    "            loss_s = loss_s1 + loss_s2\n",
    "            loss_s.backward()\n",
    "            opt_g.step()\n",
    "            opt_c1.step()\n",
    "            opt_c2.step()\n",
    "            reset_grad()\n",
    "            \n",
    "            \n",
    "            feat_s = G(X_batch)\n",
    "            output_s1 = C1(feat_s)\n",
    "            output_s2 = C2(feat_s)\n",
    "            feat_t = G(targ)\n",
    "            output_t1 = C1(feat_t)\n",
    "            output_t2 = C2(feat_t)\n",
    "\n",
    "            loss_s1 = criterion(output_s1, Y_batch)\n",
    "            loss_s2 = criterion(output_s2, Y_batch)\n",
    "            loss_s = loss_s1 + loss_s2\n",
    "            loss_dis = discrepancy(output_t1, output_t2)\n",
    "            loss = loss_s - loss_dis\n",
    "            loss.backward()\n",
    "            opt_c1.step()\n",
    "            opt_c2.step()\n",
    "            reset_grad()\n",
    "            for i in range(num_K):\n",
    "                #\n",
    "                feat_t = G(targ)\n",
    "                output_t1 = C1(feat_t)\n",
    "                output_t2 = C2(feat_t)\n",
    "                loss_dis = discrepancy(output_t1, output_t2)\n",
    "                loss_dis.backward()\n",
    "                opt_g.step()\n",
    "                reset_grad()\n",
    "        # show intermediate results\n",
    "        G.eval()\n",
    "        C1.eval()\n",
    "        C2.eval() \n",
    "        val_loss = 0\n",
    "        print(\"start validation\")\n",
    "        for v_b in tqdm(data_val):\n",
    "            X_val, Y_val = v_b[\"representation\"], v_b[\"target\"]\n",
    "            feat = G(X_val.to(DEVICE))\n",
    "            pred_1 = C1(feat).detach().cpu()\n",
    "            pred_2 = C2(feat).detach().cpu()\n",
    "            val_loss += (criterion(pred_1, Y_val) + criterion(pred_2, Y_val)) / 2\n",
    "        val_loss /= len(data_val)\n",
    "        print( f\"validation loss: {val_loss}\")\n",
    "        if val_loss <= best_val_loss and val_loss > 0:\n",
    "            counter = 0\n",
    "            print(\"Save new model!\")\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(G.state_dict(), f'extractor.h5')\n",
    "            torch.save(C1.state_dict(), f'clf1.h5')\n",
    "            torch.save(C2.state_dict(), f'clf2.h5')\n",
    "\n",
    "        else:\n",
    "            counter += 1\n",
    "        if counter == max_stable:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "87709e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda'\n",
    "max_epochs = 100\n",
    "G = G.to(DEVICE)\n",
    "C1 = C1.to(DEVICE)\n",
    "C2 = C2.to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a06d55ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10306 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/10306 [01:21<116:26:52, 40.68s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-022189db544c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"valid\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-f4ca15c16745>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(criterion, epochs, data_tr, data_val, max_stable, num_K)\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mloss_dis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscrepancy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_t1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_t2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_s\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mloss_dis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m             \u001b[0mopt_c1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mopt_c2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_fn =  nn.CrossEntropyLoss()\n",
    "train(loss_fn, max_epochs, loaders[\"train\"], loaders[\"valid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "878c9438",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6971/6971 [31:41<00:00,  3.67it/s]  \n"
     ]
    }
   ],
   "source": [
    "true_labels = []\n",
    "predicted_labels = []\n",
    "for batch in tqdm(loaders[\"test\"]):\n",
    "    G.eval()\n",
    "    C1.eval()\n",
    "    prediction = G(batch[\"representation\"].to(DEVICE))\n",
    "    prediction = C1(prediction).detach().cpu()\n",
    "    predicted_labels.extend(torch.argmax(prediction, dim=1).tolist())\n",
    "    true_labels.extend(batch[\"target\"].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "df076bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          kz       1.00      0.99      0.99     17341\n",
      "          ru       0.43      0.00      0.00     10379\n",
      "          en       0.00      0.00      0.00     12964\n",
      "       other       0.39      1.00      0.56     15084\n",
      "\n",
      "    accuracy                           0.58     55768\n",
      "   macro avg       0.45      0.50      0.39     55768\n",
      "weighted avg       0.50      0.58      0.46     55768\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(true_labels, predicted_labels, target_names=list(targets.keys()), labels=range(4))\n",
    "print(report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eb319b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np_rng = np.random.default_rng(1)\n",
    "\n",
    "\n",
    "import urllib.parse\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "import os\n",
    "\n",
    "from lidbox.meta import (\n",
    "    common_voice,\n",
    "    generate_label2target,\n",
    "    verify_integrity,\n",
    "    read_audio_durations,\n",
    "    random_oversampling_on_split\n",
    ")\n",
    "\n",
    "\n",
    "test = pd.read_csv(\"/tf/datasets/new_test.tsv\", sep=\"\\t\")\n",
    "\n",
    "test[\"path\"] = test[\"path\"].apply(lambda x: x[:-3] + \"mp3\")\n",
    "\n",
    "test[\"split\"] = \"test\"\n",
    "meta = pd.concat([test])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e75b6151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Extractor(\n",
       "  (extractor): UpstreamExpert(\n",
       "    (transformer): PretrainedTransformer(\n",
       "      (extracter): OnlinePreprocessor(\n",
       "        (_melscale): MelScale()\n",
       "        (_mfcc_trans): MFCC(\n",
       "          (amplitude_to_DB): AmplitudeToDB()\n",
       "          (MelSpectrogram): MelSpectrogram(\n",
       "            (spectrogram): Spectrogram()\n",
       "            (mel_scale): MelScale()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (model): TransformerModel(\n",
       "        (input_representations): TransformerInputRepresentations(\n",
       "          (spec_transform): Linear(in_features=80, out_features=768, bias=True)\n",
       "          (LayerNorm): TransformerLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder): TransformerEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0): TransformerLayer(\n",
       "              (attention): TransformerAttention(\n",
       "                (self): TransformerSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): TransformerSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                  (LayerNorm): TransformerLayerNorm()\n",
       "                )\n",
       "              )\n",
       "              (intermediate): TransformerIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              )\n",
       "              (output): TransformerOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (LayerNorm): TransformerLayerNorm()\n",
       "              )\n",
       "            )\n",
       "            (1): TransformerLayer(\n",
       "              (attention): TransformerAttention(\n",
       "                (self): TransformerSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): TransformerSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                  (LayerNorm): TransformerLayerNorm()\n",
       "                )\n",
       "              )\n",
       "              (intermediate): TransformerIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              )\n",
       "              (output): TransformerOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (LayerNorm): TransformerLayerNorm()\n",
       "              )\n",
       "            )\n",
       "            (2): TransformerLayer(\n",
       "              (attention): TransformerAttention(\n",
       "                (self): TransformerSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): TransformerSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                  (LayerNorm): TransformerLayerNorm()\n",
       "                )\n",
       "              )\n",
       "              (intermediate): TransformerIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              )\n",
       "              (output): TransformerOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (LayerNorm): TransformerLayerNorm()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (rnn): LSTM(768, 256, num_layers=2, batch_first=True, dropout=0.7, bidirectional=True)\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "417c0e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta.loc[((meta[\"locale\"] != \"kz\") & ~(((meta[\"split\"] == \"dev\") | (meta[\"split\"] == \"test\")) & ((meta[\"locale\"] == \"ru\") | (meta[\"locale\"] == \"kz\") | (meta[\"locale\"] == \"en\")))), \"path\"] = \"/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/\" + meta.loc[((meta[\"locale\"] != \"kz\") & ~(((meta[\"split\"] == \"dev\") | (meta[\"split\"] == \"test\")) & ((meta[\"locale\"] == \"ru\") | (meta[\"locale\"] == \"kz\") | (meta[\"locale\"] == \"en\"))))][\"locale\"]  + \"/clips/\" + meta.loc[((meta[\"locale\"] != \"kz\") & ~(((meta[\"split\"] == \"dev\") | (meta[\"split\"] == \"test\")) & ((meta[\"locale\"] == \"ru\") | (meta[\"locale\"] == \"kz\") | (meta[\"locale\"] == \"en\"))))][\"path\"]\n",
    "targets = {\"kz\": 0, \"ru\": 1, \"en\":2, \"other\":3}\n",
    "meta[\"target\"] = meta[\"locale\"]\n",
    "meta.loc[(meta[\"locale\"] != \"kz\") & (meta[\"locale\"] != \"ru\") & (meta[\"locale\"]!=\"en\"), \"target\"] = \"other\"\n",
    "meta = meta.loc[meta[\"path\"] != \"/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/kz/clips/5f590a130a73c.mp3\"]\n",
    "meta = meta.loc[meta[\"path\"] != \"/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/kz/clips/5ef9bd9ba7029.mp3\"]\n",
    "\n",
    "meta[\"id\"] = meta[\"Unnamed: 0\"].apply(str)\n",
    "meta[\"target\"] = meta[\"target\"].map(targets)\n",
    "\n",
    "\n",
    "workdir = \"/tf/datasets/transformer\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e4f63b0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       /tf/datasets/vox/en_test/shrDRhToGpY__U__S133-...\n",
       "1       /tf/datasets/vox/en_test/mzfg0RGJnV8__U__S123-...\n",
       "2       /tf/datasets/vox/en_test/-_PPCH3y0eE__U__S1---...\n",
       "3       /tf/datasets/vox/en_test/DQMxvGYyu6Q__U__S0---...\n",
       "4       /tf/datasets/vox/en_test/x4lfSc7PrB0__U__S0---...\n",
       "                              ...                        \n",
       "9995    /tf/datasets/vox/en_test/KLiy94kfZI4__U__S133-...\n",
       "9996    /tf/datasets/vox/en_test/YTlliEr5LOA__U__S113-...\n",
       "9997    /tf/datasets/vox/en_test/bSs0gNq6Kkc__U__S0---...\n",
       "9998    /tf/datasets/vox/en_test/Da7c-BY6MDA__U__S2---...\n",
       "9999    /tf/datasets/vox/en_test/VWvPndMo1F8__U__S24--...\n",
       "Name: path, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta.loc[(meta[\"split\"] == \"test\") & (meta[\"locale\"] == \"ru\"), \"path\"] = meta.loc[(meta[\"split\"] == \"test\") & (meta[\"locale\"] == \"ru\")][\"path\"].apply(lambda x: f\"/tf/datasets/vox/ru_test/{x}\")\n",
    "meta.loc[(meta[\"split\"] == \"test\") & (meta[\"locale\"] == \"ru\"), \"path\"]\n",
    "meta.loc[(meta[\"split\"] == \"test\") & (meta[\"locale\"] == \"kz\"), \"path\"] = meta.loc[(meta[\"split\"] == \"test\") & (meta[\"locale\"] == \"kz\")][\"path\"].apply(lambda x: f\"/tf/datasets/vox/kz_test/{x}\")\n",
    "meta.loc[(meta[\"split\"] == \"test\") & (meta[\"locale\"] == \"kz\"), \"path\"] \n",
    "meta.loc[(meta[\"split\"] == \"test\") & (meta[\"locale\"] == \"en\"), \"path\"] = meta.loc[(meta[\"split\"] == \"test\") & (meta[\"locale\"] == \"en\")][\"path\"].apply(lambda x: f\"/tf/datasets/vox/en_test/{x}\")\n",
    "meta.loc[(meta[\"split\"] == \"test\") & (meta[\"locale\"] == \"en\"), \"path\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b27cf25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta.loc[meta[\"split\"]==\"test\", \"Unnamed: 0\"] = meta.loc[meta[\"split\"]==\"test\"][\"path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "48184417",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta[\"id\"] = meta[\"Unnamed: 0\"].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c1472095",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta.loc[meta[\"split\"] == \"test\", \"id\"] = meta.loc[meta[\"split\"] == \"test\"][\"path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9a148a0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>locale</th>\n",
       "      <th>split</th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/en_test/shrDRhToGpY__U__S133---0944.430-0958.260.mp3</th>\n",
       "      <td>/tf/datasets/vox/en_test/shrDRhToGpY__U__S133-...</td>\n",
       "      <td>en</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>/tf/datasets/vox/en_test/shrDRhToGpY__U__S133-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/en_test/mzfg0RGJnV8__U__S123---0427.020-0444.670.mp3</th>\n",
       "      <td>/tf/datasets/vox/en_test/mzfg0RGJnV8__U__S123-...</td>\n",
       "      <td>en</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>/tf/datasets/vox/en_test/mzfg0RGJnV8__U__S123-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/en_test/-_PPCH3y0eE__U__S1---0398.760-0403.940.mp3</th>\n",
       "      <td>/tf/datasets/vox/en_test/-_PPCH3y0eE__U__S1---...</td>\n",
       "      <td>en</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>/tf/datasets/vox/en_test/-_PPCH3y0eE__U__S1---...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/en_test/DQMxvGYyu6Q__U__S0---1473.480-1485.720.mp3</th>\n",
       "      <td>/tf/datasets/vox/en_test/DQMxvGYyu6Q__U__S0---...</td>\n",
       "      <td>en</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>/tf/datasets/vox/en_test/DQMxvGYyu6Q__U__S0---...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/en_test/x4lfSc7PrB0__U__S0---0125.230-0140.900.mp3</th>\n",
       "      <td>/tf/datasets/vox/en_test/x4lfSc7PrB0__U__S0---...</td>\n",
       "      <td>en</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>/tf/datasets/vox/en_test/x4lfSc7PrB0__U__S0---...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/it/clips/common_voice_it_20015623.mp3</th>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>it</td>\n",
       "      <td>test</td>\n",
       "      <td>3</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/uk/clips/common_voice_uk_23554602.mp3</th>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>uk</td>\n",
       "      <td>test</td>\n",
       "      <td>3</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/tr/clips/common_voice_tr_20416266.mp3</th>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>tr</td>\n",
       "      <td>test</td>\n",
       "      <td>3</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/it/clips/common_voice_it_20263173.mp3</th>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>it</td>\n",
       "      <td>test</td>\n",
       "      <td>3</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/es/clips/common_voice_es_20283066.mp3</th>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>es</td>\n",
       "      <td>test</td>\n",
       "      <td>3</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51137 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                 path  \\\n",
       "Unnamed: 0                                                                                              \n",
       "/tf/datasets/vox/en_test/shrDRhToGpY__U__S133--...  /tf/datasets/vox/en_test/shrDRhToGpY__U__S133-...   \n",
       "/tf/datasets/vox/en_test/mzfg0RGJnV8__U__S123--...  /tf/datasets/vox/en_test/mzfg0RGJnV8__U__S123-...   \n",
       "/tf/datasets/vox/en_test/-_PPCH3y0eE__U__S1---0...  /tf/datasets/vox/en_test/-_PPCH3y0eE__U__S1---...   \n",
       "/tf/datasets/vox/en_test/DQMxvGYyu6Q__U__S0---1...  /tf/datasets/vox/en_test/DQMxvGYyu6Q__U__S0---...   \n",
       "/tf/datasets/vox/en_test/x4lfSc7PrB0__U__S0---0...  /tf/datasets/vox/en_test/x4lfSc7PrB0__U__S0---...   \n",
       "...                                                                                               ...   \n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...   \n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...   \n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...   \n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...   \n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...   \n",
       "\n",
       "                                                   locale split  target  \\\n",
       "Unnamed: 0                                                                \n",
       "/tf/datasets/vox/en_test/shrDRhToGpY__U__S133--...     en  test       2   \n",
       "/tf/datasets/vox/en_test/mzfg0RGJnV8__U__S123--...     en  test       2   \n",
       "/tf/datasets/vox/en_test/-_PPCH3y0eE__U__S1---0...     en  test       2   \n",
       "/tf/datasets/vox/en_test/DQMxvGYyu6Q__U__S0---1...     en  test       2   \n",
       "/tf/datasets/vox/en_test/x4lfSc7PrB0__U__S0---0...     en  test       2   \n",
       "...                                                   ...   ...     ...   \n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...     it  test       3   \n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...     uk  test       3   \n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...     tr  test       3   \n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...     it  test       3   \n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...     es  test       3   \n",
       "\n",
       "                                                                                                   id  \n",
       "Unnamed: 0                                                                                             \n",
       "/tf/datasets/vox/en_test/shrDRhToGpY__U__S133--...  /tf/datasets/vox/en_test/shrDRhToGpY__U__S133-...  \n",
       "/tf/datasets/vox/en_test/mzfg0RGJnV8__U__S123--...  /tf/datasets/vox/en_test/mzfg0RGJnV8__U__S123-...  \n",
       "/tf/datasets/vox/en_test/-_PPCH3y0eE__U__S1---0...  /tf/datasets/vox/en_test/-_PPCH3y0eE__U__S1---...  \n",
       "/tf/datasets/vox/en_test/DQMxvGYyu6Q__U__S0---1...  /tf/datasets/vox/en_test/DQMxvGYyu6Q__U__S0---...  \n",
       "/tf/datasets/vox/en_test/x4lfSc7PrB0__U__S0---0...  /tf/datasets/vox/en_test/x4lfSc7PrB0__U__S0---...  \n",
       "...                                                                                               ...  \n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...  \n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...  \n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...  \n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...  \n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...  \n",
       "\n",
       "[51137 rows x 5 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta = meta.set_index(\"Unnamed: 0\")\n",
    "meta.loc[meta[\"split\"]==\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "afa4d2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta.loc[meta[\"split\"] == \"test\"] = meta.loc[(meta[\"split\"] == \"test\") & (meta[\"target\"] != 3)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cf569a6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>locale</th>\n",
       "      <th>split</th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/en_test/shrDRhToGpY__U__S133---0944.430-0958.260.mp3</th>\n",
       "      <td>/tf/datasets/vox/en_test/shrDRhToGpY__U__S133-...</td>\n",
       "      <td>en</td>\n",
       "      <td>test</td>\n",
       "      <td>2.0</td>\n",
       "      <td>/tf/datasets/vox/en_test/shrDRhToGpY__U__S133-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/en_test/mzfg0RGJnV8__U__S123---0427.020-0444.670.mp3</th>\n",
       "      <td>/tf/datasets/vox/en_test/mzfg0RGJnV8__U__S123-...</td>\n",
       "      <td>en</td>\n",
       "      <td>test</td>\n",
       "      <td>2.0</td>\n",
       "      <td>/tf/datasets/vox/en_test/mzfg0RGJnV8__U__S123-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/en_test/-_PPCH3y0eE__U__S1---0398.760-0403.940.mp3</th>\n",
       "      <td>/tf/datasets/vox/en_test/-_PPCH3y0eE__U__S1---...</td>\n",
       "      <td>en</td>\n",
       "      <td>test</td>\n",
       "      <td>2.0</td>\n",
       "      <td>/tf/datasets/vox/en_test/-_PPCH3y0eE__U__S1---...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/en_test/DQMxvGYyu6Q__U__S0---1473.480-1485.720.mp3</th>\n",
       "      <td>/tf/datasets/vox/en_test/DQMxvGYyu6Q__U__S0---...</td>\n",
       "      <td>en</td>\n",
       "      <td>test</td>\n",
       "      <td>2.0</td>\n",
       "      <td>/tf/datasets/vox/en_test/DQMxvGYyu6Q__U__S0---...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/en_test/x4lfSc7PrB0__U__S0---0125.230-0140.900.mp3</th>\n",
       "      <td>/tf/datasets/vox/en_test/x4lfSc7PrB0__U__S0---...</td>\n",
       "      <td>en</td>\n",
       "      <td>test</td>\n",
       "      <td>2.0</td>\n",
       "      <td>/tf/datasets/vox/en_test/x4lfSc7PrB0__U__S0---...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/kz_test/rCpb0p_lyxI__U__S25---0107.830-0127.780.mp3</th>\n",
       "      <td>/tf/datasets/vox/kz_test/rCpb0p_lyxI__U__S25--...</td>\n",
       "      <td>kz</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/tf/datasets/vox/kz_test/rCpb0p_lyxI__U__S25--...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/kz_test/BkLVX9wf2YI__U__S26---0236.830-0241.550.mp3</th>\n",
       "      <td>/tf/datasets/vox/kz_test/BkLVX9wf2YI__U__S26--...</td>\n",
       "      <td>kz</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/tf/datasets/vox/kz_test/BkLVX9wf2YI__U__S26--...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/kz_test/RqdH-JD8TpM__U__S78---0466.720-0470.860.mp3</th>\n",
       "      <td>/tf/datasets/vox/kz_test/RqdH-JD8TpM__U__S78--...</td>\n",
       "      <td>kz</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/tf/datasets/vox/kz_test/RqdH-JD8TpM__U__S78--...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/kz_test/oCjW4Jy6azE__U__S110---0669.320-0675.220.mp3</th>\n",
       "      <td>/tf/datasets/vox/kz_test/oCjW4Jy6azE__U__S110-...</td>\n",
       "      <td>kz</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/tf/datasets/vox/kz_test/oCjW4Jy6azE__U__S110-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/kz_test/cwyX-Vjxep4__U__S30---0302.770-0318.540.mp3</th>\n",
       "      <td>/tf/datasets/vox/kz_test/cwyX-Vjxep4__U__S30--...</td>\n",
       "      <td>kz</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/tf/datasets/vox/kz_test/cwyX-Vjxep4__U__S30--...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36053 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                 path  \\\n",
       "Unnamed: 0                                                                                              \n",
       "/tf/datasets/vox/en_test/shrDRhToGpY__U__S133--...  /tf/datasets/vox/en_test/shrDRhToGpY__U__S133-...   \n",
       "/tf/datasets/vox/en_test/mzfg0RGJnV8__U__S123--...  /tf/datasets/vox/en_test/mzfg0RGJnV8__U__S123-...   \n",
       "/tf/datasets/vox/en_test/-_PPCH3y0eE__U__S1---0...  /tf/datasets/vox/en_test/-_PPCH3y0eE__U__S1---...   \n",
       "/tf/datasets/vox/en_test/DQMxvGYyu6Q__U__S0---1...  /tf/datasets/vox/en_test/DQMxvGYyu6Q__U__S0---...   \n",
       "/tf/datasets/vox/en_test/x4lfSc7PrB0__U__S0---0...  /tf/datasets/vox/en_test/x4lfSc7PrB0__U__S0---...   \n",
       "...                                                                                               ...   \n",
       "/tf/datasets/vox/kz_test/rCpb0p_lyxI__U__S25---...  /tf/datasets/vox/kz_test/rCpb0p_lyxI__U__S25--...   \n",
       "/tf/datasets/vox/kz_test/BkLVX9wf2YI__U__S26---...  /tf/datasets/vox/kz_test/BkLVX9wf2YI__U__S26--...   \n",
       "/tf/datasets/vox/kz_test/RqdH-JD8TpM__U__S78---...  /tf/datasets/vox/kz_test/RqdH-JD8TpM__U__S78--...   \n",
       "/tf/datasets/vox/kz_test/oCjW4Jy6azE__U__S110--...  /tf/datasets/vox/kz_test/oCjW4Jy6azE__U__S110-...   \n",
       "/tf/datasets/vox/kz_test/cwyX-Vjxep4__U__S30---...  /tf/datasets/vox/kz_test/cwyX-Vjxep4__U__S30--...   \n",
       "\n",
       "                                                   locale split  target  \\\n",
       "Unnamed: 0                                                                \n",
       "/tf/datasets/vox/en_test/shrDRhToGpY__U__S133--...     en  test     2.0   \n",
       "/tf/datasets/vox/en_test/mzfg0RGJnV8__U__S123--...     en  test     2.0   \n",
       "/tf/datasets/vox/en_test/-_PPCH3y0eE__U__S1---0...     en  test     2.0   \n",
       "/tf/datasets/vox/en_test/DQMxvGYyu6Q__U__S0---1...     en  test     2.0   \n",
       "/tf/datasets/vox/en_test/x4lfSc7PrB0__U__S0---0...     en  test     2.0   \n",
       "...                                                   ...   ...     ...   \n",
       "/tf/datasets/vox/kz_test/rCpb0p_lyxI__U__S25---...     kz  test     0.0   \n",
       "/tf/datasets/vox/kz_test/BkLVX9wf2YI__U__S26---...     kz  test     0.0   \n",
       "/tf/datasets/vox/kz_test/RqdH-JD8TpM__U__S78---...     kz  test     0.0   \n",
       "/tf/datasets/vox/kz_test/oCjW4Jy6azE__U__S110--...     kz  test     0.0   \n",
       "/tf/datasets/vox/kz_test/cwyX-Vjxep4__U__S30---...     kz  test     0.0   \n",
       "\n",
       "                                                                                                   id  \n",
       "Unnamed: 0                                                                                             \n",
       "/tf/datasets/vox/en_test/shrDRhToGpY__U__S133--...  /tf/datasets/vox/en_test/shrDRhToGpY__U__S133-...  \n",
       "/tf/datasets/vox/en_test/mzfg0RGJnV8__U__S123--...  /tf/datasets/vox/en_test/mzfg0RGJnV8__U__S123-...  \n",
       "/tf/datasets/vox/en_test/-_PPCH3y0eE__U__S1---0...  /tf/datasets/vox/en_test/-_PPCH3y0eE__U__S1---...  \n",
       "/tf/datasets/vox/en_test/DQMxvGYyu6Q__U__S0---1...  /tf/datasets/vox/en_test/DQMxvGYyu6Q__U__S0---...  \n",
       "/tf/datasets/vox/en_test/x4lfSc7PrB0__U__S0---0...  /tf/datasets/vox/en_test/x4lfSc7PrB0__U__S0---...  \n",
       "...                                                                                               ...  \n",
       "/tf/datasets/vox/kz_test/rCpb0p_lyxI__U__S25---...  /tf/datasets/vox/kz_test/rCpb0p_lyxI__U__S25--...  \n",
       "/tf/datasets/vox/kz_test/BkLVX9wf2YI__U__S26---...  /tf/datasets/vox/kz_test/BkLVX9wf2YI__U__S26--...  \n",
       "/tf/datasets/vox/kz_test/RqdH-JD8TpM__U__S78---...  /tf/datasets/vox/kz_test/RqdH-JD8TpM__U__S78--...  \n",
       "/tf/datasets/vox/kz_test/oCjW4Jy6azE__U__S110--...  /tf/datasets/vox/kz_test/oCjW4Jy6azE__U__S110-...  \n",
       "/tf/datasets/vox/kz_test/cwyX-Vjxep4__U__S30---...  /tf/datasets/vox/kz_test/cwyX-Vjxep4__U__S30--...  \n",
       "\n",
       "[36053 rows x 5 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta.loc[meta[\"split\"]==\"test\", \"id\"] = meta.loc[meta[\"split\"]==\"test\"][\"path\"]\n",
    "meta.loc[meta[\"split\"]==\"test\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e80debc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "newtest_ds = AudiosDataset(meta.loc[meta[\"split\"]==\"test\"][\"path\"], meta.loc[meta[\"split\"]==\"test\"][\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "24ba0c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders[\"new_test\"] = DataLoader(\n",
    "        newtest_ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        drop_last=True,\n",
    "    )\n",
    "DEVICE = 'cuda'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "04bb07d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4506/4506 [17:31<00:00,  4.29it/s]  \n"
     ]
    }
   ],
   "source": [
    "true_labels = []\n",
    "predicted_labels = []\n",
    "for batch in tqdm(loaders[\"new_test\"]):\n",
    "    G.eval()\n",
    "    C1.eval()\n",
    "    prediction = G(batch[\"representation\"].to(DEVICE))\n",
    "    prediction = C1(prediction).detach().cpu()\n",
    "    predicted_labels.extend(torch.argmax(prediction, dim=1).tolist())\n",
    "    true_labels.extend(batch[\"target\"].tolist())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c7f2378e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          kz       0.38      0.86      0.52     13941\n",
      "          ru       0.40      0.00      0.00     12107\n",
      "          en       0.00      0.00      0.00     10000\n",
      "       other       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.33     36048\n",
      "   macro avg       0.19      0.21      0.13     36048\n",
      "weighted avg       0.28      0.33      0.20     36048\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(true_labels, predicted_labels, target_names=list(targets.keys()), labels=range(4))\n",
    "print(report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8f544e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
